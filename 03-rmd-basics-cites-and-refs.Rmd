---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    latex_engine: xelatex
documentclass: book
bibliography: references.bib
---

# APD study {#APD-study}

\chaptermark{APD study}

\minitoc <!-- this will include a mini table of contents-->

## Introduction

## Methods

### Participants

```{r, include=FALSE}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(plyr)){install.packages("plyr")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(psych)){install.packages("psych")}
if(!require(english)){install.packages("english")}
if(!require(stringr)){install.packages("stringr")}
if(!require(nparLD)){install.packages("nparLD")}
if(!require(apa)){install.packages("apa")}


require(ggplot2)
require(ggbeeswarm)
require(dplyr)
require(plyr)
require(psych)
require(english)
require(stringr)
require(knitr)
require(kableExtra)
require(tidyr)
require(lme4)
require(sjPlot)
require(car)
require(ggpubr)
require(patchwork)
require(coin)
require(effsize)
require(rstatix)
require(graphics)
require(nparLD)
require(apa)

## Initialisation ----------------------------------------------------------------------------------------------------
date <- Sys.Date()
FileDir <- getwd()

# deviance level for abnormal z-score
CutOff <- 1.96# 1.65

# Filter buttons------------------------------------------------------------------------------------------------------
# 1. Remove NA's and observations with bad adaptive tracks 
CleanData <- 0 # On=1/Off=0 button

# 2. Remove specifc subjects 
RmvSubj <- 1 # On=1/Off=0 button
Subj2Remove <-c("APD14")  #"TD11"

# 3. Remove subjects based on their quality evaluation made by the examiner on the testing day 
QualityCtrl <- 0 # On=1/Off=0 button
rmvEval <- c("Bad") #  "Good" / "Maybe" / "Bad"

# 4. Remove APD subjects based on their diagnosis 
DiagCtrl <- 0 # On=1/Off=0 button
rmvDiag <- c("LiD","susAPD") #  "APD" / "LiD" (i.e., AP deficit and not a DISORDER) / "susAPD"

# 5. Removce APD subjects WITHOUT SPD patterns 
APDsubTypCtrl <- 0 # On=1/Off=0 button
rmvAPDType <- c(NA, "MissingReoprt") #  "SPD"

# 6. Remove outliers |z| > 2 
rmvOutlrs_z = 0
# 7. Remove outliers Cook's distance D
rmvOutlrs_D <- 0
# --------------------------------------------------------------------------------------------------------------------

# get demographics ---------------------------------------------------------------------------------------------------
d<- read.csv(file.path(FileDir,'Files','AllListenersDemographics_SK.csv'),header=T) 

# Clean data
d[is.na(d),]
d <- na.omit(d) # remove rows with missing data

# calculate age from DOB and testing day
if(!require(eeptools)){install.packages("eeptools")}
library(eeptools)

d$Age <- age_calc(as.Date(d$DOB,"%d/%m/%Y"),
                   as.Date(d$TestDate,"%d/%m/%Y"),
                   units = "years", precise = TRUE)
d$Age <- round(d$Age,1)

#unique(d$listener)
#length(unique(d$listener))

# get additional demographics -------------------------------------------------------------------------------------- 
d_Info <- read.csv(file.path(FileDir,'Files','BackgroundInfo.csv'),header=T)
d_Info <- d_Info[,-match(c("DOB", "TestingDay","Age", "Sex","Group"),names(d_Info))]

# merge data frames  -----------------------------------------------------------------------------------------------
d <- merge(d_Info,d,by=c("listener"))
cols <- c("AuditoryTraining","EarProblems","EarProblemsDur","SLT","Grommets","MusicalTraining","FMuse","Otoscopy","NrmlSpchUnderstanding")
d[cols] <- lapply(d[cols], factor)

# Filter data by groups  -------------------------------------------------------------------------------------------
TD <- d %>% filter(Group=="TD") %>% droplevels() 
APD <- d %>% filter(Group=="APD") %>% droplevels()
SexFreq_APD <- count(APD,"Sex")
DiagFreq <- count(APD,"Diagnosis")
SPDFreq <- count(APD,"Subtype")
ClinicFreq <- count(APD,"Clinic")

TD_Age <- describe(TD$Age)
APD_Age <-describe(APD$Age)

Age_min <- ifelse(TD_Age$min >APD_Age$min,TD_Age$min,APD_Age$min)
Age_max <- ifelse(TD_Age$max >APD_Age$max,TD_Age$max,APD_Age$max)

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects 
if (RmvSubj==1){d <- d[ ! d$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include / Subjects based on the quality of their testing 
if (QualityCtrl==1){d <- d[ ! d$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis
if (DiagCtrl==1){d <- d[ ! d$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns 
if (APDsubTypCtrl==1){d <- d[ ! d$Subtype %in% rmvAPDType, ] %>% droplevels()}


# -------------------------------------------------------------------------------------------------------------------

# Filter data by groups  -------------------------------------------------------------------------------------------
Clean.TD <- d %>% filter(Group=="TD") %>% droplevels() 
Clean.APD <- d %>% filter(Group=="APD") %>% droplevels() 

Clean.TD_Age <- describe(Clean.TD$Age)
Clean.APD_Age <-describe(Clean.APD$Age)

SexFreq_Clean.APD <- count(Clean.APD,"Sex")
DiagFreq.Clean <- count(Clean.APD,"Diagnosis")
SPDFreq.Clean <- count(Clean.APD,"Subtype")
ClinicFreq.Clean <- count(Clean.APD,"Clinic")

SexFreq_Clean.TD <- count(Clean.TD,"Sex")

# Test for age difference between the groups
# use Welch approximation t-test due to the uneven sample size

Age.t_test <- t.test(Age~ Group, data=d, conf.level = 0.95, paired = FALSE)
# Results: t = 3.43, df = 40.955, p-value = 0.00139
# There is a significant difference between the groups, with APD children on average ~2 years older than the TD children.

test <- glm(Age ~ Group, data=d)
summary(test)
```

`r  Hmisc::capitalize(as.character(as.english(sum(TD_Age$n,APD_Age$n),english.UK = TRUE)))` primary school children native British English speakers with normal hearing acuity participated in the study. Amongst them `r as.english(sum(APD_Age$n)-1,english.UK = TRUE)` belonged to the APD clinical group (`r SexFreq_APD[1,2]` females) with an average age of `r round(Clean.APD_Age$mean,2)` $\pm$ `r round(Clean.APD_Age$sd,2)` years (range: `r round(Clean.APD_Age$min,2)` - `r round(Clean.APD_Age$max,2)` years). One APD child was excluded from the analysis due to raised thresholds (PTA\>25 dB HL). APD children were recruited in two ways. Children diagnosed with APD at Great Ormond Street Hospital (GOSH) and at the London Hearing and Balance Centre (LHBC), London, UK, and fulfilled the recruitment criteria were identified and contacted by a clinical team member. The parents/caregivers were provided with information about the study and means of contact to express interest in participation. Others were recruited by advertisements in social networks, where parents were requested to fill-out an interest form that included screening questions to ensure they fulfil the participation requirements. [To add percentage for clinics, diagnosed/LiD/susAPD and SPD pattern?]{.correction} The remaining `r as.english(sum(TD_Age$n),english.UK = TRUE)` (`r SexFreq_Clean.TD[1,2]` females) comprised of typically developing control children (TD) with no reported concerns or diagnosis of a language or other cognitive developmental disorders. The TD group average age was `r round(Clean.TD_Age$mean,2)` $\pm$ `r round(Clean.TD_Age$sd,2)` years and ranged between `r round(Clean.TD_Age$min,2)` to `r round(Clean.TD_Age$max,2)` years (A detailed description of the groups is shown in Tab. ??).

Difference in variance for age between the two groups was tested using t-test with Welch degrees of freedom correction for uneven sample-size, showing a significant difference in age between the groups [t(`r round(Age.t_test$parameter,2)`)=`r  round(Age.t_test$statistic,2)`, p=`r round(Age.t_test$p.value,3)`].

The project was approved by the UCL Research Ethics Committee (Project ID Number 0544/006) and the NHS Health Research Authority HRA (REC reference: 18/LO/0250). The testing commenced once an informed consent was given by both the parent/caregiver and the child.

-   Background questionnaire
-   Otoscopic examination was carried out to ensure the eardrum is visible, healthy and intact.
-   Location of the testing
-   duration of the session

Participants from both TD and APD group completed the same battery of tests listed below

### Auditory evaluation

#### Standard audiometry

```{r, label='PTA', fig.cap="APD participants pure-tone audiogram thresholds for standard frequencies plotted for the left and the right ear (black). The shaded grey area represents the TD group range of audiometric thresholds and the white line represents the mean at each frequency. The dashed line represents the threshold criteria of hearing level $\\leq$ 25\ dB\ HL.", echo=FALSE, fig.align='center', figures-side, out.width='85%',fig.width=12, fig.height=6}

# Define axes
# xaxis=c(1:8) # number of frequencies tested
# 250	500	1000	2000	4000	6000	8000
FreqAxis=c("0.25","0.5","1","2","4","8")
frqs=c(0.25,0.5,1,2,4,8)

# min and max of y axis
max	=	max((d[1:nrow(d),28:39]),na.rm=T) + 17
min	=	min(d[1:nrow(d),28:39],na.rm=T) - 10

# Plot overlapping individual audiograms of test group, mean of test group, and mean +/- 1 sd of control group
# Assumes test group and control group are in same .csv file (different columns)

TD = d[grep("TD", d[,1]),] 	 #control group
APD = d[grep("APD", d[,1]),] #test group

# plot left and right ear
#layout(matrix(c(1:2), 1, 2, byrow = TRUE))
par(mfrow=c(1,2),mar=c(0,0,0,1.5),oma=c(7,7,1,1))

for (j in 1:2){
  
  # create empty plot
  plot(frqs,xlim=c(frqs[1],max(frqs)),type="n",axes=FALSE,ann=FALSE,ylim=rev(range(c(min,max))),log = "x")
  box()
  
  mtext(outer=T,side=1,line=3,text="frequency (kHz)",cex=1.5)		
  mtext(outer=T,side=2,line=3,text="threshold (dB HL)",cex=1.5)	
  
  if (j<=1){
    axis(2,col="black",cex.axis=1.5)
    text(5,-14,"Left",cex=1.5)
  }  else {
    text(5,-14,"Right",cex=1.5)
  }
  
  axis(1,at=frqs,lab=FreqAxis,cex.axis=1.5)
  
  # Left ear
  if (j<=1) {
    numCol = 34:39
  } else {
    # Right ear
    numCol = 28:33
  }
  # calculate mean for test group
  avg<-vector()
  for (i in numCol){
    avg[i-(numCol[1]-1)]<-mean(APD[1:length(APD[,1]),i])
  }
  
  ## calculate mean and sd for control group
  stdev <- vector()
  mn <- vector()
  for (i in numCol){
    stdev[i-(numCol[1]-1)]<-sd(TD[1:length(TD[,1]),i],na.rm=T)
    mn[i-(numCol[1]-1)]<-mean(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate min and max for control group
  mnn <- vector()
  mx <- vector()
  for (i in numCol){
    mnn[i-(numCol[1]-1)]<-min(TD[1:length(TD[,1]),i],na.rm=T)
    mx[i-(numCol[1]-1)]<-max(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate upper and lower boundaries of shaded area
  upper <- mnn
  lower <- mx
  
  # plot shaded area (mean +/- 1 sd)
  xx <- c(frqs, rev(frqs))
  yy <- c(lower,rev(upper))
  polygon(xx, yy, col="lightgrey",border=NA)
  
  # plot mean control group
  lines(frqs,mn,col="white",lwd=3)
  
  # plot individual audiograms test group
  for (i in 1:length(APD[,1])){
    lines(frqs,APD[i,numCol])
  }
  
  # plot mean test group
  lines(frqs,avg,lwd=4, col="black")
  
  # plot exclusion criteria line
  #lines(c(0:9), seq(25,25,length=10),lty=2,lwd=3)
  lines(c(0.25, 0.50, 1.00, 2.00, 4.00, 4.00, 2.00, 1.00, 0.50, 0.25), seq(25,25,length=10),lty=2,lwd=3)
  
  if (j<=1){
    yplot <- 35
    # plot legend
    legend(0.24,yplot, c("Mean APD","Individual APD","Mean and range TD","NH criteria"),
           lty=c(1,1,1,2),lwd=c(3,2,8,2),col=c("black","black","lightgrey","black"),cex=0.8,bty=0,box.col="white")

    # Add white line to legend for mean
    segments(x0 = .24, y0 = 42.8, x1 = .33, y1 = 42.8,col = "white", lwd = 3)   
  }
}

```

A standard air conduction pure-tone audiometry was carried out at six octave frequency bands ranging between 0.25 to 8 kHz using ???? audiometer and ??? headphones. Normal hearing acuity was defined as thresholds $\leq$ 25 dB HL for the octave frequency bands between 0.25 to 4 kHz. Thresholds at 8 kHz were $\leq$ 25 dB HL for all the participants, excluding two participants with thresholds at 35 and 30 dB HL in one ear, respectively. One participant from the clinical group (APD) was excluded from the analysis due to raised thresholds predominantly in the right ear (PTA$_{Right}$ = 36.25 dB HL; PTA$_{Left}$ = 13.75 dB HL). Otoscopy inspection of the child's ear canal revealed a large accumulation of cerumen whereby the right eardrum was not visible. The listeners' thresholds for the left and the right ear are plotted in Figure \@ref(fig:PTA). The shaded grey area represents the TD group thresholds range and the white line represents their mean at each frequency. The black lines represents the individual thresholds in the APD group and the group mean is marked by the bold black line. The dashed line represents the maximal thresholds criteria of $\leq$ 25 dB HL for participation in the study. [Results belong here??]{.correction} 


#### Extended high-frequency audiometry (EHFA)

Extended high-frequency pure-tone audiometry was carried out at four $\frac{1}{3}$ octave band frequencies 8, 11, 16, & 20 kHz using a locally developed MATLAB based software which generated and collected the data. Measurements took place at SHaPS, UCL laboratory in an electromagnetically shielded sound proof booth which is typically used for EEG measurements. A Windows PC situated outside the booth was connected via USB to an RME ???? sound card (Audio AG, Haimhausen Germany) and an ER10X Extended-Bandwidth Acoustic Probe System (Etym$\bar{o}$tic Research, Elk Grove Village, IL) which was located in the testing booth. Once the ear probe was placed in the child's ear, an in-situ sound pressure level calibration was performed (chirp noise) using a MATLAB code provided by ????.

Speak with KZ about the measurements

#### Switching task (ST)

The switching task (ST) is a novel speech-on-speech listening task that involves perception of interrupted and periodically segmented speech that is switched between the two ears out-of-phase with an interrupted distractor. Since segments of the target and of the distractor are never presented in the same ear at the same time, it enables to eliminate peripheral (EM) masking, while maintaining high IM for speech distractors. The task assesses the ability to switch attention and integration of binaural information.

Refer to Chapter 2 and briefly describe the stimuli and difference in the methods.

As described in Chapter 2 Section ???, two test versions were used with varying in sentence structure and complexity: 1. ASL 2. CCRM

Masker Types..

#### Spatialised speech-in-noise (LiSNS-UK)

The Listening in Spatialised Noise Sentences UK (LiSNS-UK) assesses the ability to use binaural cues in speech-on-speech listening conditions. The test development, speech material normalisation, and norms standardisation followed @Cameron2007 development steps and are described in detail in Chapter ???. The test uses virtualisation techniques to create spatial distribution of sound sources in space for headphones presentation where target sentences [ASL; @MacLeod1990] are presented in two simultaneous speech distractors (unrelated children's stories spoken by the target talker). It comprises of two main listening conditions, differing in their availability of spatial cues. The target sentences are configured to always appear in front of the listener's head, at 0$^{\circ}$ azimuth on the horizontal plane, with the two streams of speech distractors either co-located in space with the target (S0N0), resulting in relatively poor speech perception, or offset in space, with one distractor to either side of the target at $\pm$ 90$^{\circ}$, resulting in an improvement in speech perception of circa 13 dB [@Cameron2011], typically termed as spatial release from masking (SRM). This SRM advantage is calculated by taking the difference between performance in the co-located condition and the separated condition. The speech distractors were presented continuously throughout a run at a fixed 65? dB SPL output level and comprised of a combination of two out of three different passages children stories. A 1-up/1-down adaptive procedure was used, varying the level of the target talker relative to the distractors depending on listener's correct/incorrect response to measure the listeners' speech reception threshold (SRT), i.e., the signal-to-noise-ratio (SNR) yielding 50% speech intelligibility. A 2 ms long 1 kHz pure-tone was presented 500 ms before the target sentence onset at 65? dB SPL (0 dB SNR) as a reference cue signalling the listener to attend the coming target sentence. The initial target output level was ?? dB SPL with an initial step-size of 4 dB SNR. The step-size was reduced after every reversal, reaching a minimum step-size of 2 dB SNR after three practice reversals. A stopping rule was introduced in case the maximal SNR was reached more than three times and the procedure was considered to be successfully completed in case test reversals were obtained. The SRT was then calculated by averaging test reversals SNRs (i.e., following three practice reversals). Each run consisted of 25 sentences taken from 8? phonemically-balanced test list which were constructed following the normalisation of the speech. In addition, a sentence-specific level correction was applied to the target signal (see Chapter ?? for more information). The order of the listening condition, test lists, target sentences and distractors combinations was fixed across all the participants and started with the collocated condition. Spatialisation was applied by convolving each stimuli with head-related transfer functions (HRTFs) at the corresponding azimuthal direction separately for the left and the right channel. The HRTFs were measured with a Knowles Electronics Manikin for Acoustic Research (KEMAR, REF) manikin with a small pinnae taken from the CIPIC HRTF database[^rmd-basics-cites-and-refs-1] [@Algazi2001; see "special" HRTF data]. A post-equalisation step was applied in order to flatten the magnitude of the headphones frequency response. Headphone-to-ear Transfer Functions (HpTFs) measured with KEMAR manikin for HD-25 supraaural headphones were extracted from @Wierstorf2011 HRTF database. The final mixed stimulus was filtered with the inverse HpTFs separately for the left and the right channel before being combined together as a final step. Every participant was presented with two runs, one for each listening condition (collocated/separated). Testing started following a practice phase of two runs for each of the test conditions with five BKB sentences each [@Bench1979]. Listeners were instructed to verbally repeat the target sentences to the experimenter who was situated alongside the participant in a sound treated chamber. The experimenter scored the response by selecting the correctly repeated keywords on the screen. Listeners were encouraged to guess if unsure while no feedback was given at any time. A loose keyword scoring method was used, whereby errors of case or declension were considered as correct responses. For example, a repetition of the keywords '$<$clown*s*$>$ $<$funny$>$ $<$face*s*$>$' to the stimulus 'The $<$clown$>$ had a $<$funny$>$ $<$face$>$'.

[^rmd-basics-cites-and-refs-1]: The database is available online in: <https://www.ece.ucdavis.edu/cipic/spatial-sound/hrtf-data/>

#### Speech-in-noise (SPIN)

The speech-in-noise test was used as a more realistic listening situation that is widely used in the clinic as opposed to more complex listening tasks as listed above. The normalised ASL sentences were presented in a speech-shaped-noise (SSN) with spectrum matched to the ASL corpus. The SSN onset was 500 ms before the target sentence begin. The exact same adaptive procedure as for the LiSNS-UK was used with the same stop-rules. Each listener was presented with a single run of 25 sentences following a practice phase with seven BKB sentences. The same test list and sentences order was used across all the listeners.

#### The Environmental Auditory Scene Analysis task (ENVASA)

In analogy to the classic 'cocktail-party' scenario, ENVASA is a non-linguistic paradigm [@Leech2009] that measures detection of everyday environmental sounds presented in naturalistic auditory scenes and can be used to asses IM effects as well as sustained selective auditory attention skills. In the task, short environmental target sounds (e.g., a "dog's bark", "door knock" or "bouncing ball") were presented in a dichotic background scene (i.e., the target sound is presented only in one ear) consisting of either a single background scene,presented in both ears, or two background scenes, each presented in a different ear. The number of targets, the onset time and presentation ear varied across trials. Four target/background SNRs were employed split into two categories 'low' (-6 and -3 dB) and 'high' (0 and +3 dB) by varying the target level. Target/background contextual agreement was manipulated by embedding the target sound in a *congruent* background scene that is in agreement with the listener's expectations (e.g., a cow's 'moo' in a farmyard scene) or in an *incongruent* background scene which violate these expectations (e.g., a cow's 'moo' in a traffic scene).

Procedure:

The experiment was carried out using the original code and laptop as used and described by @Leech2009. Sounds were presented via Sennheiser HD-25 headphones (REF) and the participants response was recorded using ???? gamepad. The output level was adjusted to a comfortable level before the test started. The participants were situated in front of the laptop placed on a desk and were instructed to hold the gamepad. Prior to the test begin the listeners were presented with a short child-friendly video covering the task's instructions and demonstrated two test trials. Following the instruction video, the examiner gave the child a short recap of the task's instructions and simulated with the child an exemplary trial to make sure the child is familiarised with the task. The task began with three practice trials with provided feedback, while no further feedback was given in the testing phase.

Every trial was made of two parts, starting with a target audio and visual familiarisation phase before the main target detection phase. Target identification was recorded by pressing one of the three buttons on the gamepad which corresponded to the location of the target objects on the screen. A response was counted as correct only if the participants pushed the corresponding button within 2 s time interval, 300 ms following the target onset. The outcome measure was calculated as the percentage of target sounds correctly identified within a condition (%-correct).

In total there were 115 target sounds presented over 40 trials, where 46 target sounds were presented in a single background condition and another 46 in a dual-background condition. The 23 remaining target sounds served as foil items where they were played at 0 dB SNR without a corresponding picture on the screen. The order of the foil items was quasi-randomised and were used to estimate the quality of the participants performance.

(ref:Leech2009) Schematic of the ENVASA experimental paradigm [taken from @Leech2009]

```{r, label='ENVASA', fig.cap="(ref:Leech2009)", out.width='65%', fig.align='center', echo=FALSE}

knitr::include_graphics("figures/ENVASAparadigm.png")
```

#### CELF-RS

The Recalling Sentences (RS) sub-test of the Clinical Evaluation of Language Fundamentals Fifth UK edition [CELF-5-UK @HWiig2017] was administered to assess the listeners expressive language ability and has been shown to be a good indicator of the listeners general language skills (REF). In the task the child is presented with pre-recorded sentences of increasing length and complexity and required to repeat sentences without any changes. Scoring were marked by hand by the examiner as instructed by the test manual. The sentences were spoken by a standard southern British English female and were recorded in a sound-treated recording booth at the SHaPS UCL laboratory, London. The sentences were presented using a MATLAB program via headphones using the same experimental equipment as listed above at a comfortable output level of 70 dB HL. The task began with two practice sentences while the number of test items varied depending on the child's age performance. No repetitions or feedback was given during the testing and the test was discontinued in case the child failed to score any points for four consecutive items. Age-scaled score were calculated based on the test norms with a mean score of 10 and SD of 3. Scaled scores within $\pm$ 1 SD from the norm mean (between 8 to 12) are classified as average scores, whereas performance beyond $\pm$ 1 SD are classified as above/below the average score. Thus, the cut-off for abnormally poor performance is a scaled score $\leq$ 7.

### Questionnaires

#### Medical, Neurological, and Pysiological History {.unnumbered}

#### The Evaluation pf Children's Listening and Processing Skills (ECLiPS) {.unnumbered}

The ECLiPS questionnaire [@Barry2014] comprises of 38 items where the users are asked to express their agreement simple statements about the child's listening and other related skills or behaviours using a five-point Likert scale (from "strongly agree" to "strongly disagree"). The ECLiPS was design to identify listening and communication difficulties in children aged 6 to 11 years. Nonetheless, the UK standardisation study (REF) found little to no age effect on scores in many of the scale items, suggesting the testing age could be extended below and beyond the population used for the development. Based on factor analysis the items are grouped into five subcategories: 1. Speech & Auditory Processing (SAP), 2. Environmental & Auditory Sensitivity (EAS), 3. Language, literacy & laterality (L/L/L), 4. Memory & Attention (M&A), 5. Pragmatic & Social skills (PSS). Age- and sex-scaled scores were computed using the test excel scorer.

A score below the 10$^{th}$ percentile (corresponding to a scale score of circa 6) is generally considered clinically significant.

```{=html}
<!--
In the results: compare scores with scores obtained by: https://www.nature.com/articles/s41598-018-25316-9.pdf and Moore et al. 2020 (Listening Difficulties in Children: Behavior and Brain Activation Produced by Dichotic Listening of CV Syllables)
-->
```
#### The Children's Communication Checklist 2$^{nd}$ edition (CCC-2) {.unnumbered}

Communication abilities were assessed using the Children's Communication Checklist second edition questionnaire [CCC-2; @D.V.M.2003] was completed by the child's parent/guardian. The CCC-2 was designed to screen communication problems in children aged 4 to 16 years and comprises of 70 checklist items each comprising of a behaviour statement like "Mixes up words of similar meaning". The respondents are asked to judge how often the behaviours occur using a four-point Likert rating scale: 0. *less than once a week (or never)*, 1. *at least once a week, but not every day*, 2. *once or twice a day*, 3. *several times (more than twice) a day (or always)*. The items are grouped into ten sub-scales of behaviours tapping into different skills (A. Speech, B. Syntax, C. Semantics, D. Coherence, E. Inappropriate initiation, F. Stereotyped language, G. Use of context, H. Non-verbal communication, I. Social relations, J. Interests). Taking the sum of scores for the sub-scales A to H are used to derive the General Communication Composite (GCC) which is used to identify clinically abnormal communication competence. A GCC score \< 55 was found by @Norbury2005 to well separate between control and clinical groups, identifying children with scores at the bottom 10%. Another composite (Social-Interaction Deviance Composite, SIDC) was taken by taking the difference in sum of scales E, H, I, and J from the sum of scales of A to D. Abnormal GCC (\< 55) combined with a negative SIDC score has been shown to be indicative of an autistic spectrum disorder profile [@D.V.M.2003]. The CCC-2 scaled and composite scores were computed using the test excel scorer. Data from one TD child out of forty four children was excluded from the analysis due to inconsistent reports flagged by the test scorer.

## Results

### Standard audiometry

```{r,label='stdAud', include=FALSE, warning=FALSE}
# ---------------------------------------------------------------------------------------------
# get thresholds by frequencies
# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "Freq"
valuecol <- "dBHL"
gathercols <- c("R250","R500","R1000","R2000", "R4000", "R8000",
                "L250","L500","L1000","L2000", "L4000", "L8000")
d_L <- gather_(d, keycol, valuecol, gathercols)

# get ear information as a new column
library(stringr)
d_L$Ear <- ifelse(str_detect(d_L$Freq,"R"),"R","L")
d_L$Ear <- factor(d_L$Ear,levels=c("R","L"))
# d_L$Freq <- transform(str_replace_all(d_L$Freq,c("R"="","L"="")))
d_L$Freq  <- as.factor(revalue(d_L$Freq, c("R250"="250","R500"="500","R1000"="1000","R2000"="2000",
                                           "R4000"="4000","R8000"="8000","L250"="250","L500"="500",
                                           "L1000"="1000","L2000"="2000","L4000"="4000","L8000"="8000")))
d_L$Freq <- factor(d_L$Freq,levels=c("250","500","1000","2000","4000","8000"))
# ---------------------------------------------------------------------------------------------

# get PTAs (0.5 + 1 + 2 + 4 kHz /4):
d <- d %>% group_by(listener) %>%
  dplyr::mutate(
    PTA_R = round(mean(c(R500,R1000,R2000,R4000),na.rm=TRUE),2),
    PTA_L = round(mean(c(L500,L1000,L2000,L4000),na.rm=TRUE),2),
    PTA_RL = round(mean(c(R500,R1000,R2000,R4000,L500,L1000,L2000,L4000),na.rm=TRUE),2)) %>%
  ungroup()

# get PTA in the better ear
d$PTA_BE <- ifelse((d$PTA_R <= d$PTA_L),d$PTA_R,d$PTA_L)

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "PTA"
valuecol <- "dBHL"
gathercols <- c("PTA_R","PTA_L","PTA_RL","PTA_BE")
d_PTA_L <- gather_(d, keycol, valuecol, gathercols)

d_PTA_L$PTA <- factor(d_PTA_L$PTA,levels=c("PTA_R","PTA_L","PTA_RL","PTA_BE"))

# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Frequency & Ear
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

Wilk_HL <- d_L %>%
  group_by(Freq,Ear) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_HL$CI <- sprintf("%.02f - %.02f",round(Wilk_HL$conf.low,2),round(Wilk_HL$conf.high,2))

Wilk_HL_effectSize <- d_L %>%
  group_by(Freq,Ear) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_HL_effectSize$effsize <- round(Wilk_HL_effectSize$effsize,3)

# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by PTA
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

Wilk_PTA <- d_PTA_L %>%
  group_by(PTA) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_PTA$CI <- sprintf("%.02f - %.02f",round(Wilk_PTA$conf.low,2),round(Wilk_PTA$conf.high,2))

Wilk_PTA_effectSize <- d_PTA_L %>%
  group_by(PTA) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_PTA_effectSize$effsize <- round(Wilk_PTA_effectSize$effsize,3)
# --------------------------------------------------------------------------------------------------
# get table:

### For frequencies ###
PTA_tab1 <- d_L %>% ddply(.,~Freq*Ear*Group,summarise,N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2))  %>% 
  arrange(., group_by = Group,Ear)
PTA_tab1 <- PTA_tab1[,-grep("Group",colnames(PTA_tab1))]
# APD first then TD
PTA_tab1 <- cbind(PTA_tab1[1:12,1:ncol(PTA_tab1)],PTA_tab1[13:nrow(PTA_tab1),3:ncol(PTA_tab1)])

### For PTA ###
PTA_tab <-  d_PTA_L %>% ddply(.,~PTA*Group,summarise,Ear = "", N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2))  %>% 
  arrange(., group_by = Group)
PTA_tab <- PTA_tab[,-grep("Group",colnames(PTA_tab))]
PTA_tab <- cbind(PTA_tab[1:4,1:ncol(PTA_tab)],PTA_tab1[5:nrow(PTA_tab),3:ncol(PTA_tab)])
PTA_tab$Ear <- c("R", "L","","")
PTA_tab$PTA <- c("PTA$_{Right}$","PTA$_{Left}$","PTA","BE")

# --------------------------------------------------------------------------------------------------
# combine table
HL_tab1 <- cbind(PTA_tab1,
                 "CI"=Wilk_HL$CI,"p"=round(Wilk_HL$p,2),
                 "effect size (r)"=round(Wilk_HL_effectSize$effsize,2),
                 "magnitude"=Wilk_HL_effectSize$magnitude)
colnames(HL_tab1)[1] = ""

HL_tab2 <- cbind(PTA_tab,
                 "CI"=Wilk_PTA$CI,"p"=round(Wilk_PTA$p,2),
                 "effect size (r)"=round(Wilk_PTA_effectSize$effsize,2),
                 "magnitude"=Wilk_PTA_effectSize$magnitude)
colnames(HL_tab2)[1] = ""

HL_tab <- rbind(HL_tab1,HL_tab2)
```

```{r, label='stdAud-fig', echo=FALSE,fig.cap="Add caption here.",fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%'}
### Frequencies ###
# New facet label names for Ear variable
Ear.labs <- c("Right", "Left")
names(Ear.labs) <- c("R","L")

t1 <- ggplot(d_L, aes(x=Freq,y=dBHL,fill=Group))+ 
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(40,-10),breaks=seq(40,-10,-5))+
  #geom_text(label=d_HF_Cmpr_L$listener)+
  labs(y = "dB HL",x = "Frequency in Hz")+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ Ear, scales = "free", switch = "y", labeller = labeller(Ear = Ear.labs))+
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

### PTA ###
t2 <- ggplot(d_PTA_L, aes(x=PTA, y=dBHL, fill=Group),show.legend=FALSE) +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(15,-5),breaks=seq(15,-5,-5))+
  labs(y = "dB HL",x = "") + 
  scale_x_discrete(labels=c("PTA_R"=expression(bold(PTA[Right])),"PTA_L"=expression(bold(PTA[Left])),
                            "PTA_RL"=expression(bold("PTA")),"PTA_BE"=expression(bold("BE"))))+
  # scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.text.x = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.4)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='stdAud-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
HL_tab$p = ifelse(HL_tab$p<.05,sprintf("\\textbf{%.02f}",HL_tab$p),HL_tab$p)

kbl(HL_tab, booktabs = T, escape = F, caption = "Standard audiometry descriptive and test statistics for group differences tested using Wilcoxon rank-sum test for unpaired samples[note]. PTA$_{Right}$ and PTA$_{Left}$ were calculated by taking the individual mean for thresholds at 0.5, 1, 2 and 4\ kHz in the respective ear. PTA denotes the listeners grand-mean for PTAs in both ears and BE represents the listeners PTA at the better-ear.",
    align = c("lccccccccc")) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" "=2, "APD" = 5, "TD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(c(8,13),border_left = T) %>% 
  column_spec(14:15, italic = T) %>%
  kable_styling() %>%
  pack_rows("octave frequency bands", 1, 12) %>%
  pack_rows("PTAs and better-ear", 13, 16)
```

```{r,label='stdAud-analysis', eval=FALSE, include=FALSE}

model1 <- lmer(dBHL ~ Ear * Freq * Group * Age  + (1|listener), d_L, REML=FALSE)
model2 <- lmer(dBHL ~ Ear * Freq * Group + (1|listener), d_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear * Freq + (1|listener), d_L, REML=FALSE)
anova(model2,model3)

summary(model2)
tab_model(model2)


model1 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 Ear : Freq : Group +
                 (1|listener), d_L, REML=FALSE)

model2 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 (1|listener), d_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 (1|listener), d_L, REML=FALSE)
anova(model2,model3)
model4 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 (1|listener), d_L, REML=FALSE)
anova(model3,model4)

summary(model3)
tab_model(model3)

Anova(model3,type="II",test.statistic="Chisq")

anova(lm(dBHL ~ Ear * Freq * Group * Age, data = d_L))


# WilkTest <- d_L %>%
#   group_by(Freq) %>%
#   rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE,detailed=TRUE,conf.level = 0.95) %>%
#   rstatix::adjust_pvalue(method = "bonferroni") %>%
#   rstatix::add_significance("p.adj")

PTA_R <- d_PTA_L %>% filter(PTA=="PTA_R") %>% droplevels()
PTA_L <- d_PTA_L %>% filter(PTA=="PTA_L") %>% droplevels()
PTA_RL <- d_PTA_L %>% filter(PTA=="PTA_RL") %>% droplevels()
PTA_BE <- d_PTA_L %>% filter(PTA=="PTA_BE") %>% droplevels()

anova(lm(dBHL ~ Group * Age, data = PTA_R))
anova(lm(dBHL ~ Group * Age, data = PTA_L))
anova(lm(dBHL ~ Group * Age, data = PTA_RL))
anova(lm(dBHL ~ Group * Age, data = PTA_BE))

```

```{r eval=FALSE, fig.align='center', fig.asp=0.5, fig.cap="Add caption here.", fig.width=12, message=FALSE, warning=FALSE, include=FALSE, label='stdAud-PTA', out.width='100%'}
# PTAs by age
t1 <- ggplot(d_PTA_L, aes(x=Age, y=dBHL, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm , fill="#69b3a2", se=TRUE) +
  stat_cor(method = "kendall", cor.coef.name = "tau", aes(color = Group), label.x = 8, label.y = c(5,3.5), 
na.rm = TRUE) +
  stat_regline_equation(label.y = c(-14.2,-15))+
  scale_y_reverse() +
  labs(y = "dB HL",x = "Age (in years)") + 
  # scale_y_continuous(limits = c(-15,12),breaks=seq(-15,12,2)) +
  #scale_y_continuous(limits = c(-15,5),breaks=seq(-15,5,2)) +
  #scale_x_continuous(limits = c(min(AgeNum)-2,max(AgeNum)+2),breaks=seq(min(AgeNum)-2,max(AgeNum)+2,1)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom")

t1 <- t1 + facet_grid(. ~ PTA, scales = "free", switch = "y") +
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))
t1
```

Boxplots of listeners thresholds measured with a standard audiometer at the six octave frequency bands (0.25 to 8 kHz) and their corresponding PTAs are shown in Figure \@ref(fig:stdAud-fig) A-B. The listeners PTAs were calculated separately for the right and left ear (PTA$_{Right}$, PTA$_{Left}$) by taking the mean of thresholds at the frequency bands 0.5, 1, 2 and 4 kHz which are known to be important for speech perception (REF WHO). PTA denotes the listeners grand-mean for PTAs in both ears, form a single measure for the listeners hearing ability, and BE represents the listeners PTA at the better-ear. Descriptive statistics is given in Table \@ref(tab:stdAud-tab), split by groups.

[Do the groups differ in their hearing abilities?]{.correction}  
- To report Wilcoxon or LMEM test? - Wilcoxon test and LMEM found a significant difference between the groups for thresholds in the left ear. Nonetheless, the differences are rather small and clinically negligible, and there is no reason to assume this difference occurred by random.

### Extended high-frequency audiometry (EHFA)

```{r, include=FALSE, warning=FALSE}
d_HF<- read.csv(file.path(FileDir,'Files','EHF_Audiogram_12082020.csv'),header=T) 

d_HF <- merge(d_Info,d_HF,by=c("listener"))
#d_HF <- d_HF[,-match(c("Group.y"),names(d_HF))]
#colnames(d_HF)[2] = "Group"
d_HF$Group <- factor(d_HF$Group,levels=c("TD","APD"))
cols <- c("AuditoryTraining","EarProblems","EarProblemsDur","SLT","Grommets","MusicalTraining","FMuse","NrmlSpchUnderstanding")
d_HF[cols] <- lapply(d_HF[cols], factor)

# Include only HF thresholds ---------------------------------------------------------------------------------------------------

# add Age to the dataframe
d_HF <- d %>%
  select(listener, Age) %>%
  left_join(d_HF, ToAdd, by = "listener")

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "Freq"
valuecol <- "dBHL"
gathercols <- c("R11000","R16000","L11000","L16000")
d_HF_L <- gather_(d_HF, keycol, valuecol, gathercols)
# -------------------------------------------------------------- 
# get ear information as a new column
library(stringr)
d_HF_L$Ear <- ifelse(str_detect(d_HF_L$Freq,"R"),"R","L")
d_HF_L$Ear <- factor(d_HF_L$Ear,levels=c("R","L"))

# set levels
d_HF_L$Freq <- factor(d_HF_L$Freq,levels=c("R11000","R16000","L11000","L16000"))
d_HF_L$Freq  <- revalue(d_HF_L$Freq , c("R11000"="11000", "R16000"="16000",
                                        "L11000"="11000", "L16000"="16000"))
d_HF_L$Freq <- factor(d_HF_L$Freq,levels=c("11000","16000"))
d_HF_L$Group <- factor(d_HF_L$Group,levels=c("APD","TD"))
```

```{r, label='EHF-stats', include=FALSE}
# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Frequency & Ear
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

# remove na's
d_HF_L<- drop_na(d_HF_L,dBHL) %>% droplevels()

Wilk_EHF <- d_HF_L %>%
  group_by(Freq,Ear) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_EHF$CI <- sprintf("%.02f - %.02f",round(Wilk_EHF$conf.low,2),round(Wilk_EHF$conf.high,2))

Wilk_EHF_effectSize <- d_HF_L %>%
  group_by(Freq,Ear) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_EHF_effectSize$effsize <- round(Wilk_EHF_effectSize$effsize,2)

# --------------------------------------------------------------------------------------------------
# get table:
# For frequencies
PTA_tab1 <- d_HF_L %>% ddply(.,~Freq*Ear*Group,summarise,N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2)) %>% arrange(., group_by = Group,Ear)
PTA_tab1 <- PTA_tab1[,-grep("Group",colnames(PTA_tab1))]
PTA_tab1 <- cbind(PTA_tab1[1:4,1:ncol(PTA_tab1)],PTA_tab1[5:nrow(PTA_tab1),3:ncol(PTA_tab1)])

# --------------------------------------------------------------------------------------------------

# get PTAs:
# EHF
d_HF <- d_HF %>% group_by(listener) %>%
  dplyr::mutate(
    PTA_R = round(mean(c(R11000,R16000),na.rm=TRUE),2),
    PTA_L = round(mean(c(L11000,L16000),na.rm=TRUE),2),
    PTA_RL = round(mean(c(R11000,R16000,L11000,L16000),na.rm=TRUE),2)) %>%
  ungroup()

# get PTA in the better ear
d_HF$PTA_BE <- ifelse((d_HF$PTA_R <= d_HF$PTA_L),d_HF$PTA_R,d_HF$PTA_L)
d_HF <- drop_na(d_HF, Group) %>% droplevels()

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "PTA"
valuecol <- "dBHL"
gathercols <- c("PTA_R","PTA_L","PTA_RL","PTA_BE")
d_HF_PTA_L <- gather_(d_HF, keycol, valuecol, gathercols)

d_HF_PTA_L <- drop_na(d_HF_PTA_L, dBHL) %>% droplevels()
d_HF_PTA_L$PTA <- factor(d_HF_PTA_L$PTA,levels=c("PTA_R","PTA_L","PTA_RL","PTA_BE"))
d_HF_PTA_L$Group <- factor(d_HF_PTA_L$Group,levels=c("APD","TD"))
# --------------------------------------------------------------------------------------------------
# Compare group difference for PTAs
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------
Wilk_EHF_PTA <- d_HF_PTA_L %>%
  group_by(PTA) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_EHF_PTA$CI <- sprintf("%.02f - %.02f",round(Wilk_EHF_PTA$conf.low,2),round(Wilk_EHF_PTA$conf.high,2))

Wilk_EHF_PTA_effectSize <- d_HF_PTA_L %>%
  group_by(PTA) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_EHF_PTA_effectSize$effsize <- round(Wilk_EHF_PTA_effectSize$effsize,2)

# --------------------------------------------------------------------------------------------------
# get table:
### For PTA ###
PTA_tab <-  d_HF_PTA_L %>% ddply(.,~PTA*Group,summarise,Ear = "", N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
PTA_tab <- PTA_tab[,-grep("Group",colnames(PTA_tab))]
PTA_tab <- cbind(PTA_tab[1:4,1:ncol(PTA_tab)],PTA_tab[5:nrow(PTA_tab),3:ncol(PTA_tab)])
PTA_tab$Ear <- c("R", "L","","")
PTA_tab$PTA <- c("PTA$_{Right}$","PTA$_{Left}$","PTA","BE")

# --------------------------------------------------------------------------------------------------
# combine table
EHF_tab1 <- cbind(PTA_tab1,
                 "CI"=Wilk_EHF$CI,"p"=round(Wilk_EHF$p,2),
                 "effect size (r)"=round(Wilk_EHF_effectSize$effsize,2),
                 "magnitude"=Wilk_EHF_effectSize$magnitude)
colnames(EHF_tab1)[1] = ""

EHF_tab2 <- cbind(PTA_tab,
                 "CI"=Wilk_EHF_PTA$CI,"p"=round(Wilk_EHF_PTA$p,2),
                 "effect size (r)"=round(Wilk_EHF_PTA_effectSize$effsize,2),
                 "magnitude"=Wilk_EHF_PTA_effectSize$magnitude)
colnames(EHF_tab2)[1] = ""

EHF_tab <- rbind(EHF_tab1,EHF_tab2)
```

```{r, label='EHFAud-fig', echo=FALSE,fig.cap="Add caption here.",fig.align='center', fig.width=10, fig.asp=0.5, out.width='100%'}
### Frequencies ###

# New facet label names for Ear variable
Ear.labs <- c("Right", "Left")
names(Ear.labs) <- c("R","L")
d_HF_L$Group <- factor(d_HF_L$Group,levels=c("APD","TD"))

t1 <- ggplot(d_HF_L, aes(x=Freq,y=dBHL,fill=Group),show.legend=FALSE)+ 
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(45,-5),breaks=seq(45,-5,-5))+
  #geom_text(label=d_HF_Cmpr_L$listener)+
  labs(y = "dB HL",x = "Frequency in Hz")+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ Ear, scales = "free", switch = "y", labeller = labeller(Ear = Ear.labs))+
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

### PTA ###
d_HF_PTA_L$Group <- factor(d_HF_PTA_L$Group,levels=c("APD","TD"))
t2 <- ggplot(d_HF_PTA_L, aes(x=PTA, y=dBHL, fill=Group),show.legend=FALSE) +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(45,-5),breaks=seq(45,-5,-5))+
  labs(y = "dB HL",x = "") + 
  scale_x_discrete(labels=c("PTA_R"=expression(bold(PTA[Right])),"PTA_L"=expression(bold(PTA[Left])),
                            "PTA_RL"=expression(bold("PTA")),"PTA_BE"=expression(bold("BE"))))+
  # scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(0.6,0.4)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='EHF-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
EHF_tab$p = ifelse(EHF_tab$p<.05,sprintf("\\textbf{%.02f}",EHF_tab$p),EHF_tab$p)

kbl(EHF_tab, booktabs = T,escape = F,caption = "Extended high frequency hearing screening descriptive statistics and group difference analysis by frequency and ear or PTA.",
    align = c("lccccccccc"),format = "latex") %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 2, "APD" = 5, "TD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
  column_spec(c(8,13),border_left = T) %>% 
  column_spec(14:15, italic = T) %>%
  kable_styling() %>%
  pack_rows("octave frequency bands", 1, 4) %>%
  pack_rows("PTAs and better-ear", 5, 8)
```

```{r,label='EHF-analysis', eval=FALSE, include=FALSE}

# model1 <- lmer(dBHL ~ Ear * Freq * Group * Age  + (1|listener), d_HF_L_EHF, REML=FALSE)
# model2 <- lmer(dBHL ~ Ear * Freq * Group  + (1|listener), d_HF_L_EHF, REML=FALSE)
# anova(model1,model2)
# model3 <- lmer(dBHL ~ Ear * Freq + (1|listener), d_HF_L_EHF, REML=FALSE)
# anova(model2,model3)
# 
# summary(model2)
# tab_model(model2)


model1 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 Ear : Freq : Group +
                 (1|listener), d_HF_L, REML=FALSE)

model2 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model2,model3)
model4 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model3,model4)
model5 <- lmer(dBHL ~ Ear + Freq + Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model4,model5)
model6 <- lmer(dBHL ~ Ear + Freq +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model5,model6)
model7 <- lmer(dBHL ~ Ear +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model6,model7)

summary(model6)
tab_model(model6)

Anova(model5,type="II",test.statistic="Chisq")

anova(lm(dBHL ~ Ear * Freq * Group * Age, data = d_L))


# WilkTest <- d_L %>%
#   group_by(Freq) %>%
#   rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE,detailed=TRUE,conf.level = 0.95) %>%
#   rstatix::adjust_pvalue(method = "bonferroni") %>%
#   rstatix::add_significance("p.adj")
```

The listeners' thresholds measured with the ER10X at the EHFs 11 and 16 kHz are plotted in Figure \@ref(fig:EHF) for the left and the right ear. The shaded grey area represents the TD group thresholds range and the white line represents their mean at each frequency. The black lines represents the individual thresholds in the APD group and the group mean is marked by the bold black line. A comparison of the group means indicates that the differences in thresholds are small. Again, boxplots of the listeners thresholds by frequency and ear as well as PTAs are shown in Figure \@ref(fig:EHFAud-fig) A-B. Descriptive statistics and Wilcoxon rank-sum test outcomes for group comparison (unpaired samples) is given in Table \@ref(tab:EHF-tab), split by groups.

[Difference between groups]{.correction} Difference in thresholds between the groups across frequencies (11 & 16 kHz) and ears (left/right) as well as for the calculated PTA and BE measures were tested using a Wilcoxon rank-sum test for unpaired samples ('rstatix::wilcox_test' with bonferroni adjustment; REF). No significant difference was found between the groups for all thresholds (all p\>.05; see Table \@ref(tab:EHF-tab)). A LMEM model with **frequency** and **ear** as fixed factors showed similar results and thus was not reported here.

<!-- [Difference in HL between audiogram types?]{.correction}  -->

<!-- First, the quality(?) of the thresholds measured with the non-standard ER10X audiogram was tested by comparing the individuals thresholds with those obtained with the standard audiometer. This was tested group-wise for thresholds at 8\ kHz measured in the left and the right ear using Wilcoxon signed rank test for paired samples ('rstatix::wilcox_test' with bonferroni adjustment; REF). The test showed a significant difference in thresholds between the two audiogram type for the TD group in both right (p=`r round(Wilk_EHF$p.adj[1],3)`, effect size r=`r round(Wilk_EHF_effectSize$effsize[1],3)`) and the left ear (p=`r round(Wilk_EHF$p.adj[2],3)`, r=`r round(Wilk_EHF_effectSize$effsize[2],3)`). No significant difference was found in the APD group in both ears (right: p=`r round(Wilk_EHF$p.adj[3],3)`, r=`r round(Wilk_EHF_effectSize$effsize[3],3)`; left: p=`r round(Wilk_EHF$p.adj[4],3)`, r=`r round(Wilk_EHF_effectSize$effsize[4],3)`).  -->

```{r, label='EHF', fig.cap="APD participants pure-tone thresholds for extended high-frequencies plotted for the left and the right ear (black). The shaded grey area represents the TD group range of audiometric thresholds and the white line represents the mean at each frequency.", echo=FALSE, fig.align='center', figures-side, out.width='85%',fig.width=12, fig.height=6}
d_HF <- data.frame(d_HF)
# Define axes
# xaxis=c(1:4) # number of frequencies tested
# 11000 16000
FreqAxis = c("11","16")
frqs=c(11,16)

# min and max of y axis
max	=	max((d_HF[1:nrow(d_HF),35:36]),na.rm=T) + 17
min	=	min(d_HF[1:nrow(d_HF),35:36],na.rm=T) - 10

# Plot overlapping individual audiograms of test group, mean of test group, and mean +/- 1 sd of control group
# Assumes test group and control group are in same .csv file (different columns)

TD = d_HF[grep("TD", d_HF[,27]),] 	#control group (Group is in column 29)
APD = d_HF[grep("APD", d_HF[,27]),] #test group

# plot left and right ear
#layout(matrix(c(1:2), 1, 2, byrow = TRUE))
par(mfrow=c(1,2),mar=c(0,0,0,1.5),oma=c(7,7,1,1))

for (j in 1:2){
  
  # create empty plot
  plot(frqs,xlim=c(frqs[1],max(frqs)),type="n",axes=FALSE,ann=FALSE,ylim=rev(range(c(min,max))),log = "x")
  box()
  
  mtext(outer=T,side=1,line=3,text="frequency (kHz)",cex=1.5)		
  mtext(outer=T,side=2,line=3,text="threshold (dB HL)",cex=1.5)	
  
  if (j<=1){
    axis(2,col="black",cex.axis=1.5)
    text(14,-8,"Left",cex=1.5)
  }  else {
    text(14,-8,"Right",cex=1.5)
  }
  
  axis(1,at=frqs,lab=FreqAxis,cex.axis=1.5)
  
  # if (j<=1){
  #   axis(2,at=c(0,10,20,30,40,50,60),cex.axis=1.5)
  # }
  
  # if (j<=1) {
  #   numCol = 14:21
  # } else {
  #   numCol = 6:13
  # }
  
  if (j<=1) {
    numCol = 35:36
  } else {
    numCol = 44:45
  }
  # calculate mean for test group
  avg<-vector()
  for (i in numCol){
    avg[i-(numCol[1]-1)]<-mean(APD[1:length(APD[,1]),i],na.rm=T)
  }
  
  ## calculate mean and sd for control group
  stdev <- vector()
  mn <- vector()
  for (i in numCol){
    stdev[i-(numCol[1]-1)]<-sd(TD[1:length(TD[,1]),i],na.rm=T)
    mn[i-(numCol[1]-1)]<-mean(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate min and max for control group
  mnn <- vector()
  mx <- vector()
  for (i in numCol){
    mnn[i-(numCol[1]-1)]<-min(TD[1:length(TD[,1]),i],na.rm=T)
    mx[i-(numCol[1]-1)]<-max(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate upper and lower boundaries of shaded area
  upper <- mnn
  lower <- mx
  
  # plot shaded area (mean +/- 1 sd)
  xx <- c(frqs, rev(frqs))
  yy <- c(lower,rev(upper))
  polygon(xx, yy, col="lightgrey",border=NA)
  
  # plot individual audiograms test group
  for (i in 1:length(APD[,1])){
    lines(frqs,APD[i,numCol])
  }
  
  # plot mean control group
  lines(frqs,mn,col="white",lwd=4)
  
  # plot mean test group
  lines(frqs,avg,lwd=4, col="black")
  
  if (j<=1){
    yplot <- 50
    # plot legend
    legend(11,yplot, c("Mean APD","Individual APD","Mean and range TD"),lty=c(1,1,1),lwd=c(3,1,8),col=c("black","black","lightgrey"),cex=0.8,bty=0,box.col="white")
    #legend(.25,yplot, c("Mean older adults","Individual older adults","Mean and range young adults"),lty=c(1,1,1),lwd=c(3,1,1),col=c("black","black","white"),cex=1.3,box.col="white")
    
    segments(x0 = 11, y0 = 58.5, x1 = 11.4, y1 = 58.5,col = "white", lwd = 3)
  }
}
```

### Switching task (ST)

#### Data Analysis {.unnumbered}
[*Outliers & missing data*]{.correction}
```{r, eval=FALSE, include=FALSE}
# ASL <- read.csv(file.path(FileDir,"Files",'ST-ASL_2020-08-19.csv'),header=T)
# CCRM <- read.csv(file.path(FileDir,"Files",'ST-CCRM_2020-08-19.csv'),header=T)
# 
# if (RmvSubj==1){ASL <- ASL[ ! ASL$listener %in% Subj2Remove, ] %>% droplevels()}
# 
# graphics::hist(LevsPC~CondCode,data=ASL)
# 
# ASL$LevsPC_p2 <- ifelse(ASL$LevsPC<=.36,ASL$LevsPC_p*-1,ASL$LevsPC_p)
# 
# ASLOutliers <- ASL[which(ASL$LevsPC_p2<=0),]
# hist(LevsPC~CondCode,data=ASLOutliers)

# CCRM ---------------------------------------------------------------------------------
# hist(LevsPC~CondCode,data=CCRM)
#
# # flag p-values as negative for LevsPC <= .36
# CCRM$LevsPC_p2 <- ifelse(CCRM$LevsPC<=.36,CCRM$LevsPC_p*-1,CCRM$LevsPC_p)
#
# CCRMOutliers <- CCRM[which(CCRM$LevsPC_p2<=0),]
# hist(LevsPC~CondCode,data=CCRMOutliers)
#
# knitr::kable(CCRMOutliers) %>%
#   kable_styling() %>%
#   scroll_box(width = "100%", height = "400px")
#
# hist(LevsPC~CondCode,data=CCRMOutliers)
```

As a first step, the listeners adaptive track and psychometric functions (PF) were manually inspected for abnormalities. The proportion of correct keywords within the final test trials (LevsPC) was calculated as a measure describing the success of the adaptive procedure. Since the adaptive procedure was set to yield 50\%-correct, a successful procedure is expected to be within the 50\% range. A binomial statistical test was applied to identify observations that significantly differ from 50\%. Observations with LevsPC $\leq$ 35\% were flagged as possible outliers and were further inspected (see Figure ??). Interestingly, the majority of the flagged cases belonged to the CCRM test condition where targets were presented with a competing CCRM-type sentences (CCRM_F). Three observations out of 215 (5 conditions x 43 listeners) were flagged for data measured with the ASL corpus, and 29 observations out of 258 (6 conditions x 43 listeners) were flagged for data measured with the CCRM corpus. As expected, most of the identified cases were for observations measured with the more demanding conditions with speech distractors (see Figure ??). In five cases (2 ASL; 3 CCRM) we were able to confidently determine that the listener's true score was near to ceiling, and thus these observations were set to the maximum DC (0.97). In other cases it was not possible to confidently determine the true SRdT, either because the maximum number or trials were presented before a minimum number of test reversals were obtained (CCRM\ =\ 1; ASL\ =\ 2), or due to aberrant adaptive tracks (CCRM\ =\ 5). Since all these cases belonged to more challenging test conditions with speech distractors, it is very likely that the children's true score is at celling. Thus, to account that, rather than removing these observations, which will consequently reduce the statistical power, they were set to a DC of 1, which is above the task's upper DC limit of 0.97.

[*Regression lines + z-scores*]{.correction}
<!-- For further analysis, listener-specific age-independent scores were estimated using a linear regression model. The model was fitted separately for each test version (ASL/CCRM) per test condition and was estimated from the TD data only with %-correct as the dependent variable and age as a predictor. Standard residuals were calculated for each listener, based on the model prediction, resulting in age-independent residuals that are comparable to z-scores for data with normal distribution, with a mean and SD of approximately 0 and 1, respectively. Since the main goal of the study was to find a measure that is able to well separate between the APD group and the typically developed control group, individual differences and group differences were explored using a deviance analysis procedure proposed by @Ramus2003. Abnormal scores were defined by a deviance cut-off of $\pm$ 1.65 SD from the TD group mean. Thus, circa 90\% of the normal population residuals are expected to be within the deviance range of $\pm$ 1.65. Occasional occurrence of abnormal scores in the normal population is not unusual in behavioural measures. Therefore, since the prediction of the residuals is based on the control data, such outliers may skew the TD group true mean or SD and thus may introduce an error in the model prediction. For this reason, the procedure included two steps: i. following the initial estimation of the listeners residuals, outliers in the TD group were identified and trimmed from the data set (outside mean $\pm$ 1.65); ii. next, the linear regression was reapplied for the 'trimmed' TD group and standardised residuals were recalculated for all the listeners, including the trimmed TD observations.   -->

Age-independent scores were estimated using a linear regression model. The model was fitted condition-wise separately for each test version (ASL/CCRM) and was based on the control group data only with %-correct as the dependent variable and age as a predictor. A two-steps model comparison was performed to test the assumption that performance displays a monotonic linear relationship with age versus a non-monotonic (segmented) linear relationship. Extreme outliers were initially trimmed from the TD group to reduce noise in the data and to improve the models fit. In the first step, both models were computed and the best model was selected based on F-statistic model comparison using analysis of variance **anova()** test. Standard residuals were next calculated for each TD listener, based on the selected model prediction. The standardised residuals are age-independent and are comparable to z-scores for data with normal distribution, with a mean and SD of approximately 0 and 1, respectively. Since the main goal of the study was to find a measure that is able to well separate between the APD group and the typically developed control group, individual differences and group differences were explored using a deviance analysis procedure proposed by @Ramus2003. Abnormal scores were defined by a two-tailed deviance cut-off of $\pm$ 1.96 SD from the TD group mean. Thus, circa 95\% of the normal population residuals are expected to be within the deviance range of $\pm$ 1.96. Occasional occurrence of abnormal scores in the normal population is not unusual in behavioural measures. Therefore, since the prediction of the residuals is based on the control data, such outliers may skew the TD group true mean or SD and thus may introduce an error in the model prediction. Therefore, in the second step, additional TD outliers (with standardised residuals below/above TD mean $\pm$ 1.96) were trimmed from the data and the two models were refitted and compared again. Finally, the model with the best fit was selected and was used to calculate the standardised residuals for all the listeners, including the trimmed TD observations and the APD group.

[*Age effect*]{.correction}  
  
The effect of age was analysed using the trimmed TD group data only. This is because the control group is more heterogeneous, and thus we expect performance in the TD group to be less variable than in the APD group. A repeated measures factorial design LMEM model was used with Condition, Material (ASL/CCRM) and Age as fixed factors, SRdT as dependent variable and a random intercept for subjects. A model without three-way interaction between the main effects was found to give the best fit. Inspection of the data revealed that the assumption of normal distribution (Shapiro Wilk test) was met, whereas the assumption of homogeneity of variance (Levene's test) was marginal (*p=0.04*). 

[*Group, material and condition differences for z-scores*]{.correction}  
A 2x2x5 factorial design model with repeated measures was used to determine the effects of Group, Condition and Material as well as their interaction on the age-independent calculated z-scores. Residual analysis of a three-way ANOVA test was performed to determine if the model fulfils parametric methods assumptions. Shapiro-Wilk normality test (REF) rejected the assumption that the residuals were normally distributed, while the assumption of homoscedasticity was met (p\>\ 0.05; Levene's test, REF).

Due to the violation of normality and possible sphericity violations a nonparametric method was performed using nparLD package (REF) which is a robust rank-based method for analysis of skewed data or with outliers or from a small sample size (REF J. Feys, 2016 New parametric TankTest). The analysis was based on a f2-ld-f1 design ANOVA-type statistic (ATS) test, whereby f2 refers to an experimental design with two between-subjects factors (Group \& Material) and f1 refers to a single within-subjects factor (Condition).

other tests were considered and delivered the same results!! 
```{r,label='ST-getData', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
# remove(ASL)
# remove(CCRM)

# Load DC data ------------------------------------------------------------------
d_ST<- read.csv(file.path(FileDir,'Files',"ST_2020-10-28.csv"),header=T) 

# merge the two dataframes
d_ST <- merge(d_ST,d,by=c("listener","Group"))

## LONG format ---------------------------------------------
# material is grouped together
d_ST$CondCode <- factor(d_ST$CondCode,levels=c("Q-ASLN-NoAlt","Q-ASLN-Alt","AMSSN-ASLN-Alt","MDR_F-ASLN-Alt","ENG_F-ASLN-Alt",
                                               "Q-CCRM-NoAlt","Q-CCRM-Alt","AMSSN-CCRM-Alt","MDR_F-CCRM-Alt","ENG_F-CCRM-Alt","CCRM_F-CCRM-Alt"))

levels(d_ST$Background)
d_ST$Background <- factor(d_ST$Background,levels=c("Quiet","AMSSN", "MDR_F", "ENG_F", "CCRM_F"))
levels(d_ST$ear)
d_ST$ear <- factor(d_ST$ear,levels=c("B","A"))
levels(d_ST$material)
d_ST$Group <- factor(d_ST$Group,levels=c("APD","TD"))

# Filter data by material --------------------------------------------------------------------------------------------
ASLN <- d_ST %>% filter(material=="ASLN") %>% droplevels() # Only ASLN
CCRM <- d_ST %>% filter(material=="CCRM") %>% droplevels() # Only CCRM

# Clean data ---------------------------------------------------------------------------------------------------------

# Remove subjects with no uRev:
# ASL:
ASLN[is.na(ASLN$uRevs),] # APD10: Run 2 & 3
# remove rows with missing data
# ASLN <- drop_na(ASLN, uRevs) %>% droplevels()

# CCRM:
CCRM[is.na(CCRM$uRevs),] # APD12: Run 5
# remove rows with missing data
# CCRM <- drop_na(CCRM, uRevs) %>% droplevels()

```

```{r,label='ST-z-ASL',fig.align='center', fig.width=6, fig.asp=1.5, out.width='100%', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
#########################################
##   get z-scores by speech material   ##
#########################################

# fit individual models with and without a knot per condition & group and compare them:
source("Functions/getBestFit.R")

# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # Output[[11]] : TD trimmed data
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
TempRemove_ASL <- c("TD11_T_Run3_Q-ASLN-NoAlt_none_0dB_16-Nov-2019_14-33_ASL.csv",
                  "TD04_T_Run1_Q-ASLN-NoAlt_none_0dB_02-Jun-2019_12-13_ASL.csv",
                  "TD11_T_Run4_Q-ASLN-Alt_none_0dB_16-Nov-2019_14-35_ASL.csv",
                  "TD11_T_Run1_AMSSN-ASLN-Alt_0dB_16-Nov-2019_14-23_ASL.csv",
                  "TD04_T_Run2_AMSSN-ASLN-Alt_0dB_02-Jun-2019_12-15_ASL.csv")
ASLN$TempRmv <- ifelse((ASLN$fileName %in% TempRemove_ASL)==TRUE,1,0)


### Q-NoAlt ###
df <- ASLN %>% filter(CondCode=="Q-ASLN-NoAlt" & Group=="TD" & TempRmv <1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(ASLN,"Q-ASLN-NoAlt",CutOff,slope1_temp,int1_temp,8,05)
df_1 <- Output[[1]]  # df_All
TD_trimmed_1 = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
Slopes.ASLN <- NULL
Slopes.ASLN["Q-ASLN-NoAlt"] <- FinalM_1$m$getPars()[1]
# anova.ST <- NULL
# anova.ST[["Q-ASLN-NoAlt"]] <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary()
Lstats_1 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_1$listener[which(df_1$Group=="TD")]
B <- TD_trimmed_1$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_1 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

### Q-Alt ###
df <- ASLN %>% filter(CondCode=="Q-ASLN-Alt" & Group=="TD" & TempRmv <1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(ASLN,"Q-ASLN-Alt",CutOff,slope1_temp,int1_temp,10)
df_2 <- Output[[1]]  # df_All
TD_trimmed_2 = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))
Slopes.ASLN["Q-ASLN-Alt"] <- FinalM_2$m$getPars()[1]

# anova.ST[["Q-ASLN-Alt"]] <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary()
Lstats_2 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_2$listener[which(df_2$Group=="TD")]
B <- TD_trimmed_2$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_2 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

### AMSSN-Alt ###
Output <- getBestFit(ASLN,"AMSSN-ASLN-Alt",CutOff)
df_3 <- Output[[1]]  # df_All
TD_trimmed_3 = Output[[11]]
FinalM_3<- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))
Slopes.ASLN["AMSSN-ASLN-Alt"] <- FinalM_3$m$getPars()[1]

# anova.ST[["AMSSN-ASLN-Alt"]] <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary()
Lstats_3 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_3$listener[which(df_3$Group=="TD")]
B <- TD_trimmed_3$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_3 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

### MDR-Alt ###
Output <- getBestFit(ASLN,"MDR_F-ASLN-Alt",CutOff)
df_4 <- Output[[1]]  # df_All
TD_trimmed_4 = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
MDR.formula <- FinalM_4$m$formula()
L4<- sprintf("slope = %s, intcpt = %s, brk = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2),
             round(FinalM_4$m$getAllPars()[3],2))
Slopes.ASLN["MDR_F-ASLN-Alt"] <- FinalM_4$m$getPars()[1]
# anova.ST[["MDR_F-ASLN-Alt"]] <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary()
Lstats_4 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_4$listener[which(df_4$Group=="TD")]
B <- TD_trimmed_4$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_4 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

### ENG-Alt ###
Output <- getBestFit(ASLN,"ENG_F-ASLN-Alt",CutOff)
df_5 <- Output[[1]]  # df_All
TD_trimmed_5 = Output[[11]]
FinalM_5 <- if(Output[[8]]==1){FinalM_5=Output[[6]]}else{FinalM_5=Output[[7]]}
L5<- cbind("slope"=FinalM_5$m$getAllPars()[1],"intcpt"=FinalM_5$m$getAllPars()[2])
L5<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_5$m$getAllPars()[1],2),
             round(FinalM_5$m$getAllPars()[2],2))
Slopes.ASLN["ENG_F-ASLN-Alt"] <- FinalM_5$m$getPars()[1]
# anova.ST[["ENG_F-ASLN-Alt"]] <- lm(FinalM_5$m$formula(),data=TD_trimmed_5) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_5$m$formula(),data=TD_trimmed_5) %>% summary()
Lstats_5 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_5$listener[which(df_5$Group=="TD")]
B <- TD_trimmed_5$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_5 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

## combine all conditions together
FinalM.ASL <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4,FinalM_5)
ASLN <- rbind(df_1,df_2,df_3,df_4,df_5)
Lines.ASL <- rbind(L1,L2,L3,L4,L5)
LStats.ASL <- rbind(Lstats_1,Lstats_2,Lstats_3,Lstats_4,Lstats_5)
TD_trimmed.ASL <- rbind(TD_trimmed_1,TD_trimmed_2,TD_trimmed_3,TD_trimmed_4,TD_trimmed_5)

# get outliers: 
ASLN <- ASLN %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(ASLN,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))
```

```{r,label='ST-z-CCRM',fig.align='center', fig.width=6, fig.asp=1.5, out.width='100%', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
#########################################
##   get z-scores by speech material   ##
#########################################
# fit individual models with and without a knot per condition & group and compare them:

source("Functions/getBestFit.R")
# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # Output[[11]] : TD trimmed data
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
TempRemove_CCRM <- c("TD15_T_Run5_Q-CCRM-NoAlt_CCRM-M_All_Targets_none_0dB_07-Dec-2019_15-04_CCRM.csv",
                     "TD12_T_Run1_Q-CCRM-Alt_CCRM-M_All_Targets_none_0dB_25-Nov-2019_12-19_CCRM.csv",
                     "TD05_T_Run6_ENG_F-CCRM-Alt_0dB_22-Sep-2019_12-08_CCRM.csv")
CCRM$TempRmv <- ifelse((CCRM$fileName %in% TempRemove_CCRM)==TRUE,1,0)

### Q-NoAlt ###
Output <- getBestFit(CCRM,"Q-CCRM-NoAlt",CutOff)
df_1 <- Output[[1]]  # df_All
TD_trimmed_1 = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
Slopes.CCRM <- NULL
Slopes.CCRM["Q-CCRM-NoAlt"] <- FinalM_1$m$getPars()[1]
# anova.ST[["Q-CCRM-NoAlt"]] <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary()
Lstats_1 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

### Q-Alt ###
df <- CCRM %>% filter(CondCode=="Q-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"Q-CCRM-Alt",CutOff,-slope1_temp,int1_temp,8)
df_2 <- Output[[1]]  # df_All
TD_trimmed_2 = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))
Slopes.CCRM["Q-CCRM-Alt"] <- FinalM_2$m$getPars()[1]
# anova.ST[["Q-CCRM-Alt"]] <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary()
Lstats_2 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

### AMSSN ###
df <- CCRM %>% filter(CondCode=="AMSSN-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"AMSSN-CCRM-Alt",CutOff,-slope1_temp,int1_temp,8.5)
df_3 <- Output[[1]]  # df_All
TD_trimmed_3 = Output[[11]]
FinalM_3 <- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))
Slopes.CCRM["AMSSN-CCRM-Alt"] <- FinalM_3$m$getPars()[1]
# anova.ST[["AMSSN-CCRM-Alt"]] <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary()
Lstats_3 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

### MDR_F ###
df <- CCRM %>% filter(CondCode=="MDR_F-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

# Output <- getBestFit(CCRM,"MDR_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,11.5,0.078)
Output <- getBestFit(CCRM,"MDR_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,10,0.5)
df_4 <- Output[[1]]  # df_All
TD_trimmed_4 = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
L4<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2))
Slopes.CCRM["MDR_F-CCRM-Alt"] <- FinalM_4$m$getPars()[1]
# anova.ST[["MDR_F-CCRM-Alt"]] <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary()
Lstats_4 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

### ENG_F ###
df <- CCRM %>% filter(CondCode=="ENG_F-CCRM-Alt" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
# geom_point()+
# geom_text(label=df$listener, size=3, colour="blue") +
# labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"ENG_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,8,0.5)
df_5 <- Output[[1]]  # df_All
TD_trimmed_5 = Output[[11]]
FinalM_5 <- if(Output[[8]]==1){FinalM_5=Output[[6]]}else{FinalM_5=Output[[7]]}
L5<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_5$m$getAllPars()[1],2),
             round(FinalM_5$m$getAllPars()[2],2))
Slopes.CCRM["ENG_F-CCRM-Alt"] <- FinalM_5$m$getPars()[1]
# anova.ST[["ENG_F-CCRM-Alt"]] <- lm(FinalM_5$m$formula(),data=TD_trimmed_5) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_5$m$formula(),data=TD_trimmed_5) %>% summary()
Lstats_5 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

### CCRM_F ###
df <- CCRM %>% filter(CondCode=="CCRM_F-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"CCRM_F-CCRM-Alt",CutOff,-0.1173,1.7272,8.8838)
df_6 <- Output[[1]]  # df_All
TD_trimmed_6 = Output[[11]]
FinalM_6 <- if(Output[[8]]==1){FinalM_6=Output[[6]]}else{FinalM_6=Output[[7]]}
L6<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_6$m$getAllPars()[1],2),
             round(FinalM_6$m$getAllPars()[2],2))
Slope_CCRM_F <- FinalM_6$m$getPars()[1]
# anova.ST[["CCRM_F-CCRM-Alt"]] <- lm(FinalM_6$m$formula(),data=TD_trimmed_6) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_6$m$formula(),data=TD_trimmed_6) %>% summary()
Lstats_6 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

## combine all conditions together
# corAll.CCRM <- rbind(cor_1,cor_2,cor_3,cor_4,cor_5,cor_6)
FinalM.CCRM <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4,FinalM_5,FinalM_6)
CCRM <- rbind(df_1,df_2,df_3,df_4,df_5,df_6)
Lines.CCRM <- rbind(L1,L2,L3,L4,L5,L6)
LStats.CCRM <- rbind(Lstats_1,Lstats_2,Lstats_3,Lstats_4,Lstats_5,Lstats_6)
TD_trimmed.CCRM <- rbind(TD_trimmed_1,TD_trimmed_2,TD_trimmed_3,TD_trimmed_4,TD_trimmed_5,TD_trimmed_6)

# get outliers: 
CCRM <- CCRM %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(CCRM,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))
```

```{r,label='ST-AgeEffect', echo=FALSE,results='hide',message=FALSE,warning=FALSE, include=FALSE}
##### Age effect? ################################################################# 

TD_trimmed.CCRM_s <- TD_trimmed.CCRM %>% filter(CondCode!="CCRM_F-CCRM-Alt" & Group=="TD") %>% 
  dplyr::select(., listener, Age,Group, material, CondCode, uRevs) %>% droplevels()

# remove material affiliation in conditions name
TD_trimmed.CCRM_s$CondCode <- revalue(TD_trimmed.CCRM_s$CondCode, c("Q-CCRM-NoAlt"="Q-NoAlt","Q-CCRM-Alt"="Q-Alt",
                                              "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                                              "ENG_F-CCRM-Alt"="ENG_F-Alt"))
TD_trimmed.CCRM_s <- data.frame(TD_trimmed.CCRM_s)
TD_trimmed.ASL_s <- ASLN %>% filter(Group=="TD") %>% dplyr::select(., listener, Age,Group, material, CondCode, uRevs) %>% droplevels()
TD_trimmed.ASL_s$CondCode <- revalue(TD_trimmed.ASL_s$CondCode, c("Q-ASLN-NoAlt"="Q-NoAlt","Q-ASLN-Alt"="Q-Alt",
                                              "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt",
                                              "ENG_F-ASLN-Alt"="ENG_F-Alt"))
TD_trimmed.ASL_s <- data.frame(TD_trimmed.ASL_s)

ST_trimmed <- rbind(TD_trimmed.ASL_s,TD_trimmed.CCRM_s)
ST_trimmed <- data.frame(ST_trimmed)

######## lmer model ##########################################
## Find Best fit 
# start with a saturated model (3-way interaction with age)
model1 <- lmer(uRevs~CondCode*material*Age+(1|listener), ST_trimmed, REML=FALSE)
summary(model1)

(model2<-update(model1,  ~ . - CondCode:material:Age))
anova(model1,model2)
summary(model2)
# model2: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# model2:     CondCode:Age + material:Age
# model1: uRevs ~ CondCode * material * Age + (1 | listener)
#        npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)
# model2   18 -412.75 -351.34 224.37  -448.75                     
# model1   22 -409.33 -334.27 226.66  -453.33 4.5795  4     0.3332

(model3<-update(model2,  ~ . - material:Age))
anova(model2,model3)
summary(model3)
# model3: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# model3:     CondCode:Age
# model2: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# model2:     CondCode:Age + material:Age
#        npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)  
# model3   17 -410.96 -352.96 222.48  -444.96                       
# model2   18 -412.75 -351.34 224.37  -448.75 3.7857  1    0.05169 .

(model4<-update(model2,  ~ . - CondCode:material))
anova(model2,model4)
summary(model4)
# model4: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:Age
# model3: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# model3:     CondCode:Age
#        npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)  
# model4   13 -409.89 -365.54 217.94  -435.89                       
# model3   17 -410.96 -352.96 222.48  -444.96 9.0698  4    0.05938 .

(model5<-update(model4,  ~ . - CondCode:Age))
anova(model4,model5)
summary(model5)
# model5: uRevs ~ CondCode + material + Age + (1 | listener)
# model4: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:Age
#        npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)   
# model5    9 -403.73 -373.02 210.87  -421.73                        
# model4   13 -409.89 -365.54 217.94  -435.89 14.161  4     0.0068 **

# best mode --> model 2: uRevs ~ CondCode + material + Age + 
#                                CondCode:material + CondCode:Age + material:Age + (1 | listener) 
tab_model(model2)

# ---------------------------------------------------------------------------------
# test main effects:
rstatix::Anova(model2,type="II",test.statistic="Chisq")

BestModel <- model2

# CondCode:Age
(BestModel.1 <- update(BestModel,  . ~ . -CondCode:Age))
CondAge.LMEM <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# BestModel.1:     material:Age
# BestModel: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# BestModel:     CondCode:Age + material:Age
#             npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)   
# BestModel.1   14 -405.83 -358.06 216.91  -433.83                        
# BestModel     18 -412.75 -351.34 224.37  -448.75 14.919  4   0.004871 **

# material:Age
(BestModel.2 <- update(BestModel,  . ~ . -material:Age))
MatAge.LMEM <- anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# BestModel.2:     CondCode:Age
# BestModel: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# BestModel:     CondCode:Age + material:Age
#             npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)  
# BestModel.2   17 -410.96 -352.96 222.48  -444.96                       
# BestModel     18 -412.75 -351.34 224.37  -448.75 3.7857  1    0.05169 .

# CondCode:material
(BestModel.3 <- update(BestModel,  . ~ . - CondCode:material))
CondMat.LMEM <- anova(BestModel,BestModel.3)
summary(BestModel.3)
# BestModel.3: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:Age + 
# BestModel.3:     material:Age
# BestModel: uRevs ~ CondCode + material + Age + (1 | listener) + CondCode:material + 
# BestModel:     CondCode:Age + material:Age
#             npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq)  
# BestModel.3   14 -411.36 -363.60 219.68  -439.36                       
# BestModel     18 -412.75 -351.34 224.37  -448.75 9.3848  4    0.05217 .


# ------------------------------------------------------------------------------
# Post hoc -> individual lm's by condition.
# Since there is no material x condition interaction, observations from 
# the two speech materials were combined.
# --> use nls model used to for z-scores. This should be better method, especially for MDR_F-ASL 
# data where segmented line is needed.

# # get post-hoc test for single regression models (shown in the figure)
# anova.ST2 <- data.table::rbindlist(anova.ST) %>% data.frame(.) %>% round(.,3)
# colnames(anova.ST2)[2:4] <- c("SE","t-value","p-value")
# anova.ST2$`p-value` = ifelse(anova.ST2$`p-value`<.05,sprintf("\\textbf{%0.3f}",anova.ST2$`p-value`),anova.ST2$`p-value`)
# anova.ST2 <- cbind("Condition"=c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt","CCRM\\_F"),
#               rbind(anova.ST2[1:5,],c("","","","")),
#               anova.ST2[6:11,])


# -----------------------------------------------------------------------------------------------------
# Post-hoc paired comparison
# -----------------------------------------------------------------------------------------------------
# Material x Age:
(ref1 <- emmeans::lsmeans(BestModel,~ material*Age))
comps <- emmeans::contrast(ref1,alpha=0.05,method="pairwise",adjust=NULL) #,adjust=NULL) adjust="bonferroni"
summary(comps)

# Condition x Material:
(ref1 <- emmeans::lsmeans(BestModel,~ CondCode*material))
comps <- emmeans::contrast(ref1,alpha=0.05,method="pairwise",adjust=NULL) #,adjust=NULL) adjust="bonferroni"
summary(comps)

CondMat.postLMEM <- data.frame(comps[c(5,14,22,29,35)])
CondMat.CI <- confint(comps[c(5,14,22,29,35)])

CondMat.CI <- CondMat.CI  %>% mutate( CI = sprintf("%s - %s",
          round(lower.CL,2),
          round(upper.CL,2)))

CondMat.postLMEM <- cbind(CondMat.postLMEM,CondMat.CI$CI)
colnames(CondMat.postLMEM)[1:7] <- c("Contrasts","Estimate","SE","Df","t-value","p-value",sprintf("95\\%%-CI"))
row.names(CondMat.postLMEM) <- NULL

# change contrasts names
CondMat.postLMEM$Contrasts <-  c("(Quiet-NoAlt ASL) - (Quiet-NoAlt CCRM)", "(Quiet-Alt ASL) - (Quiet-Alt CCRM)",
                                 "(AMSSN-Alt ASL) - (AMSSN-Alt CCRM)", sprintf("(MDR\\_F-Alt ASL) - (MDR\\_F-Alt CCRM)"),
                                 sprintf("(ENG\\_F-Alt ASL) - (ENG\\_F-Alt CCRM)"))

# contrast                            estimate     SE  df t.ratio p.value
# (Q-NoAlt ASLN) - (Q-NoAlt CCRM)      0.19389 0.0254 216   7.621 <.0001 
# (Q-Alt ASLN) - (Q-Alt CCRM)          0.20112 0.0251 216   8.012 <.0001
# (AMSSN-Alt ASLN) - (AMSSN-Alt CCRM)  0.18495 0.0251 216   7.366 <.0001 
# (MDR_F-Alt ASLN) - (MDR_F-Alt CCRM)  0.24260 0.0251 216   9.662 <.0001 
# (ENG_F-Alt ASLN) - (ENG_F-Alt CCRM)  0.27378 0.0251 216  10.904 <.0001 

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
ST_AgeTab <- data.frame(rbind(
   c("Condition:Material",CondMat.LMEM$Df[2],CondMat.LMEM$Chisq[2],sprintf("\\textbf{%0.3f}",CondMat.LMEM$`Pr(>Chisq)`[2])),
  c("Condition:Age",CondAge.LMEM$Df[2],CondAge.LMEM$Chisq[2],sprintf("\\textbf{%0.3f}",CondAge.LMEM$`Pr(>Chisq)`[2])),
  c("Material:Age",MatAge.LMEM$Df[2],MatAge.LMEM$Chisq[2],sprintf("\\textbf{%0.3f}",MatAge.LMEM$`Pr(>Chisq)`[2]))))

ST_AgeTab[,c(2:3)]= apply(ST_AgeTab[,c(2:3)], 2, function(x) as.numeric(as.character(x)))

colnames(ST_AgeTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# -------------------------------------------------------------------------
```

```{r,label='ST-TDtrimmedAssumptions', echo=FALSE,results='hide',message=FALSE,warning=FALSE, include=FALSE}
################################ Assumptions testing ################################ 

# ---------------- uRevs ------------------------------------------------------------

#### For the combined data, based on the lmer model (BestModel) ####

#### normality (shapiro-wilk) ###########
# linearity is met if p>.05
# Option 1:
shapiro.test(residuals(BestModel))
# W = 0.99757, p-value = 0.983 --> normaly distr.

#### Homogeneity of variance (Levene's test) ###########
# homogeneity is met if p>.05

# Option 1: Is the lmer model fully covered here?
leveneTest(residuals(BestModel) ~ CondCode*material,data = ST_trimmed)

# Option 2: calculate Levene's test by hand, using the model.
# Based on: https://ademos.people.uic.edu/Chapter18.html [see 6.2]

ST_trimmed$BestModel.Res<- residuals(BestModel) #extracts the residuals and places them in a new column in our original data table
ST_trimmed$Abs.BestModel.Res <-abs(ST_trimmed$BestModel.Res) #creates a new column with the absolute value of the residuals
ST_trimmed$BestModel.Res2 <- ST_trimmed$Abs.BestModel.Res^2 #squares the absolute values of the residuals to provide the more robust estimate
Levene.BestModel <- lm(BestModel.Res2 ~ listener, data=ST_trimmed) #ANOVA of the squared residuals
anova(Levene.BestModel) #displays the results --> homogeneity of variance is marginally significant (p=0.04), i.e., homogeneity is not met..

boxplot(residuals(BestModel) ~ CondCode*material,data = ST_trimmed)

plot(BestModel)

t1 <- ggplot(ST_trimmed, aes(x=interaction(CondCode,material), y=BestModel.Res, color=material)) +
  geom_point(size=2,alpha=1) +
  # geom_text(label=ASLN$listener, size=3)+
  # labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  # scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  # scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))
```

```{r,label='ST-Assumptions', echo=FALSE,results='hide',message=FALSE,warning=FALSE, include=FALSE}
################################ Assumptions testing ################################ 

# ---------------- uRevs ------------------------------------------------------------

############
# ASLN #####
############

# linear model
w1 <- lm(uRevs~ CondCode + Group, data = ASLN)

# 1. Normality (Shapiro-Wilk test) --> NOT met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(ASLN$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(ASLN$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- ASLN %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> NOT met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=ASLN,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = ASLN))

# Option 3:
# per condition
VarTest <- ASLN %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

############
# CCRM #####
############

# linear model
w1 <- lm(uRevs~ CondCode + Group, data = CCRM)

# 1. Normality (Shapiro-Wilk test) --> NOT met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(CCRM$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(CCRM$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- CCRM %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> NOT met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=CCRM,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = CCRM))

# Option 3:
# per condition
VarTest <- CCRM %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

# ---------------- z_trim -------------------------------------------------------

############
# ASLN #####
############

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = ASLN)

# 1. Normality (Shapiro-Wilk test) --> NOT met! (4/10)
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(ASLN$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(ASLN$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- ASLN %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=ASLN,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = ASLN))

# Option 3:
# per condition
VarTest <- ASLN %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

############
# CCRM #####
############

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = CCRM)

# 1. Normality (Shapiro-Wilk test) --> NOT met! (3/10)
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(CCRM$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(CCRM$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- CCRM %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=CCRM,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = CCRM))

# Option 3:
# per condition
VarTest <- CCRM %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

```

```{r,label='ST-getAdultData', echo=FALSE,message=FALSE, warning=FALSE,results='hide'}
# get adults data for for the boxplots: 
d_study2 <- read.csv(file.path(FileDir,'Files','StudyII_AdultData.csv'),header=T) 

d_study2 <- d_study2 %>% filter(CondCode=="Q_ASL_TarB" | CondCode=="Q_CCRM_TarB" | CondCode=="DSDG_ASL_TarB+MskB" |
                            CondCode=="DSDG_CCRM_TarB+MskB" | CondCode=="SSDG_CCRM_TarB+MskB") %>% droplevels() 

d_study2$CondCode <- revalue(d_study2$CondCode, c("DSDG_ASL_TarB+MskB"="ENG_F-ASLN-Alt","DSDG_CCRM_TarB+MskB"="ENG_F-CCRM-Alt", "Q_ASL_TarB"="Q-ASLN-Alt", "Q_CCRM_TarB"="Q-CCRM-Alt", "SSDG_CCRM_TarB+MskB"="CCRM_F-CCRM-Alt"))

d_study2$CondCode <- factor(d_study2$CondCode,levels=c("Q-ASLN-Alt", "Q-CCRM-Alt", "ENG_F-ASLN-Alt", "ENG_F-CCRM-Alt","CCRM_F-CCRM-Alt"))

# select columns of interest from the main data frame
d_adults <- d_study2[,c("Listener","Age","Material","CondCode","duty")]

# get HW data
d_studyHW <- read.csv(file.path(FileDir,'Files','HW_YOnly_Upto35Yrs_n14_meanSRdT.csv'),header=T) 

d_studyHW <- d_studyHW %>% filter(Condition=="AMSSN" | Condition=="MDR_F") %>% droplevels() 

d_studyHW$Condition <- revalue(d_studyHW$Condition, c("AMSSN"="AMSSN-ASLN-Alt","MDR_F"="MDR_F-ASLN-Alt"))

d_studyHW$Material <- "ASL"

colnames(d_studyHW)[2] <- "Listener"
colnames(d_studyHW)[3] <- "CondCode"
colnames(d_studyHW)[13] <- "duty"

d_studyHW <- d_studyHW[,c("Listener","Age","Material","CondCode","duty")]

d_adults <- rbind(d_adults,d_studyHW)
d_adults$Age=14
colnames(d_adults)[5] <- "uRevs"
d_adults$Group="TD"

# Filter data by material  --------------------------------------------------------------------------------------
ASLN_adults <- d_adults %>% filter(Material=="ASL") %>% droplevels() # Only ASL
CCRM_adults <- d_adults %>% filter(Material=="CCRM") %>% droplevels() # Only CCRM
```

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# For ASL
ASL_tab <- ASLN %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
ASL_tab <- ASL_tab[,-grep("Group",colnames(ASL_tab))]
# APD first then TD
ASL_tab <- cbind(ASL_tab[1:5,1:ncol(ASL_tab)],ASL_tab[6:nrow(ASL_tab),2:ncol(ASL_tab)])
ASL_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt")

# For CCRM
CCRM_tab <- CCRM %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
CCRM_tab <- CCRM_tab[,-grep("Group",colnames(CCRM_tab))]
# APD first then TD
CCRM_tab <- cbind(CCRM_tab[1:6,1:ncol(CCRM_tab)],CCRM_tab[7:nrow(CCRM_tab),2:ncol(CCRM_tab)])
CCRM_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt","CCRM\\_F-Alt")
# --------------------------------------------------------------------------------------------------
# combine table
colnames(ASL_tab)[1] = ""
colnames(CCRM_tab)[1] = ""

ST_tab <- rbind(ASL_tab,CCRM_tab)
```

#### SRdTs by age {.unnumbered}
Since the age of the TD/APD children that participated in the present study spanned between circa 7 to 13 years, a developmental age effect was expected, where performance was expected to improve with an increasing age. To inspect this effect across the different test conditions and speech material (ASL/CCRM), scatterplots and linear regression lines for the listeners SRdTs as a function of age are shown in Figure\ \@ref(fig:ST-Age)\ A-B. The effect of age was tested against the TD group only since the variability in scores in the TD group is expected to be relatively smaller than in the clinical APD group. Therefore, any interpretation based on the APD regression lines should be carried out cautiously. The TD regression lines were determined based on model comparison and outliers trimming procedure to improve the model's fit (see section ??). Regular regression lines were found to be the most parsimonious in describing the relationship between the TD children performance and their age. This was the case in all test conditions but the MDR_F distractor in the ASL material, where a segmented line was found to give the best fit. MDR_F segmented line indicated that DC improved with age by circa 0.1 per year until reaching a plateau at the age of 9.5 years.  

```{r, label='ST-Age', fig.cap="Scatterplot and linear regression lines for the listeners SRdTs measured with the switching task with the ASL (A) and CCRM speech material (B) as a function of age. Corresponding regression coefficients and statistics is provided for TD group only. Red indicates data from the APD group and cyan indicates data from the TD control group. Data for normal hearing adults taken from Chapter 2 is shown in the boxplots as a reference.", fig.align='center', fig.width=14, fig.asp=0.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE,fig.pos='h'}

dat_text.ASL <- data.frame(
  label = Lines.ASL,
  label2 = matrix(LStats.ASL),
  CondCode   = levels(ASLN$CondCode),
  Group = "TD")

dat_text.CCRM <- data.frame(
  label = Lines.CCRM,
  label2 = matrix(LStats.CCRM),
  CondCode   = levels(CCRM$CondCode),
  Group = "TD")

###### ASL ##############
t1 <- ggplot(ASLN, aes(x=Age, y=uRevs, color=Group)) +
  geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
  geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
  geom_point(size=2,alpha=1) +
  # geom_text(label=ASLN$listener, size=3)+
  geom_line(data=filter(ASLN, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(ASLN,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.ASL, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 3.5)+
  geom_text(data = dat_text.ASL, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 3.5)+
  geom_boxplot(ASLN_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
  labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                      labeller = labeller(CondCode = c("Q-ASLN-NoAlt" ="Quiet-NoAlt","Q-ASLN-Alt"="Quiet-Alt",
                                                       "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt","ENG_F-ASLN-Alt"="ENG_F-Alt"))) +
  theme(panel.spacing.x = unit(0,"line"),
        strip.background = element_rect(fill="white", color="white"),
        strip.text = element_text(face = "bold", size = 11))

###### CCRM ##############
t2 <- ggplot(CCRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
  geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
  geom_point(size=2, alpha=1) +
  # geom_text(label=CCRM$listener, size=3)+
  geom_line(data=filter(CCRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(CCRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.CCRM, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3, size = 3.5)+
  geom_text(data = dat_text.CCRM, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 3.5)+
  geom_boxplot(CCRM_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
  labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t2 <- t2 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                      labeller = labeller(CondCode = c("Q-CCRM-NoAlt" ="Quiet-NoAlt","Q-CCRM-Alt"="Quiet-Alt",
                                                       "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                                                       "ENG_F-CCRM-Alt"="ENG_F-Alt","CCRM_F-CCRM-Alt"="CCRM_F-Alt"))) +
  theme(panel.spacing.x = unit(0,"line"),
        strip.background = element_rect(fill="white", color="white"),
        strip.text = element_text(face = "bold", size = 11))

(t1 + t2) + plot_layout(ncol = 1, nrow = 2, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```
  

Overall, Figure \@ref(fig:ST-Age)\ A-B showed a similar trend in performance in the two speech materials, where children in both groups showed larger decrement in performance for speech distractors (smaller SRdT $\rightarrow$ better performance). The regression lines indicates that the improvement in performance by age was more prominent for speech distractors, with relatively steeper slopes (almost twice as steep) than for the non-speech distractor (AMSSN) or for conditions without a distractor. Furthermore, as expected, CCRM sentences were more intelligible, with performance shifted towards lower DC range (i.e., more difficult) relative to performance for the ASL speech material. This is due to the more simple speech material and the restricted alternative responses of the CCRM matrix-based sentences.
  
  
A closer look at the linear lines shows several interesting trends. The non-speech AMSSN distractor showed to have little-to-no effect on performance, at least in the TD group, where performance was fairly similar to performance in the Quiet conditions. When comparing the regression lines, there appears to be a relatively larger separation between the groups for data measured with the CCRM speech material, especially for AMSSN, but also for the speech distractors. However, it is possible that the APD regression lines do not reflect the true population  due to the large spread in performance and the small sample size and thus any interpretation should be taken with a pinch of salt. Another interesting observation is that the children showed little-to-no *masking-release* for speech spoken in an unfamiliar language (MDR_F) when compared with a distractor spoken in English (ENG_F). This is in agreement with findings in the adults study in Chapter\ \@ref(Chpt2). Lastly, it is apparent from the figure that performance for CCRM_F distractor was near-to-ceiling for some children, mostly among the APD group.  
  
  
An exploratory comparison between between the children's data measured in the present study with data measured across young NH adults collected in Chapter\ \@ref(Chpt2) further highlight the strong developmental trend, with SRdTs still not entirely "adult-like" even at the age of 13 years, especially for speech distractos (see boxplots in Figure\ \@ref(fig:ST-Age)\ A-B). The children in both groups seems to be markedly susceptible to competing CCRM sentences or familiar/unfamiliar speech presented with ASL sentences, with performance at the age of 12 years still largely differing from those obtained by the adults. On the other hand, by the age of 12 years, the TD children reached near to "adult-like" performance when CCRM target sentences were presented with with ENG_F speech distractor or when ASL sentences were presented with AMSSN distractor.  
  
  
Next, age effect was evaluated using LMEM (lmer, REF), with Condition, Material (ASL/CCRM) and Age as fixed factors, SRdT as dependent variable and a random intercept for subjects (reference levels: Condition = Quiet-NoAlt; Material = ASL). A model without two-way interaction between Condition, Material and Age was found to give the best fit (see Table\ \@ref(tab:ST-AgeLMEM)). Model comparison procedure was performed on the model with the best fit, comparing it to a reduced model where each of the fixed terms were singly term was removed, starting with the interaction terms. The model comparison revealed a highly significant two-way interaction between Condition\ x\ Age (p<0.001) as well as a marginal two-way interaction between Condition\ x\ Material and Material\ x\ Age (p=0.052). These results further supports the trends seen in the scatterplots. 

`r kableExtra::text_spec("The significant Material\ x\ Age interaction indicates that the developmental trend is different between the two speech materials, with larger age effect (i.e., steeper slopes) for the ASL than for the CCRM sentences(?????). [the LMEM summary gives an estimate for materialCCRM:Age of 0.014 (ASL is the reference level). Does that mean that the ASL sentences mean improvement per 1 year was 0.014 larger than for the CCRM material? I'm not too sure how to interpret this..]", color = "red")` Furthermore, the significant Condition\ x\ Material interaction implies that performance in the different test conditions differed between the two speech materials. A post-hoc t-test comparison based on the fitted model (lsmeans(), REF; see Table\ \@ref(tab:ST-AgeLMEMpost)), revealed a highly significant difference in performance between the speech materials (reference level = ASL) across all five test conditions (all p's <\ 0.001). The estimated mean difference between the contrast pairs ranged between \+0.18 to \+0.27, hence, the CCRM speech material was significantly more intelligible than the ASL material, across all test conditions.
  
  
Lastly, as observed in Figure\ \@ref(fig:ST-Age)\ A-B, the highly significant Condition\ x\ Age interaction supports the observation that the magnitude of the age effect was different across the test conditions. These findings raises the following questions -- do all the conditions show a significant age effect? Moreover, since the effect of age is not the same across the test conditions, which conditions showed the largest age effect? One possible way to tackle these questions is to compare the separate regression models using F-statistics. Nonetheless, due to the small sample-size and the large number of paired comparisons, the test lacks a statistical power, thus the results may not reflect the true effect (better term?). The TD group regression model's R$^{2}$ and p-values are given in the bottom part of Figure A and B. The ASL model's p-value showed a highly significant age effect for ENG_F, MDR_F and Quiet-NoAlt condition and a marginal effect for AMSSN (p=0.048), whereas no significant age effect was found for Quiet-Alt (p=0.168). As for the CCRM material, there was a highly significant age effect for ENG_F and a marginal effect for the Quiet-Alt condition (p=0.058) and for CCRM_F condition (p=0.05) which is not included in the LMEM model, whilst no significant age effect was found for Quiet-NoAlt, AMSSN and MDR_F conditions. Furthermore, age was found to be a better predictor (i.e., accounting for larger variance in SRdT) for conditions with speech distractors, with R$^{2}$ ranging between 32\% to 72\% for the ASL material and about 12\% to 29\% for the CCRM material. A comparison between the regression lines slopes fitted for the different test conditions for the CCRM (x-axis) and ASL speech material (y-axis) is depicted in Figure\ \@ref(fig:ST-AgeSlopes). A possible pattern emerges from the figure, namely, while the slopes for the quiet and non-speech conditions are fairly similar across the two speech material (indicated by their proximity to the diagonal line), differences are relatively larger for speech distractors, in particularly for MDR_F where the slope for the ASL material (-0.13) is about six times steeper than the slope for the CCRM material (-0.02). 

```{r,label='ST-AgeLMEM',echo=FALSE,warning=FALSE, message=FALSE}

kbl(ST_AgeTab, booktabs = T,escape = F,caption = "Mixed effects model for SRdTs measured with the switching task with condition, speech material and age as fixed factors and a random intercept for subjects. Note: only data measured with the control group following outliers trimming was included (trimmed TD). Reference levels: Condition = Quiet-NoAlt, Group = APD, Material = ASL).",
    align = c("lccc"),format = "latex",digits = 3) %>%
    # kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c("+ CondCode:material + CondCode:Age + material:Age + (1 | Subjects)" = 4)) %>%
  add_header_above(c("SRdT ~ Condition + Material + Age" = 4), align = "l",line = FALSE) %>%
  column_spec(1, width = "8cm") %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T)
```


(ref:tabCap) Post-hoc t-test paired comparison for Condition x Material two-way interaction. The test was performed on the fitted LMEM model and included adjusted least-squared-mean for the random intercept (subjects) using lsmeans package (REF).

```{r, label='ST-AgeLMEMpost', echo=FALSE}
CondMat.postLMEM$`p-value` = ifelse(CondMat.postLMEM$`p-value`<.001,sprintf("\\textbf{< 0.001}"),CondMat.postLMEM$`p-value`)

kbl(CondMat.postLMEM,booktabs = T, escape = F,caption = '(ref:tabCap)',
    align = c("lcccccc"),format = "latex",digits = 2) %>%
    kable_styling(latex_options = c("scale_down")) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(6, italic = T)

# use this if you want to fore latex to print the table in an exact location!
# latex_options = c("hold_position")
```

```{r, label='ST-AgeSlopes', fig.cap="A comarison beteween the regression lines slopes fitted for the CCRM (x-axis) and ASL speech material (y-axis) in the switching task. The different test conditions are represented by the different symbols given in the legend. The diagonal line represents an optimal agreement between the speech materials. Observations falling below the line indicate steeper slope for the ASL material than compared with the CCRM material.", fig.align='center', fig.width=6, fig.asp=0.7, out.width='60%',echo=FALSE, message=FALSE, warning=FALSE}

# fig.pos='h'
## Get slope plot --------------------------------------------------------------
Slopes.ASLN <- data.frame(Slopes.ASLN)
Slopes.CCRM <- data.frame(Slopes.CCRM)
SlopePlot <- cbind(CondCode=levels(ST_trimmed$CondCode),Slopes.ASLN,Slopes.CCRM)

SlopePlot <- data.frame(SlopePlot)
SlopePlot$CondCode <- factor(SlopePlot$CondCode,levels=levels(ST_trimmed$CondCode))

t1 <- ggplot(SlopePlot, aes(x=Slopes.CCRM, y=Slopes.ASLN)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point(size=3, aes(shape=CondCode)) +
  labs(x = "CCRM", y = "ASL") +
  scale_y_continuous(limits = c(-0.14,0,0.02),breaks=seq(-0.14,0,0.02)) +
  scale_x_continuous(limits = c(-0.14,0,0.02),breaks=seq(-0.14,0,0.02)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position=c(0.15, 0.75),
        legend.direction = "vertical",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t1$labels$shape ="Condition"
t1
```

<!-- For Discussion:
- Different age distribution btw the groups.
- Only speech maskers degraded performance.
- little-to-no masking-release for speech spoken in a foreign language (MDR) when compared with ENG masker.
- Clear age effect: norms by age per condition and the need for more data in adolescence to have a fuller picture of the developmental trend. 
-->

#### Age-independent z-scores {.unnumbered}
[*Boxplots & abnormal scores by conditions*]{.correction}  
  
  
Age-independent (standardised residuals) z-scores were calculated based on the TD group data using a multiple-case study approach (@Ramus2003; see section ??? for more details). Descriptive statistics for the listeners age-independent z-scores is giving in Table\ \@ref(tab:ST-Tab). Additional boxplots are shown in Figure \@ref(fig:ST-z)\ A-B, for the ASL and CCRM speech material respectively. Scores were calculated separately for each test condition, with better performance indicated by smaller z-score. The grey area marks the two-tailed 1.96 deviance cut-off for abnormal score from the control group mean (z $\approx$ 0), where only about 5\% of the normal population is expected to score below/above it. Overall, APD children performance in both test versions was noticeably poorer, with higher median z-scores than compared with the TD children. The next paragraphs will cover the examination and analysis of the individuals and group differences separately for each test version.

```{r, label='ST-z', fig.cap="Boxplots of the listeners age-independent standardised residuals for data measured with the ASL (A) and the CCRM speech material (B). Residuals were calculated seperately for each condition and are based on a model predicton for TD group only. The grey area represents the deviance cut-off for abnormal score (SD $\\pm$\ 1.96 below/above the TD mean), where about 95\\% of the normal population is e expected to lay within. The dashed line represents the theorethical TD group mean (z = 0).", fig.align='center', fig.width=10, fig.asp=.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# ASL_Outlier <- ASLN[which(ASLN$z_trim>1.65),] %>% droplevels()
# ggplot(ASL_Outlier, aes(x=listener, fill = Group)) + geom_histogram(alpha = .5, bins=25, position = "identity",stat="count") + theme_classic()
# var_select = c("listener")
# count_freq = count(ASL_Outlier, var_select)

###### ASL ##############
t1 <- ggplot(ASLN, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,shape=1,colour="blue")+
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.48, y=1, angle=90, size=5)+
  annotate(geom ="text",  x=1, y = 7.5, label = "ST-ASL", size=9, face="bold",fontface=2) +
  # geom_text(aes(label = ifelse(ASLN$z_trim>1.65,ASLN$listener,"")),
            # position = position_dodge2(width = .8,padding = 0.1))+
  scale_y_continuous(limits = c(-5,8),breaks=seq(-5,8,2))+
  scale_x_discrete(labels=c("Q-ASLN-NoAlt" ="Quiet-NoAlt","Q-ASLN-Alt"="Quiet-Alt",
                            "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt","ENG_F-ASLN-Alt"="ENG_F-Alt"))+
  labs(y = "standardised residual (z-score)" ,x = NULL)+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"))

###### CCRM #############
# CCRM_Outlier <- CCRM[which(CCRM$z_trim>1.65),] %>% droplevels()
# ggplot(CCRM_Outlier, aes(x=listener, fill = Group)) + geom_histogram(alpha = .5, bins=25, position = "identity",stat="count") + theme_classic()
# var_select = c("listener")
# count_freq = count(ASL_Outlier, var_select)

t2 <- ggplot(CCRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,shape=1,colour="blue")+
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.5, y=3, angle=90, size=5)+
  annotate(geom ="text",  x=1.3, y = 7.5, label = "ST-CCRM", size=9, face="bold",fontface=2) +
  # geom_text(aes(label = ifelse(CCRM$z_trim>1.65,CCRM$listener,"")),
            # position = position_dodge2(width = .8,padding = 0.1))+
  scale_y_continuous(limits = c(-3,8),breaks=seq(-3,8,2))+
  scale_x_discrete(labels=c("Q-CCRM-NoAlt" ="Quiet-NoAlt","Q-CCRM-Alt"="Quiet-Alt",
                            "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                            "ENG_F-CCRM-Alt"="ENG_F-Alt","CCRM_F-CCRM-Alt"="CCRM_F-Alt"))+
  labs(y = "standardised residual (z-score)" ,x = NULL)+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"))

library(patchwork)
(t1 + t2) + plot_layout(ncol = 1, nrow = 2, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='ST-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
# ST_tab$p = ifelse(ST_tab$p<.05,sprintf("\\textbf{%.02f}",ST_tab$p),ST_tab$p)

kbl(ST_tab,booktabs = T, escape = F,caption = "Switching task descriptives for standardised residuals (z-scores) calculated for data measured with the ASL and CCRM speech material.",
    align = c("lcccccccccc"),format = "latex") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" ", "APD" = 5, "TD" = 5)) %>%
  column_spec(c(7),border_left = T) %>%
  kable_styling() %>%
  pack_rows("ASL", 1, 5) %>%
  pack_rows("CCRM", 6, 11)
```

##### ASL corpus {.unnumbered}  
  
  
A comparison of the groups means reveals that the APD children were more susceptible to the non-switched condition (Quiet-NoAlt), where the target sentences were presented in quiet, and the switched condition where the target sentences were presented with a non-speech distractor (AMSSN), which yielded the largest separation between the groups, with APD median score of 1.81 and 1.79, respectively, laying just within the norms upper limit. Performance of the APD children was also noticeably poorer for conditions with speech distractors (MDR_F and ENG_F), with median z-score of circa 1, whereas performance for Quiet-Alt condition was fairly similar between the groups.

A comparison between the proportion of abnormal scores amongst the APD children in the different conditions revealed that AMSSN, Quiet-NoAlt and MDR_F gave the highest proportion of abnormal scores[^AbnormalScore-Footnote].
Surprisingly, AMSSN distractor yielded the highest proportion of abnormal scores, with half of the APD children exhibiting abnormal score (20/10, 50\%). Followed by Quiet-NoAlt condition, where paradoxically and against our expectation 45\% of the APD group (9/20) obtained an abnormal score, whereas only 10\% (2/20) obtained an abnormal score in the Quiet-Alt condition. Interestingly, the APD children did not benefit from a release of masking for a speech distractor spoken in an unfamiliar language (MDR_F) as opposed to a familiar speech spoken in English (ENG_F), with median scores very similar in both conditions. This sits well with our previous findings with adults where adults showed no benefit for MDR_F speech masker (see chapter ???). Another interesting observation was that double the amount of APD children exhibited abnormal score (8/20 = 40\%), making it the third largest proportion of abnormal scores, while only 20\% (4/20) of the children were abnormal for the ENG_F condition. Lastly, The proportion of abnormal scores amongst the TD group ranged between 0\% to 13\% with a mean of 7.8\%, which corroborate fairly well with the theoretical probability of 2.5\% (one-tailed).    
  
[^AbnormalScore-Footnote]: Focusing on future clinical viability of the task, we were only interested in identifying children with clinically poor performance. Thus, abnormal score was defined as a one-tailed deviance cut-off of z-score > 1.96, within which circa 97.5\% of the normal population is expected to lay.  

##### CCRM corpus {.unnumbered}  
  
  
Figure \@ref(fig:ST-z)\ B reveals a similar trend for the CCRM sentences, however with a more modest differences between the two groups. AMSSN yielded the largest separation between the groups, where 40\% (8/20) of the APD children obtained an abnormal score and with a median score of 1.62, which is relatively close to the \+1.96 upper deviance cut-off. In comparison, only 4.3\% of the TD children (1/23) had abnormal performance for AMSSN condition. Again, the APD group median z-score for the speech distractors conditions was approximately 1 (range: 0.86-1.11), however the proportion of abnormal APD children was noticeably smaller than for the non-speech distractor, with 25\% (5/20) for MDR_F, 20\% (4/20) for ENG_F, and only 10\% (2/20) for CCRM_F distractor. Lastly, in contrast to the ASL material, performance for the CCRM sentences presented in quiet were relatively better without switching (NoAlt) than with switching (Alt). Nonetheless, the spread in performance for the non-switched condition was larger, which suggests that some APD children were more negatively affected by the condition than others. The percentage of abnormal scores in the TD group were relatively low ranging between 0 to 8.7\% (2/23, Quiet-NoAlt) with an average of 4.3\% abnormal scroes across the different conditions.
  

[*nparLD() full 2x2x5 model*]{.correction}  
  
  
A three-way 2\ x\ 2\ x\ 5 factorial design with repeated measures was used to test the main effects of Group, Condition, and Material as well as their interaction on performance in the task (with z-scores as dependent variable). Note that the CCRM test condition with CCRM-type sentences as distractor (CCRM_F) was not included in the model since there was no comparable condition in the ASL speech material. Inspection of the standardised residuals z-scores revealed that the assumption of normal distribution (Shapiro Wilk test) was rejected for data measured with both speech material. Furthermore, homogeneity of the variance in the APD group was rejected for the ASL corpus (Levene's test; *F(4,95)\ =\ 2.71*, *p\ <\ 0.05*). Thus, due to the small sample size and the incomplete fulfilment of parametric statistical methods assumptions, a non-parametric approach was adopted. This was tested with an rank-based ANOVA-type statistic test (ATS) using the *nparLD()* function (nparLD package, REF), which is a robust method for small datasets with outliers or skewed scores (see Jos Feys, 2016 for a good introduction for robust nonparametric techniques)[^nparLD-Footnote]. The *nparLD ATS* test results are given in Table\ \@ref(tab:ST-Tab-nparLD). No significant three-way or two-way interactions were found (Group\ x Condition\ x\ Material, Group\ x\ Material, Material\ x\ Condition, and Group\ x\ Condition; all *p's\ >\ 0.05*), while there was a highly significant main effect of Group (*p\ < 0.0001*) and a strong main effect of Condition (*p\ < 0.001*). Despite some evidence for better performance in the CCRM material, the main effect of Material was not significant (p=0.62). Furthermore, in spite of some apparent differences in performance between the two groups across the different test conditions, these differences were found to be insignificant based on the Group\ x\ Condition two-way interaction.

[*additional model for CCRM_F*]{.correction}  

```{r,label='ST-zAssumptions', message=FALSE, warning=FALSE, include=FALSE, results='hide'}
# remove CCRM_F condition
CCRM_s <- CCRM %>% filter(CondCode!="CCRM_F-CCRM-Alt") %>% 
  dplyr::select(., listener, Group, material, CondCode, z_trim) %>% droplevels()

# remove material affiliation in conditions name
CCRM_s$CondCode <- revalue(CCRM_s$CondCode, c("Q-CCRM-NoAlt"="Q-NoAlt","Q-CCRM-Alt"="Q-Alt",
                                              "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                                              "ENG_F-CCRM-Alt"="ENG_F-Alt"))
ASLN_s <- ASLN %>% dplyr::select(., listener, Group, material, CondCode, z_trim) %>% droplevels()
ASLN_s$CondCode <- revalue(ASLN_s$CondCode, c("Q-ASLN-NoAlt"="Q-NoAlt","Q-ASLN-Alt"="Q-Alt",
                                              "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt",
                                              "ENG_F-ASLN-Alt"="ENG_F-Alt"))

ST <- rbind(ASLN_s, CCRM_s)
ST <- data.frame(ST)
# levels(ST$material)
# levels(ST$Group)
# levels(ST$CondCode)


########################### Test assumptions #########################################
# For ST combined data (z-scores)

# Normality: not met
# homoscedasticity: met

# linear model
w1 <- lm(z_trim ~ CondCode * Group * material, data = ST)

#### normality (shapiro-wilk) ###########
# Do all the points fall approximately along the reference line? If YES we can assume normality.
# ggqqplot(residuals(w1))

# Option 1:
# linearity is met if p>.05
shapiro.test(residuals(w1))
# W = 0.94461, p-value = 1.375e-11 --> NOT normaly distr.

# Option 2: by fixed factors: --> mostly normal..
NormTest <- ST %>%
  group_by(CondCode, Group, material) %>%
  rstatix::shapiro_test(z_trim)

#### Homogeneity of variance (Levene's test) ###########
# homogeneity is met if p>.05

# Option 1: Is the lm model fully covered here?
leveneTest(residuals(w1) ~ CondCode * Group * material, data = ST)
# -> homogeneity of the full model is met

# Levene's Test for Homogeneity of Variance (center = median)
#        Df F value Pr(>F)
# group  19  0.8729 0.6174
#       410    

# Option 2: by fixed factors
# per condition
VarTest <- ST %>%
  rstatix::group_by(CondCode) %>%
  levene_test(z_trim ~ Group*material)

VarTest <- ST %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode*material)

VarTest <- ST %>%
  rstatix::group_by(material) %>%
  levene_test(z_trim ~ CondCode*Group)

# Option 2: calculate Levene's test by hand, using the model.
# Based on: https://ademos.people.uic.edu/Chapter18.html [see 6.2]

ST$BestModel.Res<- residuals(w1) #extracts the residuals and places them in a new column in our original data table
ST$Abs.BestModel.Res <-abs(ST$BestModel.Res) #creates a new column with the absolute value of the residuals
ST$BestModel.Res2 <- ST$Abs.BestModel.Res^2 #squares the absolute values of the residuals to provide the more robust estimate
Levene.BestModel <- lm(BestModel.Res2 ~ listener, data=ST) #ANOVA of the squared residuals
anova(Levene.BestModel) #displays the results --> homogeneity of variance is marginally significant (p=0.04), i.e., homogeneity is not met..

boxplot(residuals(w1) ~ CondCode * Group * material,data = ST)

plot(BestModel)

t1 <- ggplot(ST, aes(x=interaction(CondCode,Group,material), y=BestModel.Res)) +
  geom_point(size=2,alpha=1) +
  # geom_text(label=ASLN$listener, size=3)+
  # labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  # scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  # scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))
```

```{r,label='ST-nparLD', message=FALSE, warning=FALSE, include=FALSE, results='hide'}


ST.nparLD <- nparLD(z_trim ~ CondCode * Group * material, data = ST, subject = "listener", description = TRUE, plot.CI=TRUE)

ST.nparLD <- data.frame(round(ST.nparLD$ANOVA.test,3))

### CCRM only
CCRM <- data.frame(CCRM)
CCRM.nparLD <- nparLD(z_trim ~ CondCode * Group, data = CCRM, subject = "listener", description = TRUE, plot.CI=TRUE)

CCRM.nparLD <- data.frame(CCRM.nparLD$ANOVA.test)

```

Since the CCRM condition with CCRM-type distractor were not included in the aforementioned model, an additional 2\ x\ 6 model was computed only for data measured with the CCRM speech material. The model included Group and Condition as between- and within-subjects predictors, respectively, with z-scores as the dependent variable using nparLD ATS test (f1.ld.f1 design). The ATS test found a strong significant difference between the groups (`r sprintf("Statistic = %0.3f, df = %0.3f, p < %0.1f", CCRM.nparLD[1,1], CCRM.nparLD[1,2],CCRM.nparLD[1,3])`), while no significant main effect was found for Condition (`r sprintf("Statistic = %0.3f, df = %0.3f, p = %0.3f", CCRM.nparLD[2,1], CCRM.nparLD[2,2],CCRM.nparLD[2,3])`) nor for Group x\ Condition interaction (`r sprintf("Statistic = %0.3f, df = %0.3f, p = %0.3f", CCRM.nparLD[3,1], CCRM.nparLD[3,2],CCRM.nparLD[3,3])`).

[^nparLD-Footnote]: Other non-parametric tests procedures gave similar results. 

```{r, label='ST-Tab-nparLD', echo=FALSE}
ST.nparLD$p.value = ifelse(ST.nparLD$p.value<.05,sprintf("\\textbf{%0.3f}",ST.nparLD$p.value),ST.nparLD$p.value)
colnames(ST.nparLD)[3] <- "p-value"


row.names(ST.nparLD) <- c("Group","Condition","Material","Group:Condition","Material:Condition",
          "Group:Material","Group:Condition:Material")
colnames(ST.nparLD)[3] <- "p-value"

kbl(ST.nparLD,booktabs = T, escape = F,caption = "Statistical analysis for the effects of Group, Condition and Material as well as their interaction (2x2x5 factorial design with repeated measures) tested with a robust rank-based method for analysis of nonparametric data using nparLD package (REF). Analysis was based on a f2-ld-f1 design ANOVA-type statistic (ATS) test, whereby f2 refers to an experimental design with two between-subjects factors (Group and Material) and f1 refers to a single within-subjects factor (Condition).",
    align = c("lccc"),format = "latex",digits = 3) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T)

# use this if you want to fore latex to print the table in an exact location!
# latex_options = c("hold_position")
```


[Discussion or here?]{.correction}  
  
The lack of significant interaction (Group x Condition or Group x Condition x Material), is somewhat surprising and and do not reflect some of the differences seen in Figure ?? between the two groups for certain conditions or the overall difference in performance between the speech materials. These disagreement mat suggest that the model is under-powered to test that.

[*ROC curves table?*]{.correction}

[*Switching effect (derived measures)*]{.correction}

```{r,echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# Get derived measures ----------------------------------------------------------------------

###### ASLN ######
# change data from Long2Wide
ASLN_w <- ASLN %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim")) %>%
  ungroup()
colnames(ASLN_w)[1:length(ASLN_w)] <- gsub("-", "_", colnames(ASLN_w[,c(1:length(ASLN_w))]))
  
# -- get derived scores --------------------------------------
# uRevs
# ASLN_w$ASLN_QAlt_vs_QNoAlt   <-  ASLN_w$uRevs_Q_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_AMSSN_vs_QNoAlt  <-  ASLN_w$uRevs_AMSSN_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_MDR_vs_QNoAlt    <-  ASLN_w$uRevs_MDR_F_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_ENG_vs_QNoAlt    <-  ASLN_w$uRevs_ENG_F_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt

# z-scores
ASLN_w$ASLN_QAlt_vs_QNoAlt_z   <-  ASLN_w$z_trim_Q_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_AMSSN_vs_QNoAlt_z  <-  ASLN_w$z_trim_AMSSN_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_MDR_vs_QNoAlt_z    <-  ASLN_w$z_trim_MDR_F_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_ENG_vs_QNoAlt_z    <-  ASLN_w$z_trim_ENG_F_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt

# -- Change data layout from Wide2Long -----------------------
# ASLN_L_uRevs <- ASLN_w %>% 
#   select(listener,Age, Group, ASLN_QAlt_vs_QNoAlt, ASLN_AMSSN_vs_QNoAlt,
#          ASLN_MDR_vs_QNoAlt, ASLN_ENG_vs_QNoAlt) %>%
#   pivot_longer(
#     cols = c("ASLN_QAlt_vs_QNoAlt","ASLN_AMSSN_vs_QNoAlt",
#              "ASLN_MDR_vs_QNoAlt","ASLN_ENG_vs_QNoAlt"), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "uRevs") %>%
#   ungroup()

ASLN_L_z <- ASLN_w %>% 
    dplyr::select(listener, Age, Group, ASLN_QAlt_vs_QNoAlt_z, ASLN_AMSSN_vs_QNoAlt_z,
         ASLN_MDR_vs_QNoAlt_z, ASLN_ENG_vs_QNoAlt_z) %>%
  pivot_longer(
    cols = c("ASLN_QAlt_vs_QNoAlt_z","ASLN_AMSSN_vs_QNoAlt_z",
             "ASLN_MDR_vs_QNoAlt_z","ASLN_ENG_vs_QNoAlt_z"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()

###### CCRM ######
# change data from Long2Wide
CCRM_w <- CCRM %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim")) %>%
  ungroup()
colnames(CCRM_w)[1:length(CCRM_w)] <- gsub("-", "_", colnames(CCRM_w[,c(1:length(CCRM_w))]))

# -- get derived scores --------------------------------------
# uRevs
# CCRM_w$CCRM_QAlt_vs_QNoAlt   <-  CCRM_w$uRevs_Q_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_AMSSN_vs_QNoAlt  <-  CCRM_w$uRevs_AMSSN_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_MDR_vs_QNoAlt    <-  CCRM_w$uRevs_MDR_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_ENG_vs_QNoAlt    <-  CCRM_w$uRevs_ENG_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_CCRM_vs_QNoAlt   <-  CCRM_w$uRevs_CCRM_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt

# z-scores
CCRM_w$CCRM_QAlt_vs_QNoAlt_z   <-  CCRM_w$z_trim_Q_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_AMSSN_vs_QNoAlt_z  <-  CCRM_w$z_trim_AMSSN_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_MDR_vs_QNoAlt_z    <-  CCRM_w$z_trim_MDR_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_ENG_vs_QNoAlt_z    <-  CCRM_w$z_trim_ENG_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_CCRM_vs_QNoAlt_z   <-  CCRM_w$z_trim_CCRM_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt

# -- Change data layout from Wide2Long -----------------------
# CCRM_L_uRevs <- CCRM_w %>% 
#   select(listener, Age, Group, CCRM_QAlt_vs_QNoAlt, CCRM_AMSSN_vs_QNoAlt,
#          CCRM_MDR_vs_QNoAlt, CCRM_ENG_vs_QNoAlt,CCRM_CCRM_vs_QNoAlt) %>%
#   pivot_longer(
#     cols = c("CCRM_QAlt_vs_QNoAlt","CCRM_AMSSN_vs_QNoAlt",
#              "CCRM_MDR_vs_QNoAlt","CCRM_ENG_vs_QNoAlt","CCRM_CCRM_vs_QNoAlt"), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "uRevs") %>%
#   ungroup()

CCRM_L_z <- CCRM_w %>% 
    dplyr::select(listener, Age, Group, CCRM_QAlt_vs_QNoAlt_z, CCRM_AMSSN_vs_QNoAlt_z,
         CCRM_MDR_vs_QNoAlt_z, CCRM_ENG_vs_QNoAlt_z,CCRM_CCRM_vs_QNoAlt_z) %>%
  pivot_longer(
    cols = c("CCRM_QAlt_vs_QNoAlt_z","CCRM_AMSSN_vs_QNoAlt_z",
             "CCRM_MDR_vs_QNoAlt_z","CCRM_ENG_vs_QNoAlt_z","CCRM_CCRM_vs_QNoAlt_z"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()
```

```{r, label='ST-CorASL', fig.cap="Add caption here.", fig.align='center', fig.width=8, fig.asp=.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

############ ASL ############
ASLN_w$Group <- factor(ASLN_w$Group,levels=c("APD","TD"))

library(ggExtra)

t1 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_Q_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "Quiet-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_AMSSN_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "AMSSN-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_MDR_F_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "MDR_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_ENG_F_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "ENG_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"),
        legend.position=c(0.85,0.2))

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

library(cowplot)
plot_grid(t1,t2,t3,t4, ncol=2, nrow = 2)
```

```{r, label='ST-CorCCRM', fig.cap="Add caption here.", fig.align='center', fig.width=8, fig.asp=1.2, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
############ CCRM ############
CCRM_w$Group <- factor(CCRM_w$Group,levels=c("APD","TD"))

t1 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_Q_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "Quiet-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_AMSSN_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "AMSSN-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_MDR_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "MDR_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_ENG_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "ENG_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

t5 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_CCRM_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "CCRM_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"),
        legend.direction = "horizontal",
        legend.position=c(0.35,0.905))

t5 <- ggMarginal(t5, type="boxplot",groupFill = TRUE)

plot_grid(t1,t2,t3,t4,t5, ncol=2, nrow = 3)
```


### Spatialised speech-in-noise (LiSNS-UK)

```{r, echo=FALSE,results='hide',message=FALSE,warning=FALSE}

# Load LiSNS data ---------------------------------------------------------------------------------------------------
d_LiSNS <- read.csv(file.path(FileDir,'Files','LiSNS_2020-08-19.csv'),header=T) 

d_LiSNS$CondCode  <- as.factor(revalue(d_LiSNS$CondCode,c("SpchInNz"="SSN", "LiSNS-S0N0"="S0N0", "LiSNS-S0N90"="S0N90")))

d_LiSNS <- d_LiSNS[ ! d_LiSNS$listener %in% "APD08", ] %>% droplevels()

# Add age info ------------------------------------------------------------------------------------------------------
# merge the two dataframes
d_LiSNS <- merge(d_LiSNS,d,by=c("listener"))
colnames(d_LiSNS)[4] <- "Group"
## LONG format ---------------------------------------------

# Convert Long2Wide by uRevs and zScores
d_LiSNS_w <- d_LiSNS %>%
  pivot_wider(
    id_cols = "listener",
    names_from = "CondCode",
    values_from = c("uRevs")) %>%
  ungroup()

# get SRM by listener
d_LiSNS_w$SRM <-  d_LiSNS_w$`S0N0` - d_LiSNS_w$`S0N90`

## get z-scores by speech material

# add age 
d_LiSNS_w <- d %>%
  dplyr::select(listener, Age, Group) %>%
  left_join(d_LiSNS_w, ToAdd, by = "listener")

d_LiSNS_w <- d_LiSNS_w[ ! d_LiSNS_w$listener %in% "APD08", ] %>% droplevels()

# change to long to fit the function
LiSNS <- d_LiSNS_w %>%
  pivot_longer(
    cols = c("SSN","S0N0","S0N90","SRM"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "uRevs") 

```

```{r, label='LiSNS', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}

source("functions/getBestFit.R")

# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
LiSNS$TempRmv <- ifelse((LiSNS$listener %in% c("TD03","TD11") & 
                           LiSNS$CondCode ==c("S0N0"))==TRUE,1,0)

### SSN ###
df <- LiSNS %>% filter(CondCode=="SSN" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"SSN",CutOff,slope1_temp,int1_temp,9.5)
df_1 <- Output[[1]]  # df_All
TD_trimmed_1 = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
# anova.LiSNS <- NULL
# anova.LiSNS[["SSN"]] <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary()
Lstats_1 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_1$listener[which(df_1$Group=="TD")]
B <- TD_trimmed_1$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_1 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}


### S0N0 ###
df <- LiSNS %>% filter(CondCode=="S0N0" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"S0N0",CutOff,slope1_temp,10,8.5,4)
# Output <- getBestFit(LiSNS,"S0N0",CutOff,-1,int1_temp,8,2)
df_2 <- Output[[1]]  # df_All
TD_trimmed_2 = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))

# anova.LiSNS[["S0N0"]] <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary()
Lstats_2 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_2$listener[which(df_2$Group=="TD")]
B <- TD_trimmed_2$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_2 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}


### S0N90 ###
df <- LiSNS %>% filter(CondCode=="S0N90" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

# Output <- getBestFit(LiSNS,"S0N90",CutOff,-1.2,2,11.7,12.1)
Output <- getBestFit(LiSNS,"S0N90",CutOff,slope1_temp,int1_temp,11.7,2)
df_3 <- Output[[1]]  # df_All
TD_trimmed_3 = Output[[11]]
FinalM_3 <- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))

# anova.LiSNS[["S0N90"]] <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary()
Lstats_3 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_3$listener[which(df_3$Group=="TD")]
B <- TD_trimmed_3$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_3 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

### SRM ###
df <- LiSNS %>% filter(CondCode=="SRM" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"SRM",CutOff,0.18,5.7,8.7)
df_4 <- Output[[1]]  # df_All
TD_trimmed_4 = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
L4<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2))

# anova.LiSNS[["SRM"]] <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_4$m$formula(),data=TD_trimmed_4) %>% summary()
Lstats_4 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_4$listener[which(df_4$Group=="TD")]
B <- TD_trimmed_4$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_4 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}

# combine all conditions together
# FinalM.LiSNS <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4)
LiSNS <- data.frame(rbind(df_1,df_2,df_3,df_4))
Lines.LiSNS <- rbind(L1,L2,L3,L4)
Lstats.LiSNS <- rbind(Lstats_1,Lstats_2,Lstats_3,Lstats_4)


# Convert data from Lond2Wide to include SRM zscores
LiSNS_w <- LiSNS %>% 
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim",)) %>%
  ungroup()

# ----------------------------------------------------------------------------------------------
# replace SRM z-scores:
LiSNS_w$z_trim_SRM <-  LiSNS_w$z_trim_S0N0 - LiSNS_w$z_trim_S0N90
  
# ugly but works..
# change again to long format
LiSNS_z <- LiSNS_w %>%
  pivot_longer(
    cols = c("z_trim_SSN","z_trim_S0N0","z_trim_S0N90","z_trim_SRM"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "z_trim") %>%
  ungroup()

LiSNS_z <- data.frame(LiSNS_z)
LiSNS_z <- LiSNS_z %>%
transform(CondCode=str_replace(CondCode,"z_trim_",""))
# change conditions order for the plot
LiSNS_z$CondCode <- factor(LiSNS_z$CondCode,levels=c("SSN", "S0N0", "S0N90", "SRM"))
#levels(LiSNS$group)
LiSNS_z$Group <- factor(LiSNS_z$Group,levels=c("APD", "TD"))

# merge dataframes with uRevs and z-scores together
LiSNS <- LiSNS %>%
  dplyr::select(listener,Group,CondCode,uRevs,predicted) %>%
  left_join(LiSNS_z, ToAdd, by = c("listener","Group","CondCode"))

# get outliers: 
LiSNS <- LiSNS %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(LiSNS,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))

# Some stats --------------------------------------------------------------------------------------------

# summarise condition across listeners 
# uRevs
ddply(LiSNS,~CondCode*Group,summarise,N=length(uRevs),mean=mean(uRevs,na.rm=TRUE),sd=sd(uRevs,na.rm=TRUE), min=min(uRevs,na.rm=TRUE),max=max(uRevs,na.rm=TRUE)) 
# z-trim
ddply(LiSNS,~CondCode*Group,summarise,N=length(z_trim),mean=mean(z_trim,na.rm=TRUE),sd=sd(z_trim,na.rm=TRUE), min=min(z_trim,na.rm=TRUE),max=max(z_trim,na.rm=TRUE)) 

```

```{r,label='LiSNS-AgeAssumptions', echo=FALSE,results='hide',message=FALSE,warning=FALSE,include=FALSE}
################################ Assumptions testing ################################ 

# ---------------- uRevs ------------------------------------------------------------
# linear model
w1 <- lm(uRevs~ CondCode * Group, data = LiSNS)

# 1. Normality (Shapiro-Wilk test) --> is met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(LiSNS$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(LiSNS$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- LiSNS %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> ~ is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=LiSNS,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = LiSNS))

# Option 3:
# per condition
VarTest <- LiSNS %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

# ---------------- z_trim -------------------------------------------------------

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = LiSNS)

# 1. Normality (Shapiro-Wilk test) --> is met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(LiSNS$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(LiSNS$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- LiSNS %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=LiSNS,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = LiSNS))

# Option 3:
# per condition
VarTest <- LiSNS %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

```

```{r, label='LiSNS-ztab', echo=FALSE}

# Some stats and plots--------------------------------------------------------------------------------------------
# summarise condition across listeners 
# z-scores
LiSNS_z_tab_TD <- LiSNS %>% filter(Group=="TD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 
colnames(LiSNS_z_tab_TD)[1] = ""

LiSNS_z_tab_APD <- LiSNS %>% filter(Group=="APD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 

# get table
LiSNS_z_tab <- cbind(LiSNS_z_tab_TD,LiSNS_z_tab_APD[2:6])
colnames(LiSNS_z_tab)[1] = ""

# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(LiSNS_z_tab, escape = F, booktabs = T, caption = "LiSNS standard residuals (z-scores) descriptives by group.",
    align = c("lccccccccc"),format = "latex") %>% 
  add_header_above(c(" ", "TD" = 5, "APD" = 5))
```

#### SRTs by age {.unnumbered}

The distribution of the listeners SRTs and their corresponding regression lines, split by group is shown in Figure\ \@ref(fig:LiSNS-Age) A for the spatially- collocated (S0N0) and separated condition (S0N90), as well as the non-spatialised condition where the ASL sentences were presented with a speech-shaped-noise (SSN). The listeners binaural advantage, calculated as the difference between the collocated and separated spatial conditions (SRM\ =\ S0N0\ -\ S0N90) is shown in Figure \@ref(fig:LiSNS-Age) B. As in the ST task, age effect was tested against the TD group only, where the regression lines for the TD group were determined based on model comparison and outliers trimming procedure to improve the model's fit (model coefficients and statistic is given in the bottom of Figure A and B). 

```{r, label='LiSNS-Age', fig.cap="Scatterplot and linear regression lines for the LiSN-S UK and SPIN SRTs (A) and the derived measure SRM (B) as a function of the listeners age. Corresponding regression coefficients and statistics is provided for TD group only. Red indicates data from the APD group and green indicates data from the TD control group.", fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE}
# get some sub dataframes: 
LiSNS_Col_Sep <- LiSNS %>% filter(CondCode!="SRM" & CondCode!="SSN") %>% droplevels()
LiSNS_Col_Sep  <- drop_na(LiSNS_Col_Sep, uRevs) %>% droplevels()

LiSNS_NoSRM <- LiSNS %>% filter(CondCode!="SRM") %>% droplevels()
LiSNS_NoSRM <- drop_na(LiSNS_NoSRM, uRevs) %>% droplevels()

LiSNS_SRM <- LiSNS %>% filter(CondCode=="SRM") %>% droplevels()
LiSNS_SRM  <- drop_na(LiSNS_SRM, uRevs) %>% droplevels()

LiSNS_SSN <- LiSNS %>% filter(CondCode=="SSN") %>% droplevels()
LiSNS_SSN  <- drop_na(LiSNS_SSN, uRevs) %>% droplevels()

# LiSNS by age (SSN, S0N0 & S0N90)
dat_text.LiSNS <- data.frame(
  label = c(Lines.LiSNS[1],Lines.LiSNS[2],Lines.LiSNS[3]),
  label2 = c(Lstats.LiSNS[1],Lstats.LiSNS[2],Lstats.LiSNS[3]),
  CondCode   = levels(LiSNS_NoSRM$CondCode),
  Group = "TD")

t1 <- ggplot(LiSNS_NoSRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_point(size=2) +
  geom_line(data=filter(LiSNS_NoSRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(LiSNS_NoSRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.LiSNS, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 4)+
  geom_text(data = dat_text.LiSNS, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 4)+
  labs(y = "Speech Reception Threshold, SRT (in dB SNR)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-15,5),breaks=seq(-15,5,2)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y") +
     # ggtitle("LiSNS - Scores by age") + 
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

# LiSNS by age (SRM)
dat_text.LiSNS2 <- data.frame(
  label = c(Lines.LiSNS[4]),
  label2 = c(Lstats.LiSNS[4]),
  CondCode   = levels(LiSNS_SRM$CondCode),
  Group = "TD")

t2 <- ggplot(LiSNS_SRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_point(size=2) +
  geom_line(data=filter(LiSNS_SRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(LiSNS_SRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.LiSNS2, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 4)+
  geom_text(data = dat_text.LiSNS2, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 4)+
  labs(y = "dB",x = "Age (in years)") + 
  scale_y_continuous(limits = c(0,13),breaks=seq(0,13,2)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "none")

t2 <- t2 + facet_grid(. ~ CondCode, scales = "free", switch = "y") +
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

library(patchwork)
(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

As previously reported by other researchers that used similar test paradigm looking into binaural skills(?) in children (e.g., Cameron et al., ,2007; REFs), the scatterplots shows a clear developmental trend, with an overall improvement in performance with increase in age. S0N90 showed the largest age effect, with near to 1 dB improvement in performance per 1 year increase (TD slope = -0.84). The regression lines slope for S0N0 and SSN conditions where shallower, with roughly half a dB improvement in performance per 1 year increase, with a TD slope of -0.51 and -0.47, respectively. Difference in performance with age for the SRM was negligible, with a predicted improvement of circa 1 dB between the age of 7 to 13 years. There was a significant effect of age in all three test conditions (moderate effect size), with the largest effect for S0N0, accounting for circa 40\% of variability in performance, followed by SSN with 34\% and about 26\% for S0N90. The linear regression fit for SRM showed no significant age effect for SRM (R$^{2}$=0.075, p=0.219).

[**LMEM**]{.correction}  
  
  
A two-way factorial design with repeated measures was used to test the main effects for Condition (SSN, SON0, S0N90) and Age with TD group SRTs as dependent variable. Interaction terms were included as well as a random intercept for subjects. Note that the model included only data for the control group and data for SRM was not included. Assumptions of normal distribution and homogeneity were met, and thus a parametric approach was selected based on a linear mixed-effects regression model (LMEM'), using the *lmer()* function (lme4 package, REF). The model that was found to give the best fit and main effects are giving in Table\ \@ref(tab:LiSNS-AgeLMEM). Model selection was based on a backward model selection procedure using a likelihood ratio test ($\chi^{2}$). The final model did not include interaction terms and thus indicating that age affected performance in a similar way in the three test conditions. The model revealed a highly significant main effect of Age and Condition (p < 0.001). 

```{r,label='LiSNS-AgeLMEM', message=FALSE, warning=FALSE, include=FALSE, echo=FALSE,results='hide'}
# Test for age effect -----------------------------------------------------------------------------------

# get TD trimmed data only for SSN, S0N0 & S0N90
TD_trimmed.LiSNS <- rbind(TD_trimmed_1,TD_trimmed_2,TD_trimmed_3)

######## lmer model ##########################################
## Find Best fit 
# start with a saturated model (3-way interaction with age)

model1 <- lmer(uRevs~CondCode*Age+(1|listener), data=TD_trimmed.LiSNS, REML=FALSE)
summary(model1)

(model2<-update(model1,  ~ . - CondCode:Age))
anova(model1,model2)
summary(model2)
# Data: TD_trimmed.LiSNS
# Models:
# model2: uRevs ~ CondCode + Age + (1 | listener)
# model1: uRevs ~ CondCode * Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model2    6 259.12 272.35 -123.56   247.12                     
# model1    8 261.66 279.30 -122.83   245.66 1.4607  2     0.4817

(model3<-update(model2,  ~ . - Age))
anova(model2,model3)
summary(model3)
# model3: uRevs ~ CondCode + (1 | listener)
# model2: uRevs ~ CondCode + Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# model3    5 270.49 281.51 -130.24   260.49                         
# model2    6 259.12 272.35 -123.56   247.12 13.364  1  0.0002565 ***

# best mode --> model 2: uRevs ~ CondCode + Age + (1 | listener)
tab_model(model2)

# ---------------------------------------------------------------------------------
# test main effects:

BestModel <- model2

(BestModel.1 <- update(BestModel,  . ~ . -Age))
Age.LMEM <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: uRevs ~ CondCode + (1 | listener)
# BestModel: uRevs ~ CondCode + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.1    5 270.49 281.51 -130.24   260.49                         
# BestModel      6 259.12 272.35 -123.56   247.12 13.364  1  0.0002565 ***

(BestModel.2 <- update(BestModel,  . ~ . -CondCode))
CondCode.LMEM <-anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: uRevs ~ Age + (1 | listener)
# BestModel: uRevs ~ CondCode + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.2    4 355.48 364.30 -173.74   347.48                         
# BestModel      6 259.12 272.35 -123.56   247.12 100.36  2  < 2.2e-16 ***

# ------------------------------------------------------------------------------
# Post hoc -> individual lm's by condition. (models R^2 and p's are shown in the figure)
# The model suggest that there is a significant age effect and that is the same in 
# all three conditions (since there is no Condition x Age interaction).

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
LiSNS_AgeTab <- data.frame(rbind(
  c("Condition",CondCode.LMEM$Df[2],CondCode.LMEM$Chisq[2],sprintf("\\textbf{<0.001}")),
  c("Age",Age.LMEM$Df[2],Age.LMEM$Chisq[2], sprintf("\\textbf{<0.001}"))))

LiSNS_AgeTab[,c(2:3)]= apply(LiSNS_AgeTab[,c(2:3)], 2, function(x) as.numeric(as.character(x)))

colnames(LiSNS_AgeTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# # -------------------------------------------------------------------------

```

```{r,label='LiSNS-AgeLMEMTab',echo=FALSE,warning=FALSE, message=FALSE}
kbl(LiSNS_AgeTab, booktabs = T,escape = F,caption = "Add caption here.",
    align = c("lccc"),format = "latex",digits = 3) %>% 
  add_header_above(c("SRT ~ Condition + Age + (1 | Subjects)" = 4)) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T) 
```
  
#### Age-independent z-scores {.unnumbered}  
  
Boxplots of the listeners age-independent standardised residuals z-scores (blue circles) collapsed across the different test conditions are shown in Figure \@ref(fig:LiSNS-zfig), separately for the APD group (red) and TD group (cyan). The z-scores were calculated in the exact same way as for the ST task. Again, the dashed line indicate the TD group mean ($\sim$ 0), and the grey area indicate the lower and upper limit of normal population (TD mean $\pm$ 1.96). Descriptive statistics collapsed by group and test conditions are given in Table \@ref(tab:LiSNS-ztab). Overall, when compared with the control group, the APD children exhibited poorer performance (i.e., higher z-score) across all three test conditions as well as for the derived SRM measure.

SSN and S0N0 test conditions yielded the largest separation between the groups, however the spread in scores was relatively large and the percentage of abnormal performance in the APD group was rather small, with circa 16\% (3/19) and 26\% (5/19), respectively. Whereas, only about 10% of the APD children (2/19) had abnormal score for S0N90 test condition and for SRM. No abnormal performance was obtained in the TD group for SSN, S0N90 and SRM, while two TD children (~9\%) had abnormal score for S0N0 condition. 
  
```{r, label='LiSNS-zfig', fig.cap="Add caption here.", fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE}

t1 <- ggplot(LiSNS_NoSRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=1),outlier.shape=NA)+ 
  # scale_fill_manual(values = c("#00BFC4", "#F8766D")) +
  #geom_text(label=d$listener)+
  labs(y = "standardised residual (z-score)",x = "") + 
  guides(fill=guide_legend(title="Group")) + 
  geom_quasirandom(dodge.width=1,shape=1,colour="blue") +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  geom_vline(xintercept=c(1.5,2.5), linetype=1,color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.4, y=2, angle=90, size=5)+
  scale_y_continuous(limits = c(-2,5),breaks=seq(-2,5,1)) +
  scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

t2 <- ggplot(LiSNS_SRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-1.64, ymax=1.64),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=1),outlier.shape=NA)+ 
  # scale_fill_manual(values = c("#00BFC4", "#F8766D")) +
  #geom_text(label=d$listener)+s
  labs(y = "standardised residual (z-score)",x = "", label = "SRM") + 
  guides(fill=guide_legend(title="Group")) + 
  geom_quasirandom(dodge.width=1,shape=1,colour="blue") +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("better performance $\\rightarrow$"),x=0.45, y=0.5, angle=90, size=5)+
  scale_y_continuous(limits = c(-4,3),breaks=seq(-4,3,1)) +
  scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.33)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```
  

[*LMEM model*]{.correction} 
```{r, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE,results='hide'}
##### Test z_trim #####
LiSNS_3 <- LiSNS %>% filter(CondCode!="SRM") %>% droplevels()

# for lmer() analysis see: https://verbingnouns.github.io/notebooks/prose_statistics.nb.html 
# or: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr
# May be useful too: https://exeter-data-analytics.github.io/StatModelling/mixed-effects-models.html#model-checking-with-mixed-models

## --------------------
# [From: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr]
# The model selection process recommended by Zuur et al. (2009) is a top-down strategy and goes as follows:
# 
# 1. fit a full model (he even recommends “beyond optimal” i.e. more complex than you’d expect or want it to be)
# 2. sort out the random effects structure (use REML likelihoods or REML AIC or BIC)
# 3. sort out fixed effects structure (either use REML the F-statistic or the t-statistic or 
#    compare nested ML models - keep your random effects constant)
# 4. once you arrive at the final model present it using REML estimation
## --------------------

##### Select model with the best fit

# Saturated model including 2-way interaction and lower level fixed effects:
model1 <- lmer(z_trim~CondCode*Group+(1|listener), LiSNS_3, REML=FALSE)
summary(model1)
tab_model(model1)

# -----------------------------------------------------------------------------------------------------
# Chose model with the best fit (top-down stepwise method)
# test for best fit by comparing the reduced full model with a simpler model until p is significant  (<.05):
# -----------------------------------------------------------------------------------------------------
(model2<-update(model1,  ~ . - CondCode:Group))
anova(model1,model2)
summary(model2)
# model2: z_trim ~ CondCode + Group + (1 | listener)
# model1: z_trim ~ CondCode * Group + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model2    6 379.56 396.58 -183.78   367.56                     
# model1    8 381.78 404.47 -182.89   365.78 1.7777  2     0.4111

(model3<-update(model2,  ~ . - Group))
anova(model2,model3)
summary(model3)
# model3: z_trim ~ CondCode + (1 | listener)
# model2: z_trim ~ CondCode + Group + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)   
# model3    5 386.23 400.41 -188.12   376.23                        
# model2    6 379.56 396.58 -183.78   367.56 8.6725  1    0.00323 **

# ***** ---> Best model: model2!

# z_trim ~ CondCode + Group + (1 | listener)

# BestModel (model10):
BestModel <- lmer(z_trim ~ CondCode + Group + (1 | listener), data=LiSNS_3, REML=FALSE)
tab_model(BestModel, 
          show.se =TRUE,
          show.stat = TRUE,
          show.icc = FALSE,
          show.ngroups = TRUE,
          show.obs = TRUE)

##### Test main effects:
# -----------------------------------------------------------------------------------------------------
# test main effects by comparing the FULL model to a simplified model without the predictor/interaction term.
# e.g., anova(m1,m2), anova(m1,m3), anova(m1,m4),...
# -----------------------------------------------------------------------------------------------------
# How to deal with main efect testing when there is a significant interaction: see https://stats.stackexchange.com/questions/378652/testing-the-significance-of-a-main-effect-using-model-comparison-when-an-intera

# Group
(BestModel.1 <- update(BestModel,  . ~ . -Group))
Group.Anova <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: z_trim ~ CondCode + (1 | listener)
# BestModel: z_trim ~ CondCode + Group + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)   
# BestModel.1    5 386.23 400.41 -188.12   376.23                        
# BestModel      6 379.56 396.58 -183.78   367.56 8.6725  1    0.00323 **

# CondCode
(BestModel.2<-update(BestModel, . ~ . - CondCode))
CondCode.Anova <- anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: z_trim ~ Group + (1 | listener)
# BestModel: z_trim ~ CondCode + Group + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# BestModel.2    4 379.37 390.71 -185.68   371.37                     
# BestModel      6 379.56 396.58 -183.78   367.56 3.8087  2     0.1489

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
LiSNS_zTab <- data.frame(rbind(
  c("Condition",CondCode.Anova$Df[2],CondCode.Anova$Chisq[2], CondCode.Anova$`Pr(>Chisq)`[2]),
  c("Group",Group.Anova$Df[2],Group.Anova$Chisq[2],Group.Anova$`Pr(>Chisq)`[2])))

LiSNS_zTab[,c(2:4)]= apply(LiSNS_zTab[,c(2:4)], 2, function(x) as.numeric(as.character(x)))

colnames(LiSNS_zTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# mark all the significant p's
LiSNS_zTab$p = ifelse(LiSNS_zTab$p<.05,
                      sprintf("\\textbf{%0.3f}",LiSNS_zTab$p),
                      sprintf("%0.3f",LiSNS_zTab$p))
# -------------------------------------------------------------------------
```
  
  
Differences between the groups for the test SSN as well as the spatialised conditions S0N0 and S0N90 were tested with a 3\ x\ 2 factorial design LMEM model with z-score as a dependent variable and random intercept for subjects. Model assumptions for normal distribution and homogeneity of variance was verified. The model that was found to give the best fit did not include a two-way interaction term between the main effects Group and Condition, thus suggesting again that the two groups behaved in a similar way in the three test conditions (see Table\ \@ref(tab:LiSNS-zLMEM). Comparison of the full model with a simplified model without each of the predictors revealed a significant effect of Group (p < 0.05), while no significant difference in performance between the three conditions was found (p=0.149). 
  
```{r,label='LiSNS-zLMEM',echo=FALSE,warning=FALSE, message=FALSE}
kbl(LiSNS_zTab, booktabs = T,escape = F,caption = "Add caption here.",
    align = c("lccc"),format = "latex",digits = 3) %>% 
  add_header_above(c("z ~ Condition + Group + (1 | Subjects)" = 4)) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T) 
```


[*Correlation between conditions (z-score)*]{.correction}


```{r, label='LiSNS-cor', fig.cap="Add caption here.", fig.align='center', fig.asp=0.5, fig.width=12, out.width='100%', ,echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

library(ggExtra)

t1 <- ggplot(LiSNS_w, aes(x=z_trim_S0N0, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_S0N0", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(LiSNS_w, aes(x=z_trim_SRM, y=z_trim_S0N0, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SRM", "z_trim_"), y = str_remove("z_trim_S0N0", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(LiSNS_w, aes(x=z_trim_SRM, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SRM", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(LiSNS_w, aes(x=z_trim_SSN, y=z_trim_S0N0, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SSN", "z_trim_"), y = str_remove("z_trim_S0N0", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none") 

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

t5 <- ggplot(LiSNS_w, aes(x=z_trim_SSN, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
labs(x = str_remove("z_trim_SSN", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t5 <- ggMarginal(t5, type="boxplot",groupFill = TRUE)

cowplot::plot_grid(t1,t2,t3,t4,t5, ncol=3, nrow = 2)

```

[*comparison with clinical data?*]{.correction}

### The Environmental Auditory Scene Analysis task (ENVASA)

```{r,label='ENVASA-getData', echo=FALSE,results='hide',message=FALSE,warning=FALSE}
## -------------------------------------------------------------------------------------------------------
# Load data and remove outliers first
## -------------------------------------------------------------------------------------------------------
d_ENVASA_w <- read.csv(file.path(FileDir,'Files','ENVASA_2020-09-10.csv'),header=T)
colnames(d_ENVASA_w)[3] <- "Group"
d_ENVASA_w <- d %>%
  dplyr::select(listener, Age) %>%
  right_join(d_ENVASA_w, ToAdd, by = "listener")
d_ENVASA_w <- d_ENVASA_w[,-match(c("X"),names(d_ENVASA_w))]

ENVASA_TD  <- d_ENVASA_w[which(d_ENVASA_w$Group=="TD"),]
mean_TD <- round(mean(ENVASA_TD$IncongHighSNRPC_s),0)
SD_TD <- round(sd(ENVASA_TD$IncongHighSNRPC_s),0)
CutOff_TD <- round(mean_TD - SD_TD,0)
CutOff_TD2 <- round(mean_TD - 2*SD_TD,0)

ENVASA_APD <- d_ENVASA_w[which(d_ENVASA_w$Group=="APD"),]
mean_APD <- mean(ENVASA_APD$IncongHighSNRPC_s)
SD_APD <- sd(ENVASA_APD$IncongHighSNRPC_s)
CutOff_APD <- mean_APD - SD_APD

ENVASA_TD$listener[which(ENVASA_TD$IncongHighSNRPC_s<CutOff_TD)]
ENVASA_TD$IncongHighSNRPC_s[which(ENVASA_TD$IncongHighSNRPC_s<CutOff_TD)]

ENVASA_APD$listener[which(ENVASA_APD$IncongHighSNRPC_s<CutOff_APD)]
ENVASA_APD$IncongHighSNRPC_s[which(ENVASA_APD$IncongHighSNRPC_s<CutOff_APD)]

# remove scores below 2 SD (less conservative approach):
d_ENVASA_w <- d_ENVASA_w[ ! d_ENVASA_w$listener %in% "TD15", ] %>% droplevels()

nTD_ENVASA <- length(d_ENVASA_w$listener[which(d_ENVASA_w$Group=="TD")])
nAPD_ENVASA <- length(d_ENVASA_w$listener[which(d_ENVASA_w$Group=="APD")])

## -------------------------------------------------------------------------------------------------------
# get derived scores & shorten levels names (derived measures are re-calculated again using the z-transformed scores)
## -------------------------------------------------------------------------------------------------------
# Contextual pop-out effect (i.e. incongruent.-congruent)
# Combined data
d_ENVASA_w$Diff_High <- d_ENVASA_w$IncongHighSNRPC - d_ENVASA_w$CongHighSNRPC
d_ENVASA_w$Diff_Low <-  d_ENVASA_w$IncongLowSNRPC - d_ENVASA_w$CongLowSNRPC
d_ENVASA_w$Diff_Total <-d_ENVASA_w$IncongruentPC - d_ENVASA_w$CongruentPC

# Single/dual
d_ENVASA_w$Diff_High_s <- d_ENVASA_w$IncongHighSNRPC_s - d_ENVASA_w$CongHighSNRPC_s
d_ENVASA_w$Diff_Low_s <-  d_ENVASA_w$IncongLowSNRPC_s - d_ENVASA_w$CongLowSNRPC_s
d_ENVASA_w$Diff_Total_s <-d_ENVASA_w$IncongruentPC_s - d_ENVASA_w$CongruentPC_s

d_ENVASA_w$Diff_High_d <- d_ENVASA_w$IncongHighSNRPC_d - d_ENVASA_w$CongHighSNRPC_d
d_ENVASA_w$Diff_Low_d <-  d_ENVASA_w$IncongLowSNRPC_d - d_ENVASA_w$CongLowSNRPC_d
d_ENVASA_w$Diff_Total_d <-d_ENVASA_w$IncongruentPC_d - d_ENVASA_w$CongruentPC_d

d_ENVASA_w$RTLonger_2sPC <- round((d_ENVASA_w$RTLonger_2s/92)*100,2)
d_ENVASA_w$RTLonger_2sPC_s <- round((d_ENVASA_w$RTLonger_2s_s/92)*100,2)
d_ENVASA_w$RTLonger_2sPC_d <- round((d_ENVASA_w$RTLonger_2s_d/92)*100,2)

# Change data layout from Wide2Long:
d_ENVASA_L <- d_ENVASA_w %>%
  pivot_longer(
    cols = c(RTLonger_2s:RTLonger_2sPC_d), 
    names_to = c("CondCode"), 
    names_ptypes = list(CondCode = factor()),
    values_to = "PC") %>% 
    ungroup()

# Single vs dual background
d_ENVASA_L_sd <- d_ENVASA_L[ d_ENVASA_L$CondCode %in%
                               c("CongruentPC_s", "CongLowSNRPC_s", "CongHighSNRPC_s","IncongruentPC_s",
                                 "IncongLowSNRPC_s","IncongHighSNRPC_s","LowSNRPC_s","HighSNRPC_s","TotalPC_s","CatchFalsePC_s",
                                 "RTLonger_2sPC_s","Diff_High_s","Diff_Low_s","Diff_Total_s",
                                 "CongruentPC_d", "CongLowSNRPC_d", "CongHighSNRPC_d","IncongruentPC_d",
                                 "IncongLowSNRPC_d","IncongHighSNRPC_d","LowSNRPC_d","HighSNRPC_d","TotalPC_d","CatchFalsePC_d",
                                 "RTLonger_2sPC_d","Diff_High_d","Diff_Low_d","Diff_Total_d"), ] %>% droplevels()
# combined data only
d_ENVASA_L_c <- d_ENVASA_L[ d_ENVASA_L$CondCode %in%
                               c("CongruentPC", "CongLowSNRPC", "CongHighSNRPC","IncongruentPC",
                                 "IncongLowSNRPC","IncongHighSNRPC","LowSNRPC","HighSNRPC", "TotalPC",
                                 "CatchFalsePC","RTLonger_2sPC","Diff_High","Diff_Low","Diff_Total"), ] %>% droplevels()

d_ENVASA_L_sd$CondCode <- revalue(d_ENVASA_L_sd$CondCode, c("CongruentPC_s"="C_s",
                                                      "CongHighSNRPC_s"="C_High_s", 
                                                      "CongLowSNRPC_s"="C_Low_s",
                                                      "IncongruentPC_s"="I_s",
                                                      "IncongHighSNRPC_s"="I_High_s",
                                                      "IncongLowSNRPC_s"="I_Low_s",
                                                      "LowSNRPC_s"="Low_s",
                                                      "HighSNRPC_s"="High_s",
                                                      "TotalPC_s"="Total_s",
                                                      "CatchFalsePC_s"="CatchFalse_s",
                                                      "RTLonger_2sPC_s"="RTLonger_2s_s",
                                                      "Diff_High_s"="DiffHigh_s",
                                                      "Diff_Low_s"="DiffLow_s",
                                                      "Diff_Total_s"="DiffTotal_s",

                                                      "CongruentPC_d"="C_d",
                                                      "CongHighSNRPC_d"="C_High_d", 
                                                      "CongLowSNRPC_d"="C_Low_d",
                                                      "IncongruentPC_d"="I_d",
                                                      "IncongHighSNRPC_d"="I_High_d",
                                                      "IncongLowSNRPC_d"="I_Low_d",
                                                      "LowSNRPC_d"="Low_d",
                                                      "HighSNRPC_d"="High_d",
                                                      "TotalPC_d"="Total_d",
                                                      "CatchFalsePC_d"="CatchFalse_d",
                                                      "RTLonger_2sPC_d"="RTLonger_2s_d",
                                                      "Diff_High_d"="DiffHigh_d",
                                                      "Diff_Low_d"="DiffLow_d",
                                                      "Diff_Total_d"="DiffTotal_d"))

d_ENVASA_L_c$CondCode <- revalue(d_ENVASA_L_c$CondCode, c("CongruentPC"="C",
                                                          "CongHighSNRPC"="C_High",
                                                          "CongLowSNRPC"="C_Low",
                                                          "IncongruentPC"="I",
                                                          "IncongHighSNRPC"="I_High",
                                                          "IncongLowSNRPC"="I_Low",
                                                          "LowSNRPC"="Low",
                                                          "HighSNRPC"="High",
                                                          "TotalPC"="Total",
                                                          "CatchFalsePC"="CatchFalse",
                                                          "RTLonger_2sPC"="RTLonger_2s",
                                                          "Diff_High"="DiffHigh",
                                                          "Diff_Low"="DiffLow",
                                                          "Diff_Total"="DiffTotal")) 

# remove non-raw conditions 
d_ENVASA_L_sd_raw <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in%
                               c("C_Low_s","C_High_s","I_Low_s","I_High_s",
                                 "C_Low_d","C_High_d","I_Low_d","I_High_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode, "_s")=="TRUE","Single","Dual")
# get SNR / Congruent/Incongruent info:
d_ENVASA_L_sd_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
d_ENVASA_L_sd_raw$SNR <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode,"High")=="TRUE","High","Low")

d_ENVASA_L_sd_raw$BackgroundType <- factor(d_ENVASA_L_sd_raw$BackgroundType , levels = c("Single","Dual"))
d_ENVASA_L_sd_raw$MaskerType <- factor(d_ENVASA_L_sd_raw$MaskerType , levels = c("Congruent","Incongruent"))
d_ENVASA_L_sd_raw$SNR <- factor(d_ENVASA_L_sd_raw$SNR , levels = c("Low","High"))

# get dataframe with difference scores
d_ENVASA_L_sd_diff <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in% 
                                    c("DiffHigh_s","DiffLow_s","DiffTotal_s",
                                      "DiffHigh_d","DiffLow_d","DiffTotal_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_diff$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_diff$CondCode, "_s")=="TRUE","Single","Dual")
d_ENVASA_L_sd_diff$BackgroundType <- factor(d_ENVASA_L_sd_diff$BackgroundType , levels = c("Single","Dual"))
# get SNR info:
d_ENVASA_L_sd_diff$SNR <- ifelse(str_detect(d_ENVASA_L_sd_diff$CondCode,"High")=="TRUE","High","Low")
d_ENVASA_L_sd_diff$SNR <- factor(d_ENVASA_L_sd_diff$SNR , levels = c("Low","High"))

# get dataframe with difference scores
d_ENVASA_L_c_diff <- d_ENVASA_L_c[ d_ENVASA_L_c$CondCode %in% 
                                    c("DiffHigh","DiffLow","DiffTotal"), ] %>% droplevels()
# get dataframe for combined scores
d_ENVASA_L_c_Total <- d_ENVASA_L_c[ d_ENVASA_L_c$CondCode %in% "Total", ] %>% droplevels()

# get dataframe for combined scores
d_ENVASA_L_Total  <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in%
                               c("Total_s","Total_d"), ] %>% droplevels()

d_ENVASA_L_Total <- rbind(d_ENVASA_L_Total,d_ENVASA_L_c_Total)
```
Due to technical problems, data for six listeners is missing (TD: 2; APD: 4), resulting in a total sample-size of 21 and 17 for the TD and APD group, respectively. Initial inspection of the individuals performance was performed to ensure that the task instructions were followed and well understood. Performance for the reference condition (single incongruent background at a high SNR), which is expected to least impact performance, was compared with a cut-off criterion of `r CutOff_TD2` %, calculated as 2 SD from the TD group mean (`r mean_TD` % $\pm$ `r SD_TD` %). Individuals with performance bellow the cut-off criterion were excluded from the analysis. One TD listener aged 7 years old scored 45 % was thus excluded, resulting in a total of 20 listeners in the TD group.

```{r, label='ENVASA-getZ',echo=FALSE,results='hide',message=FALSE,warning=FALSE}
## -------------------------------------------------------------------------------------------------------
# get z-transformed scores 
## -------------------------------------------------------------------------------------------------------
# fit individual models with and without a knot per condition & group and compare them:

source("Functions/getBestFit.R")

# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # Output[[11]] : TD trimmed data
  # --------------------------------------------

#Change PC name to uRevs (ugly solution to use getZ...)
colnames(d_ENVASA_L_sd)[5] <- "uRevs"
colnames(d_ENVASA_L_c)[5] <- "uRevs"

### Total_s ###
df <- d_ENVASA_L_sd %>% filter(CondCode=="Total_s" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(d_ENVASA_L_sd,"Total_s",CutOff,1,int1_temp)
df_1 <- Output[[1]]  # df_All
TD_trimmed_1 = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
Slopes.ENVASA <- NULL
Slopes.ENVASA["Total_s"] <- FinalM_1$m$getPars()[1]
# anova.ENVASA <- NULL
# anova.ENVASA[["Total_s"]] <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_1$m$formula(),data=TD_trimmed_1) %>% summary()
Lstats_1 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_1$listener[which(df_1$Group=="TD")]
B <- TD_trimmed_1$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_1 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}


### Total_d ###
df <- d_ENVASA_L_sd %>% filter(CondCode=="Total_d" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(d_ENVASA_L_sd,"Total_d",CutOff,1,int1_temp)
df_2 <- Output[[1]]  # df_All
TD_trimmed_2 = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2 <- sprintf("slope = %s, intcpt = %s, brk = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2),
             round(FinalM_2$m$getAllPars()[3],2))
Slopes.ENVASA["Total_d"] <- FinalM_2$m$getPars()[1]
# anova.ENVASA[["Total_d"]] <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_2$m$formula(),data=TD_trimmed_2) %>% summary()
Lstats_2 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_2$listener[which(df_2$Group=="TD")]
B <- TD_trimmed_2$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_2 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}


### Total ###
df <- d_ENVASA_L_c %>% filter(CondCode=="Total" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(d_ENVASA_L_c,"Total",CutOff,1,int1_temp)
df_3 <- Output[[1]]  # df_All
TD_trimmed_3 = Output[[11]]
FinalM_3 <- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3 <- sprintf("slope = %s, intcpt = %s, brk = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2),
             round(FinalM_3$m$getAllPars()[3],2))
Slopes.ENVASA["Total"] <- FinalM_3$m$getPars()[1]
# anova.ENVASA <- NULL
# anova.ENVASA[["Total"]] <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary() %>% coefficients(.) %>% data.frame() %>% slice_tail()

LineStats <- lm(FinalM_3$m$formula(),data=TD_trimmed_3) %>% summary()
Lstats_3 <- sprintf("R^2 = %s, p = %s",
             round(LineStats$r.squared,3),
             round(LineStats$coefficients[8],3))

# get removed listeners:
A <- df_3$listener[which(df_3$Group=="TD")]
B <- TD_trimmed_3$listener
Rmv <- setdiff(A,B)
if (!is.null(Rmv)){df_3 %>% filter(listener %in% Rmv) %>% dplyr::select(., listener, Age, uRevs, z_trim)}


################ combine all conditions together #####################
FinalM.ENVASA <- list(FinalM_1,FinalM_2,FinalM_3)
ENVASA_Total <- rbind(df_1,df_2,df_3) %>% 
  dplyr::select(listener,Age,Group,CondCode,PC=uRevs,predicted,z_trim) 
Lines.ENVASA <- rbind(L1,L2,L3)
LStats.ENVASA <- rbind(Lstats_1,Lstats_2,Lstats_3)
TD_trimmed.ENVASA <- rbind(TD_trimmed_1,TD_trimmed_2,TD_trimmed_3) %>% 
  dplyr::select(listener,Age,Group,CondCode,PC=uRevs,z) 

# get outliers: 
ENVASA_Total <- ENVASA_Total %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim < -CutOff,1,0))

ddply(ENVASA_Total,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))

# change from Long2Wide format to get derived measures
ENVASA_Total_w <- ENVASA_Total %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("z_trim","PC")) %>%
  ungroup()

## -------------------------------------------------------------------------------------------------------
# get derived measures
## -------------------------------------------------------------------------------------------------------

# # Contextual pop-out effect (i.e. incongruent.-congruent)
# # Combined data
# d_ENVASA_c_w$Diff_High  <- d_ENVASA_c_w$I_High - d_ENVASA_c_w$C_High
# d_ENVASA_c_w$Diff_Low   <- d_ENVASA_c_w$I_Low - d_ENVASA_c_w$C_Low
# d_ENVASA_c_w$Diff_Total <- d_ENVASA_c_w$I - d_ENVASA_c_w$C
# 
# # Single/dual
# d_ENVASA_sd_w$Diff_High_s  <- d_ENVASA_sd_w$I_High_s - d_ENVASA_sd_w$C_High_s
# d_ENVASA_sd_w$Diff_Low_s   <- d_ENVASA_sd_w$I_Low_s - d_ENVASA_sd_w$C_Low_s
# d_ENVASA_sd_w$Diff_Total_s <- d_ENVASA_sd_w$I_s - d_ENVASA_sd_w$C_s
# 
# d_ENVASA_sd_w$Diff_High_d  <- d_ENVASA_sd_w$I_High_d - d_ENVASA_sd_w$C_High_d
# d_ENVASA_sd_w$Diff_Low_d   <- d_ENVASA_sd_w$I_Low_d - d_ENVASA_sd_w$C_Low_d
# d_ENVASA_sd_w$Diff_Total_d <- d_ENVASA_sd_w$I_d - d_ENVASA_sd_w$C_d
# 
# # change data from Wide2Long
# d_ENVASA_L_sd_z <- d_ENVASA_sd_w %>%
#   pivot_longer(
#     cols = c(CatchFalse_s:Diff_Total_d), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "zScore") %>% 
#   ungroup()
# 
# d_ENVASA_L_c_z <- d_ENVASA_c_w %>%
#   pivot_longer(
#     cols = c(CatchFalse:Diff_Total),
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "zScore") %>% 
#   ungroup()
# 
# ## -------------------------------------------------------------------------------------------------------
# # get separate data frames for the different plots
# ## -------------------------------------------------------------------------------------------------------
#                               
# # remove non-raw conditions 
# d_ENVASA_L_sd_z_raw <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in%
#                                c("C_Low_s","C_High_s","I_Low_s","I_High_s",
#                                  "C_Low_d","C_High_d","I_Low_d","I_High_d"), ] %>% droplevels()
# 
# # get background info (single/dual)                                      
# d_ENVASA_L_sd_z_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode, "_s")=="TRUE","Single","Dual")
# # get SNR / Congruent/Incongruent info:
# d_ENVASA_L_sd_z_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
# d_ENVASA_L_sd_z_raw$SNR <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode,"High")=="TRUE","High","Low")
# 
# d_ENVASA_L_sd_z_raw$BackgroundType <- factor(d_ENVASA_L_sd_z_raw$BackgroundType , levels = c("Single","Dual"))
# d_ENVASA_L_sd_z_raw$MaskerType <- factor(d_ENVASA_L_sd_z_raw$MaskerType , levels = c("Congruent","Incongruent"))
# d_ENVASA_L_sd_z_raw$SNR <- factor(d_ENVASA_L_sd_z_raw$SNR , levels = c("Low","High"))
# 
# # get dataframe with difference scores
# d_ENVASA_L_sd_z_diff <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in% 
#                                     c("DiffHigh_s","DiffLow_s","DiffTotal_s",
#                                       "DiffHigh_d","DiffLow_d","DiffTotal_d"), ] %>% droplevels()
# 
# # get background info (single/dual)                                      
# d_ENVASA_L_sd_z_diff$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_z_diff$CondCode, "_s")=="TRUE","Single","Dual")
# d_ENVASA_L_sd_z_diff$BackgroundType <- factor(d_ENVASA_L_sd_z_diff$BackgroundType , levels = c("Single","Dual"))
# # get SNR info:
# d_ENVASA_L_sd_z_diff$SNR <- ifelse(str_detect(d_ENVASA_L_sd_z_diff$CondCode,"High")=="TRUE","High","Low")
# d_ENVASA_L_sd_z_diff$SNR <- factor(d_ENVASA_L_sd_z_diff$SNR , levels = c("Low","High"))
# 
# # get dataframe for combined scores
# d_ENVASA_L_sd_z_Total <- d_ENVASA_L_sd_z <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in%
#                                c("Total_s","Total_d"), ] %>% droplevels()
# 
# # remove non-raw conditions 
# d_ENVASA_L_c_z_raw <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in%
#                                c("C_Low","C_High","I_Low","I_High",
#                                  "C_Low","C_High","I_Low","I_High"), ] %>% droplevels()
# 
# # get dataframe with difference scores
# d_ENVASA_L_c_z_diff <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in% 
#                                     c("DiffHigh","DiffLow","DiffTotal"), ] %>% droplevels()
# 
# # get dataframe for combined scores
# d_ENVASA_L_c_z_Total <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in% "Total", ] %>% droplevels()
# 
# # get background info (single/dual)                                      
# d_ENVASA_L_c_z_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode, "_s")=="TRUE","Single","Dual")
# # get SNR / Congruent/Incongruent info:
# d_ENVASA_L_c_z_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
# d_ENVASA_L_c_z_raw$SNR <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode,"High")=="TRUE","High","Low")
# 
# d_ENVASA_L_c_z_raw$BackgroundType <- factor(d_ENVASA_L_c_z_raw$BackgroundType , levels = c("Single","Dual"))
# d_ENVASA_L_c_z_raw$MaskerType <- factor(d_ENVASA_L_c_z_raw$MaskerType , levels = c("Congruent","Incongruent"))
# d_ENVASA_L_c_z_raw$SNR <- factor(d_ENVASA_L_c_z_raw$SNR , levels = c("Low","High"))
# 
# # combine scores
# d_ENVASA_L_Total_z <- rbind(d_ENVASA_L_sd_z_Total,d_ENVASA_L_c_z_Total)
```

```{r, label='ENVASA-AgeAssumptions', eval=TRUE, include=FALSE, warning=FALSE}
############### Test parametric assumptions for PC by age (TD trimmed only) ###############

w1 <- lm(PC~ CondCode*Age, data = TD_trimmed.ENVASA)

#### normality (shapiro-wilk) ###########
# linearity is met if p>.05
# Option 1:
shapiro.test(residuals(w1))
# p-value = 0.3278 --> normaly distr.

#### Homogeneity of variance (Levene's test) ###########
# homogeneity is met if p>.05

# Option 1: Is the lmer model fully covered here?
leveneTest(residuals(w1) ~ CondCode,data = TD_trimmed.ENVASA)
# p=0.2067 --> homogeneity is met!
```

```{r, label='ENVASA-AgeLMEM', eval=TRUE, include=FALSE, warning=FALSE}

# Test for age effect -----------------------------------------------------------------------------------
######## simple anova per condition ##########################################

# Anova.ENVASA <- aov(PC~CondCode*Age, data = TD_trimmed.ENVASA) %>% summary(.)

######## lmer model ##########################################################
## Find Best fit 
# start with a saturated model (3-way interaction with age)

model1 <- lmer(PC~CondCode*Age+(1|listener), data=TD_trimmed.ENVASA, REML=FALSE)
summary(model1)

(model2<-update(model1,  ~ . - CondCode:Age))
anova(model1,model2)
summary(model2)
# model2: PC ~ CondCode + Age + (1 | listener)
# model1: PC ~ CondCode * Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model2    6 378.95 391.42 -183.47   366.95                     
# model1    8 382.50 399.12 -183.25   366.50 0.4539  2      0.797

(model3<-update(model2,  ~ . - Age))
anova(model2,model3)
summary(model3)
# model3: PC ~ CondCode + (1 | listener)
# model2: PC ~ CondCode + Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# model3    5 390.92 401.30 -190.46   380.92                         
# model2    6 378.95 391.42 -183.47   366.95 13.967  1  0.0001861 ***

# best mode --> model 2: PC ~ CondCode + Age + (1 | listener)
tab_model(model2)

# ---------------------------------------------------------------------------------
# test main effects:

BestModel <- model2

(BestModel.1 <- update(BestModel,  . ~ . -Age))
Age.LMEM <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: PC ~ CondCode + (1 | listener)
# BestModel: PC ~ CondCode + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.1    5 390.92 401.30 -190.46   380.92                         
# BestModel      6 378.95 391.42 -183.47   366.95 13.967  1  0.0001861 ***

(BestModel.2 <- update(BestModel,  . ~ . -CondCode))
CondCode.LMEM <-anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: PC ~ Age + (1 | listener)
# BestModel: PC ~ CondCode + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.2    4 395.88 404.19 -193.94   387.88                         
# BestModel      6 378.95 391.42 -183.47   366.95 20.933  2  2.847e-05 ***

# ------------------------------------------------------------------------------
# Post hoc -> individual lm's by condition. (models R^2 and p's are shown in the figure)
# The model suggest that there is a significant age effect and that is the same in 
# all three conditions (since there is no Condition x Age interaction).

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
ENVASA_AgeTab <- data.frame(rbind(
  c("Condition",CondCode.LMEM$Df[2],CondCode.LMEM$Chisq[2],sprintf("\\textbf{<0.001}")),
  c("Age",Age.LMEM$Df[2],Age.LMEM$Chisq[2], sprintf("\\textbf{<0.001}"))))

ENVASA_AgeTab[,c(2:3)]= apply(ENVASA_AgeTab[,c(2:3)], 2, function(x) as.numeric(as.character(x)))

colnames(ENVASA_AgeTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# # -------------------------------------------------------------------------
```

#### %-correct by age {.unnumbered}
The ENVASA measurements in the current study strictly followed the same 2 (single-/dual-background) x 4 (SNRs: -6, -3, 0 +3 dB) factorial design as used by ????, resulting in a total of 92 test response (%-correct) per listener or between 10 to 11 test items per background/SNR combination. Because of the small test items per condition, the listeners %-correct was combined into three different measures: i. a *single background*, ii. a *dual backgrounds*, iii. and a *combined*. 

The relationship between performance and age was inspected in the same way as carried out for the other auditory tasks, with the listeners combined scores are plotted as a function age, with linear regression lines, model coefficients and statistics for the trimmed TD group (see Figure \@ref(fig:ENVASA-Age)). The regression lines reveals a noticeable developmental trend in all three measures, where performance improved with increase of age. A regular linear regression line with a monotonic linear increase in performance by age was found to best fit performance for a single background, with an increase of circa 3.5% in score per year. Performance for dual backgrounds and the combined measure on the other hand were best described using segmented linear regression models, with an increase of performance by circa 12\% per year until the age of 9 years old where performance plateaued. Age was statistically tested using an LMEM model with Condition and Age as fixed factors and \%-correct (PC) as dependent variable and a random intercept for subjects (reference level: single-background). A model without an interaction term was found to give the best fit (see Table ???). Model comparison was performed on the selected model, comparing it to a reduced model where each of the fixed terms were singly removed, revealing a highly significant main effect of age and condition (p<0.001). This is in agreement with @Krishnan2013 study where they found a strong developmental effect across normal-hearing typically developing children in a similar age range to those measured in the present study.

```{r,label='ENVASA-Age', fig.cap="Scatterplot and linear regression lines for the ENVASA task \\%-correct as a function of age for single background, dual backgrounds and the combined measure. Red indicates data from the APD group and cyan indicates data from the TD control group.", fig.align='center', fig.width=11, fig.asp=0.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE}
# Total PC scores by age

dat_text.ENVASA <- data.frame(
  label = Lines.ENVASA,
  label2 = matrix(LStats.ENVASA),
  CondCode   = levels(ENVASA_Total$CondCode),
  Group = "TD")

###### ASL ##############
t1 <- ggplot(ENVASA_Total, aes(x=Age, y=PC, color=Group)) +
  geom_point(size=2,alpha=1) +
  # geom_text(label=ENVASA_Total$listener, size=3)+
  geom_line(data=filter(ENVASA_Total, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(ENVASA_Total,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.ENVASA, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 4.5)+
  geom_text(data = dat_text.ENVASA, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 4.5)+
  labs(y = "% correct",x = "Age") + 
  scale_y_continuous(limits = c(30,100),breaks=seq(30,100,10))+
  scale_x_continuous(breaks=seq(7,13,1),labels=c("7","8","9","10","11","12","13"),limits=c(7, 13))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                      labeller = labeller(CondCode = c("Total_s" ="Single background",
                                                       "Total_d"="Dual backgrounds",
                                                       "Total"="Combined"))) +
  theme(panel.spacing.x = unit(0,"line"),
        strip.background = element_rect(fill="white", color="white"),
        strip.text = element_text(face = "bold", size = 11))
t1
```

```{r,label='ENVASA-AgeLMEMTab',echo=FALSE,warning=FALSE, message=FALSE}
kbl(ENVASA_AgeTab, booktabs = T,escape = F,caption = "Add caption here.",
    align = c("lccc"),format = "latex",digits = 3) %>% 
  add_header_above(c("PC ~ Condition + Age + (1 | Subjects)" = 4)) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T) 
```

```{r, label='ENVASA-zAssumptions', eval=TRUE, include=FALSE, warning=FALSE}
############### Test parametric assumptions for z-scores ###############

# ------------------------------------------------
# 1. Normality (Shapiro test) 
# linear model

w1 <- lm(z_trim~ CondCode*Group, data = ENVASA_Total)

# Option 1:
shapiro.test(residuals(w1))
# p-value = 6.442e-05 ---> normal distr is rejected!

# Option 2:
NormTest <- ENVASA_Total %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)
# --> this is because of non-normal distr. in the APD group.. 

# ------------------------------------------------
# 2. Homogeneity of variance test (Levene's test)
# Interpretation: homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim~ CondCode*Group, data=ENVASA_Total)
# Results: p value = 0.0326 * --> assumption of homogeneity is NOT met!
# Interpretation: test is significant, i.e., the null hypothesis that the variance is not equal cannot be accepted.

```

#### Age-independent z-scores {.unnumbered}
Thus, for further analysis, age was controlled for using the same multiple-case approach method described in ????.

Boxplots of the age-independent z-scores for the three ENVASA measures are shown in Figure \@ref(fig:ENVASA-zPlot), with larger z-scores indicating better performance. The grey area indicate the upper and lower cut-off (z = $\pm$ 1.96) for normal score, where only about 95 % of the normal population scores are expected to lay within. Single background condition yielded the largest separation between the group with a median z-score of roughly -1, while the median performance for dual backgrounds and the combined score was relatively similar to those in the control group. The percentage of abnormal APD scores was relatively low, with circa 29\% (5/17) for the combined score Total,  24\% (4/17) for single background and 18\% (3/17) for dual backgrounds condition. 

A two-way interaction between Group and Condition (2\ x\ 3 factorial design data with repeated measures) was tested with a non-parametric robust aligned rank test using npIntFactRep package (REF). Mauchly's test indicated that the assumption of sphericity for the two-way interaction term had been violated (p<0.001), therefore the degrees of freedom were corrected using Greenhouse-Geisser estimate of sphericity ($\varepsilon$=0.55). The test showed a significant two-way interaction between Group and Condition [F(1.64,57.57)=10.82, p<0.001]. Difference between the groups were examined using using Wilcoxon rank-sum test with permutation (N=999999) for independent two samples test which is a t-test equivalent for non-parametric data ('coin::wilcox_test()'; REF). Groups descriptive scores collapsed by the three test measures as well as p statistics and effect size r are given in Table \@ref(tab:ENVASA-zTab). Performance of children in the APD group was significantly poorer than the TD children in the single background condition (p=0.02, moderate effect), whereas no significant difference between the groups were found for dual backgrounds or the combined measure (p>0.05).

```{r, label='ENVASA-zPlot', fig.cap="ENVASA age-independent standardised residuals for the \\%-correct in single background, dual backgrounds and the combined measure. Residuals were calculated seperately for each condition and are based on a model predicton for TD group only. The grey area represents the deviance cut-off for abnormal score (SD $\\pm$\ 1.96 below/above the TD mean), where about 95\\% of the normal population is e expected to lay within. The dashed line represents the theorethical TD group mean (z = 0).", fig.align='center', fig.width=6, fig.asp=.8, out.width='80%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# ENVASA_Total_Outlier <- ENVASA_Total[which(ENVASA_Total$z_trim< -CutOff),] %>% droplevels()
# ggplot(ENVASA_Total_Outlier, aes(x=listener, fill = Group)) + geom_histogram(alpha = .5, bins=25, position = "identity",stat="count") + theme_classic()
# var_select = c("listener")
# count_freq = count(ENVASA_Total_Outlier, var_select)

t1 <- ggplot(ENVASA_Total, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,shape=1,colour="blue")+
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  labs(y = "standardised residual (z-score)" ,x = NULL)+ 
scale_y_continuous(limits = c(-7,2),breaks=seq(-7,2,1))+
  scale_x_discrete(labels=c("Total_s" ="Single background","Total_d"="Dual backgrounds",
                            "Total"="Combined"))+
  annotate("text", label = latex2exp::TeX("better performance $\\rightarrow$"), x = 0.5, y = -2, size = 4, angle = 90, colour = "black")+
  # geom_text(aes(label = ifelse(ASLN$z_trim>1.65,ASLN$listener,"")),
            # position = position_dodge2(width = .8,padding = 0.1))+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"))
t1
```

```{r,label='ENVASA-nparLD1', message=FALSE, warning=FALSE, include=FALSE, results='hide'}
# 2-way factorial design:

# OPTION 1: nparLD
ENVASA_Total <- data.frame(ENVASA_Total)

ENVASA.nparLD_all <- nparLD(z_trim ~ CondCode * Group, data = ENVASA_Total, subject = "listener", description = TRUE, plot.CI=TRUE)

ENVASA.nparLD_all <- data.frame(round(ENVASA.nparLD_all$ANOVA.test,3))
# --> sig. effect for condcode. no difference between groups

#                Statistic   df p.value
# Group              2.482 1.00   0.115
# CondCode           4.239 1.23   0.031
# Group:CondCode     2.066 1.23   0.146

# OPTION 2: npIntFactRep
ENVASA_Total_w_all <- ENVASA_Total_w[,1:6]
ENVASA_Total_w_all <- data.frame(ENVASA_Total_w_all) 
colnames(ENVASA_Total_w_all)[1] = "subj"
npIntFactRep.ENVASA_all <- npIntFactRep::npIntFactRep(ENVASA_Total_w_all)
print(npIntFactRep.ENVASA_all)
# --> Sphericity is violated. use GG correction.
# --> Regular ranks shows sig. Group:CondCode interaction p=6.806667e-05 

# Apply correction for degree of freedom due to non-sphericity: multiple each df with it's corresponding epsilon
# gg_e <- 0.5483168 # Greenhouse-Geisser GGe
# df1 <- round(3 * gg_e,3)
# df2 <- round(105 * gg_e,3)
```

```{r eval=FALSE, include=FALSE}
# OPTION 3: ez::ezPerm

# Perm.ENVASA_all <- ez::ezPerm(
#     data = ENVASA_Total
#     , dv = z_trim
#     , wid = listener
#     , within = CondCode
#     , between = Group
#     , perms = 1e3
#     , parallel = FALSE
#     , alarm = FALSE
# )
# 
# print(Perm.ENVASA_all)
# --> sig. main effect for Group and CondCode
#           Effect     p p<.05
# 1          Group 0.017     *
# 2       CondCode 0.033     *
# 3 Group:CondCode 0.068  
```

```{r,label='ENVASA-nparLD2', message=FALSE, warning=FALSE, include=FALSE, results='hide'}
# --------------------------------------------------------------------------
# Try without combined measure:

# OPTION 1: nparLD
ENVASA_Total_ds <- ENVASA_Total %>% filter(CondCode!="Total") %>% droplevels()
ENVASA_Total_ds <- data.frame(ENVASA_Total_ds) 

ENVASA.nparLD_ds <- nparLD(z_trim ~ CondCode * Group, data = ENVASA_Total_ds, subject = "listener", description = TRUE, plot.CI=TRUE)

ENVASA.nparLD_ds <- data.frame(round(ENVASA.nparLD_ds$ANOVA.test,3))
# --> sig. effect for condcode. no difference between groups (p=0.057)
#                Statistic df p.value
# Group              3.631  1   0.057
# CondCode           4.116  1   0.042
# Group:CondCode     2.553  1   0.110


# OPTION 2: npIntFactRep
ENVASA_Total_w_ds <- ENVASA_Total_w[,1:5]
ENVASA_Total_w_ds <- data.frame(ENVASA_Total_w_ds) 
colnames(ENVASA_Total_w_ds)[1] = "subj"
npIntFactRep.ENVASA <- npIntFactRep::npIntFactRep(ENVASA_Total_w_ds)
print(npIntFactRep.ENVASA)
# --> sphericity is violated (use GG correction).
# --> Regular ranks shows sig. Group:CondCode interaction p=9.743992e-05 
```

```{r eval=FALSE, include=FALSE}
# OPTION 3: ez::ezPerm

# Perm.ENVASA_ds <- ez::ezPerm(
#     data = ENVASA_Total_ds
#     , dv = z_trim
#     , wid = listener
#     , within = CondCode
#     , between = Group
#     , perms = 1e3
#     , parallel = FALSE
#     , alarm = FALSE
# )
# 
# print(Perm.ENVASA_ds)
# --> sig. main effect for Group and CondCode
#           Effect     p p<.05
# 1          Group 0.022     *
# 2       CondCode 0.035     *
# 3 Group:CondCode 0.088      

```

```{r eval=FALSE, include=FALSE, label='ENVASA-Tab-nparLD'}
ENVASA.nparLD$p.value = ifelse(ENVASA.nparLD$p.value<.05,sprintf("\\textbf{%0.3f}",ENVASA.nparLD$p.value),ENVASA.nparLD$p.value)
colnames(ENVASA.nparLD)[3] <- "p-value"
row.names(ENVASA.nparLD) <- c("Group","Condition","Group:Condition")

kbl(ENVASA.nparLD,booktabs = T, escape = F,caption = "Statistical analysis for the effects of Group and Condition as well as their interaction (2x3 factorial design with repeated measures) tested with a robust rank-based method for analysis of nonparametric data using nparLD package (REF). Analysis was based on a f1-ld-f1 design ANOVA-type statistic (ATS) test, whereby the first f1 refers to an experimental design with one between-subjects factor (Group) and the seconf f1 refers to a single within-subjects factor (Condition).",
    align = c("lccc"),format = "latex",digits = 3) %>%
  add_footnote(c("significant p-values (p < 0.05) are shown in bold."), notation = "symbol") %>%
  column_spec(4, italic = T)

# use this if you want to fore latex to print the table in an exact location!
# latex_options = c("hold_position")
```

```{r,label='ENVASA-zTab',echo=FALSE,warning=FALSE,message=FALSE}
# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Condition
# --------------------------------------------------------------------------------------------------
source("functions/getPermWilcoxInd.R")

Output <- getPermWilcoxInd(ENVASA_Total,"z_trim","Group","CondCode")
ENVASA_Wilcox <- data.frame(Output[[2]])
ENVASA_Wilcox <- ENVASA_Wilcox[,- c(1,4)]
ENVASA_Wilcox[,c(2:3)]= apply(ENVASA_Wilcox[,c(2:3)], 2, function(x) as.numeric(as.character(x)))
ENVASA_Wilcox$p = ifelse(ENVASA_Wilcox$p<.05,sprintf("\\textbf{%.02f}",ENVASA_Wilcox$p),ENVASA_Wilcox$p)
colnames(ENVASA_Wilcox)[1] <- sprintf("95\\%%-CI")
# get table
ENVASA_tab <- ENVASA_Total %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
ENVASA_tab <- ENVASA_tab[,-grep("Group",colnames(ENVASA_tab))]
# APD first then TD
ENVASA_tab <- cbind(ENVASA_tab[1:3,1:ncol(ENVASA_tab)],
                    ENVASA_tab[4:nrow(ENVASA_tab),2:ncol(ENVASA_tab)],
                    ENVASA_Wilcox)
ENVASA_tab$CondCode <- c("Single","Dual","Combined")
colnames(ENVASA_tab)[1] = "background"

# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(ENVASA_tab, booktabs = T,escape = F,caption = "Descriptive of the ENVASA standard residuals (z-scores) split by groups and test measures.",
    align = c("lcccccccccc"),format = "latex",digits = 2) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 1, "APD" = 5, "TD" = 5, "Wilcoxon rank-sum test" = 4)) %>%
  column_spec(c(7,12),border_left = T) %>%
  column_spec(13, italic = T)
```


### CELF-RS

```{r, label='CELF-getData', echo=FALSE,warning=FALSE,message=FALSE,results='hide'}

d_RS<- read.csv(file.path(FileDir,'Files','CELF_RS_13032020.csv'),header=T)

# merge data frames to include extra info
d_RS <- merge(d_Info,d_RS,by=c("listener"))

d_RS$Group <- factor(d_RS$Group,levels=c("APD","TD"))

describeBy(ScaledScore~Group, data=d_RS, mat=TRUE, digits=3)
```

```{r, label='CELF-Assumptions', echo=FALSE,warning=FALSE,message=FALSE,results='hide'}
# Assumptions:

# linear model
w1 <- lm(ScaledScore ~ Group, data = d_RS)

# 1. Normality (Shapiro-Wilk test) --> ~is met!
# data is normally distributed if p >.05

# QQ plot of residuals
# qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
# par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
# qqnorm(d_RS$ScaledScore, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
# qqline(d_RS$ScaledScore, col = "red", lwd = 2)
# qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
# qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))
# p-value = 0.05976

# Option 2 by conditions:
NormTest <- d_RS %>%
  group_by(Group) %>%
  rstatix::shapiro_test(ScaledScore)

# 2. Homogeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05
car::leveneTest(ScaledScore ~ Group, data=d_RS,center=median)
# p=0.3554
```

```{r, label='CELF-Stats', echo=FALSE,warning=FALSE,message=FALSE,results='hide'}
# --------------------------------------------------------------------------------------------------
# Parametric test assumptions are met -> t-test is used.
# boot.t.test is the same as the regular t.test function but with bootstrapping.
RS_ttest <- MKinfer::boot.t.test(ScaledScore~ Group, data = d_RS, paired = FALSE,conf.level = 0.95, R = 9999)
# --------------------------------------------------------------------------------------------------
# get table
RS_tab_TD <- d_RS %>% filter(Group=="TD") %>%
ddply(.,~Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),
      SD=round(sd(ScaledScore,na.rm=TRUE),2),min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) 

RS_tab_APD <- d_RS %>% filter(Group=="APD") %>%
ddply(.,~Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),
      SD=round(sd(ScaledScore,na.rm=TRUE),2),min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) 

# RS_tab <- cbind(RS_tab_TD[2:6],RS_tab_APD[2:6],p=round(results_p,3),effectSize[c(4,7)])
RS_tab <- cbind(RS_tab_TD[2:6],RS_tab_APD[2:6])
```

Boxplots of children's age-corrected scaled scores split into groups for the CELF-5 UK Recalling Sentences subtest are given in Figure \@ref(fig:CELF). The grey area indicate the upper and lower norms limit among the normal population ($\pm$ 1 SD).

On average, performance was within the norms range in both the APD group (median = `r RS_tab_APD$median`) and the TD group, albeit laying within the upper norms limit (median = `r RS_tab_TD$median`). Thus, although the majority of the APD children expressive language skills were within the norms, the figure reveals a clear difference in performance between the group, where the TD children expressive language skills are noticeably better than for children in the APD group. 

Almost half of the TD children obtained a scaled score above the average and none exhibited abnormal scores. On the other hand, only three APD children performed above the average and performance of two children was considered to be abnormal (scaled score =  6).

An independent-samples t-test with bootstrapping (n=9999) was computed using *boot.t.test()* function (MKinfer package, REF) to compare the listeners scaled scores in the two groups (parametric data assumptions were met). There was a highly significant difference in scaled scores between the APD (M\ =\ 9.5, SD\ =\ 2.7) and TD group (M\ =\ 13.6, SD\ =\ 3.1) [t(`r round(RS_ttest$parameter,2)`) = `r round(RS_ttest$statistic,2)`, p\ <\ 0.001]. 

```{r, label='CELF', fig.cap="Boxplots for CELF-5 UK Recall Sentences subtest scaled scores by groups. The dashed line represents the norms mean and the grey area indicate the upper and lower limit of an average performance in the normal population ($\\pm$\ 1\ SD).", fig.align='center', fig.width=3, fig.asp=1, out.width='50%', ,echo=FALSE,warning=FALSE, message=FALSE}
# get plot
ggplot(d_RS, aes(x=Group,y=ScaledScore,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=7, ymax=13),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  #geom_text(label=d_RS$listener)+
  labs(y = "Scaled score",x = "Group")+ 
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(1,19),breaks=seq(1,19,2))+
  scale_x_discrete(labels=c("APD","TD"))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))
```

### Questionnaires

#### CCC-2

```{r, label='CCC2-getData', echo=FALSE,warning=FALSE,message=FALSE,results='hide'}

d_CCC2<- read.csv(file.path(FileDir,'Files','CCC2_13032020.csv'),header=T)

# Arrange table
colnames(d_CCC2)[8] <- "A.speech"
colnames(d_CCC2)[10] <- "C.semantic"
d_CCC2$group.diagnosis[d_CCC2$group.diagnosis == "1"] <- "APD"
d_CCC2$group.diagnosis[d_CCC2$group.diagnosis == "2"] <- "TD"
d_CCC2$group.diagnosis <- factor(d_CCC2$group.diagnosis,levels=c("APD","TD"))

# delete some columns
# Clean data
d_CCC2[is.na(d_CCC2),]
d_CCC2 <- na.omit(d_CCC2) # remove rows with missing data
# use data only if ConsistencyCheck equal to 1
d_CCC2 <- d_CCC2 %>% filter(ConsistencyCheck==1) %>% droplevels() 
# d_CCC2 <- d_CCC2[,-match(c("date.of.CCC","dob","informant","GCC","SPC","pass.consistency.check...1.yes..0.no.","neg.mean","pos.mean"),names(d_CCC2))] %>% droplevels() 

# --> TD13 was removed due to inconsistent responses

# change format from wide 2 long
library(tidyr)
d_CCC2_L <- gather(d_CCC2,group.diagnosis, gender, A.speech:J.interests, factor_key=TRUE)

# change columns names
colnames(d_CCC2_L)[1] <- "listener"
colnames(d_CCC2_L)[2] <- "DOB"
colnames(d_CCC2_L)[4] <- "Age"
colnames(d_CCC2_L)[9] <- "Measure"
colnames(d_CCC2_L)[10] <- "ScaledScore"

# convert age from months to years
d_CCC2_L$Age <- round(d_CCC2_L$Age/12,2)

# get groups association
# library(stringr)
d_CCC2_L$Group <- ifelse((str_detect(d_CCC2_L$listener,"APD")=="TRUE"),"APD","TD")
d_CCC2_L$ScaledScore <- as.numeric(as.character(d_CCC2_L$ScaledScore))
d_CCC2_L$Group <- factor(d_CCC2_L$Group,levels=c("APD","TD"))
#str(d_CCC2_L)

# merge data frames  -----------------------------------------------------------------------------------------------
d_CCC2_L <- merge(d_Info,d_CCC2_L,by=c("listener"))
# d_CCC2_L <- d_CCC2_L[,-match(c("Group.y"),names(d_CCC2_L))]
# colnames(d_CCC2_L)[2] = "Group"

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects
if (RmvSubj==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include subjects based on the quality of their testing 
if (QualityCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_E_L$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis 
if (DiagCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns
if (APDsubTypCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$Subtype %in% rmvAPDType, ] %>% droplevels()}
## ------------------------------------------------------------------------------------------------------------------

# Check for scores that are cilincally significant
LowScore_CCC2 <- d_CCC2_L %>% filter(ScaledScore<=4) 
# get frequency per listener
SigLowScore_CCC2 <- data.frame(table(LowScore_CCC2$listener))
colnames(SigLowScore_CCC2)[1] <- "listener"

# Filter listners with significant scores
SigLowScore_CCC2 <- SigLowScore_CCC2 %>% filter(Freq>=2) %>% droplevels() 

Sig_listeners<-levels(SigLowScore_CCC2$listener)
length(Sig_listeners)
# listeners has sig low scores: APD=18; TD=1
```

Data for one TD listener was flagged as inconsistent and was thus removed from the analysis. The groups descriptives for the parental reposts in the different sub-scales as well as the GCC and SIDC sum of scores composites are given in Table\ \@ref(tab:CCC-Tab). GCC stands for general communication composite, calculated by taking the sum for scaled scores A to H. It is used to clinically identify abnormal communication skills, defined by a GCC < 55 (10$^{th}$ percentile). The SIDC stands for social-interaction deviance composite [sum(E+H+I+J)-sum(A+B+C+D)]. A combination of abnormal GCC and a negative SIDC has been found to be indicative of ASD traits (Bishop, 2003; Norbury et al., 2005?).

Boxplots of the two groups scaled scores for the different sub-scales and a scatterplot depicting the relationship between GCC and SIDC are shown in Figure\ \@ref(fig:CCC-plot) A-B, respectively. A striking 90\% of the APD children (18/20) obtained a scaled score below the 5th percentile two or more times, which has been found to indicate clinically significant communication problems (Bishop 2003). Whereas, only one such case was found in the TD group.

The GCC cut-off was found to well separate between the two groups, where 90\% of the APD children (18/20) had abnormal score, whereas less only one TD child (out of 22) had abnormal communication skills (see Figure \@ref(fig:CCC-plot) B). Half of the APD children with abnormal GCC score (45\%, 9/20) exhibited a score pattern that is indicative of SLI, whereas the other half exhibited an ASD pattern. Interestingly, out of the nine APD children who fell within the ASD category, three were reported by their parents to have an HF-ASD diagnosis, and additional two children were undergoing an ASD assessment at the time of testing (see scores marked with open circles in Figure\ \@ref(fig:CCC-plot) B).

Difference between the two groups for GCC was tested using an independent-samples t-test with bootstrapping (MKinfer::boot.t.test(), REF;n=9999). There was a highly significant difference in GCC between the APD (M =, SD = ) and TD group (t(39.80) = -9.42, p < 0.001). 

```{r, label='CCC2-plot', fig.cap="CCC-2 questionnaire parental reports for the APD (red) and TD group (cyan). (A) Boxplots for scaled scores in the ten sub-scales. (B) Scatterplot for General Communication Composite (GCC) as a function of Social-Interaction Deviance Composite, (SIDC). APD children with diagnosed high-functioning Autism (HF-ASD) are denoted with open circles. APD children with undergoing ASD assessment on the day of testing are marked with open rectangles. The lines indicates the cut-off criteria for typically developing children (TD), children with specific language impairment (SLI) and ASD (cf. Ferguson et al., 2011).", fig.align='center', fig.width=21, fig.asp=.4, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# Data without subjects with significantly low scores
# d_CCC2_L_Clean <- d_CCC2_L[ ! d_CCC2_L$listener %in% Sig_listeners, ] %>% droplevels()

t1 <- ggplot(d_CCC2_L, aes(x=Measure,y=ScaledScore,fill=Group))+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+
  #geom_text(label=d_CCC2_L$listener)+
  labs(y = "Scaled Score",x = "Measure")+
  guides(fill=guide_legend(title="Group"))+
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(0,16),breaks=seq(0,16,2))+
  #scale_x_discrete(labels=c("TD","APD"))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=10, face="bold"),
        axis.title.y = element_text(size=10, face="bold"),
        legend.title = element_text(size=10, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))

# plot GCC and mark subjects with a combination of negative SPC in red (indicative of ASD)
SumScores <- subset(d_CCC2_L, Measure=="A.speech") %>% droplevels() 
SumScores$Abnormal <- ifelse(SumScores$SPC<0 & SumScores$GCC<55,1,0)

t2 <- ggplot(SumScores, aes(x=GCC,y=SPC,color=Group))+
  geom_point(size=2) +
  geom_point(aes(x=GCC,y=SPC),data=filter(SumScores,listener %in%
                                            c("APD16","APD20","APD21")),shape=1,size=4,show.legend = FALSE) +
  geom_point(aes(x=GCC,y=SPC),data=filter(SumScores,listener %in%
                                              c("APD06","APD09","APD18")),shape=0,size=4,show.legend = FALSE) +
  geom_segment(aes(x=0,xend=55,y=0,yend=0), color="black",size=0.5)+
    geom_vline(xintercept=55, color="black",size=1)+
    # geom_text(label=SumScores$listener)+
  labs(y = "Social-Interaction Deviance Composite (SIDC)",x = "General Communication Composite (GCC)")+
  guides(color=guide_legend(title="Group"))+
  scale_y_continuous(limits = c(-20,20),breaks=seq(-20,20,10))+
  scale_x_continuous(limits = c(0,120),breaks=seq(0,120,20),expand = c(0, 0))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=10, face="bold"),
        axis.title.y = element_text(size=10, face="bold"),
        legend.title = element_text(size=10, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 0.9), widths = c(1,0.4)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))

# t2 <- ggplot(SumScores, aes(x=Group,y=GCC,fill=Group))+
#   geom_boxplot(position=position_dodge(width=0.8),show.legend = FALSE,outlier.shape=NA)+
#   geom_hline(yintercept=55, linetype="dashed", color = "black")+
#   # geom_text(label=d_CCC2_L$listener)+
#   labs(y = "sum of scaled scores (sub-scales A-H)",x = "")+
#   guides(fill=guide_legend(title="Group"))+
#   geom_quasirandom(aes(x=Group),data=filter(SumScores,Abnormal=="0"),dodge.width=0.8,colour="blue", shape=1, show.legend = FALSE)+
#   geom_quasirandom(aes(x=Group),data=filter(SumScores,Abnormal=="1"),dodge.width=0.8,shape=8, show.legend = FALSE)+
#   scale_y_continuous(limits = c(0,110),breaks=seq(0,110,20))+
#   theme(strip.background = element_blank())+
#   theme_bw()+
#   theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
#         axis.title.x = element_text(size=11, face="bold"),
#         axis.title.y = element_text(size=11, face="bold"),
#         legend.title = element_blank(),
#         legend.text  = element_blank(),
#         legend.position = "none")

# (t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.12)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
#   theme(legend.position='bottom',        
#         legend.direction = "horizontal",
#         legend.background = element_blank(),
#         legend.box.background = element_rect(colour = "black"),
#         plot.tag = element_text(face = 'bold'))

```

```{r, label='CCC-Tab', echo=FALSE,warning=FALSE,message=FALSE}
# get table
CCC2_tab <- d_CCC2_L %>% ddply(.,~Measure*Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),sd=round(sd(ScaledScore,na.rm=TRUE),2), min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)

CCC2_tab <- CCC2_tab[,-grep("Group",colnames(CCC2_tab))]
# APD first then TD
CCC2_tab <- cbind(CCC2_tab[1:10,1:ncol(CCC2_tab)],
                    CCC2_tab[11:nrow(CCC2_tab),2:ncol(CCC2_tab)])
# Add summary scores
GCC <- SumScores %>% ddply(.,~Group,summarise,N=length(GCC),median=round(median(GCC,na.rm=TRUE),2),sd=round(sd(GCC,na.rm=TRUE),2), min=round(min(GCC,na.rm=TRUE),2),max=round(max(GCC,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)

SPC <- SumScores %>% ddply(.,~Group,summarise,N=length(SPC),median=round(median(SPC,na.rm=TRUE),2),sd=round(sd(SPC,na.rm=TRUE),2), min=round(min(SPC,na.rm=TRUE),2),max=round(max(SPC,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)

CCC2_extra <- cbind("Measure" = c("GCC","SIDC"),
                    rbind(GCC[1,2:6],SPC[1,2:6]),
                    rbind(GCC[2,2:6],SPC[2,2:6]))

CCC2_tab <- rbind(CCC2_tab,CCC2_extra)
rownames(CCC2_tab) <- c()
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(CCC2_tab, booktabs = T,escape = F,caption = "CCC-2 subscales descriptives split by groups.",
    align = c("lccccccccccc"),format = "latex",digits = 2) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 1, "APD" = 5, "TD" = 5)) %>%
  add_footnote(c("GCC: General Communication Composite sum(A+B+C+D+E+F+G+H)","SIDC: Social Interaction Deviance Composite sum(E+H+I+J)-sum(A+B+C+D)"), notation = "none") %>%
  column_spec(c(7),border_left = T) 
```


Discussion:
- Compare data with Ferguson et al. 2011

```{r, label='CCC-Stats', echo=FALSE,warning=FALSE,message=FALSE,results='hide'}
# Assumptions:

# linear model
w1 <- lm(GCC ~ Group, data = SumScores)

# 1. Normality (Shapiro-Wilk test) --> ~is met!
# data is normally distributed if p >.05

# Option 1:
shapiro.test(residuals(w1))
# p-value = 0.05179

# Option 2 by conditions:
NormTest <- SumScores %>%
  group_by(Group) %>%
  rstatix::shapiro_test(GCC)

# 2. Homogeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05
car::leveneTest(GCC ~ Group, data=SumScores,center=median)
# p=0.973

# t-test with bootstrapping for GCC:
# Parametric test assumptions are met -> t-test is used.
# boot.t.test is the same as the regular t.test function but with bootstrapping.
CCC2_ttest <- MKinfer::boot.t.test(GCC~ Group, data = SumScores, paired = FALSE,conf.level = 0.95, R = 9999)
# p-value < 2.2e-16 -> sig

```





#### ECLIPS
```{r, label='ECLIPS-getData', echo=FALSE,warning=FALSE,message=FALSE}

d_E<- read.csv(file.path(FileDir,'Files','ECLIPS_13032020.csv'),header=T)

d_E$Group <- factor(d_E$Group,levels=c("APD","TD"))

d_E_ScaledScore <- d_E %>% filter(ScoreType=="Scaled Score") %>% droplevels() 

library(tidyr)
d_E_L <- gather(d_E_ScaledScore,Sex, Age, SAP:Total, factor_key=TRUE)

colnames(d_E_L)[4] <- "Measure"
colnames(d_E_L)[5] <- "ScaledScore"

d_E_L$ScaledScore <- as.numeric(as.character(d_E_L$ScaledScore))
# rename measures for the plot
d_E_L$Measure <- revalue(d_E_L$Measure, c("SAP"="SAP","LLL"="L/L/L","M.A"="M&A",
                                          "PSS"="PSS","EAS"="EAS","Listening"="Listening",
                                          "Language"="Language","Social"="Social","Total"="Total"))
# merge data frames  -----------------------------------------------------------------------------------------------
d_E_L <- merge(d_Info,d_E_L,by=c("listener"))
# d_E_L <- d_E_L[,-match(c("Group.y"),names(d_E_L))]
# colnames(d_E_L)[2] = "Group"

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects
if (RmvSubj==1){d_E_L <- d_E_L[ ! d_E_L$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include subjects based on the quality of their testing 
if (QualityCtrl==1){d_E_L <- d_E_L[ ! d_E_L$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis 
if (DiagCtrl==1){d_E_L <- d_E_L[ ! d_E_L$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns 
if (APDsubTypCtrl==1){d_E_L <- d_E_L[ ! d_E_L$Subtype %in% rmvAPDType, ] %>% droplevels()}
## ------------------------------------------------------------------------------------------------------------------

```
- Missing data

- Table

- Figure

- How many abnormal kids in each group

```{r, label='ECLIPS-plot', fig.cap="Add caption here.", fig.align='center', fig.width=10, fig.asp=.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
ggplot(d_E_L, aes(x=Measure,y=ScaledScore,fill=Group))+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+
  geom_hline(yintercept=5, linetype="dashed", color = "red")+
  #geom_text(label=d_E_L$listener)+
  labs(y = "ECLiPS Scaled Score",x = "Measure")+
  guides(fill=guide_legend(title="Group"))+
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(min(d_E_L$ScaledScore),max(d_E_L$ScaledScore)),breaks=seq(min(d_E_L$ScaledScore),max(d_E_L$ScaledScore),2))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))
```

```{r, label='ECLIPS-Tab', echo=FALSE,warning=FALSE,message=FALSE}
# get table
ECLIPS_tab <- d_E_L %>% ddply(.,~Measure*Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),sd=round(sd(ScaledScore,na.rm=TRUE),2), min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)

ECLIPS_tab <- ECLIPS_tab[,-grep("Group",colnames(ECLIPS_tab))]
# APD first then TD
ECLIPS_tab <- cbind(ECLIPS_tab[1:9,1:ncol(ECLIPS_tab)],
                    ECLIPS_tab[10:nrow(ECLIPS_tab),2:ncol(ECLIPS_tab)])
rownames(ECLIPS_tab) <- c()
colnames(ECLIPS_tab)[3] = sprintf("M\\&A")

# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(CCC2_tab, booktabs = T,escape = F,caption = "ECLiPS descriptives split by groups.",
    align = c("lccccccccccc"),format = "latex",digits = 2) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 1, "APD" = 5, "TD" = 5)) %>%
  add_footnote(c("Add note here"), notation = "none") %>%
  column_spec(c(7),border_left = T) 
```

```{r,label='ECLIPS-stats',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# --------------------------------------------------------------------------------------------------
# Assumptions:
ECLiPS_Total <- d_E_L %>% filter(Measure=="Total") %>% droplevels() 

# linear model
w1 <- lm(ScaledScore ~ Group, data = ECLiPS_Total)

# 1. Normality (Shapiro-Wilk test) --> ~is met for TD, but not for APD
# data is normally distributed if p >.05

# QQ plot of residuals
# qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
# par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
# qqnorm(d_RS$ScaledScore, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
# qqline(d_RS$ScaledScore, col = "red", lwd = 2)
# qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
# qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- ECLiPS_Total %>%
  group_by(Group) %>%
  rstatix::shapiro_test(ScaledScore)

# 2. Homoggeneity of variance (Levene's test) --> is NOT met!
# homogeneity is met if p>.05
# Option 1:
car::leveneTest(ScaledScore ~ Group, data=ECLiPS_Total,center=median)
# p = 0.0001759 ***
# Option 2: 

# --------------------------------------------------------------------------------------------------
# ==> Nonparametric t-test:
source("functions/getPermWilcoxInd.R")

Output <- getPermWilcoxInd(ECLiPS_Total,"ScaledScore","Group","Measure")
ECLiPS_Wilcox <- data.frame(Output[[2]])
ECLiPS_Wilcox <- ECLiPS_Wilcox[,- c(1,4)]
ECLiPS_Wilcox[,c(2:3)]= apply(ECLiPS_Wilcox[,c(2:3)], 2, function(x) as.numeric(as.character(x)))
ECLiPS_Wilcox$p = ifelse(ECLiPS_Wilcox$p<.05,sprintf("\\textbf{< 0.001}"),ECLiPS_Wilcox$p)
colnames(ECLiPS_Wilcox)[1] <- sprintf("95\\%%-CI")

```


- parametric assumptions are not fulfilled. Wilcox test. 



## Discussion


*Points for age effect:*   
- Goldsworthy et al. 2018 found that age explained only a small portion of variability in speech perception performance (n.s.) for Quiet, SSN and 2-talker connected-speech distractors (children aged 5-17). See table 3.

*Points for SSN:*   
- "Despite mature peripheral encoding, school-children have more difficulty understanding speech in noise compared with adults. For example, 5-7 year-old children require 3 to 6 dB more favourable SNR than adults to achieve comparable speech detection, word identification, or sentence recognition performance in a speech-shaped noise maker (e.g., Corbin et al., 2016)" [Leibold, Buss and Calandruccio, 2019, Acoustics today].
- "Speech recognition gradually improves until 9-10 years of age , after which mature performance is generally observed" [Leibold, Buss and Calandruccio, 2019, Acoustics today].

- SSN age effect in other studies are smaller

## Conclusion

\clearpage

```{=html}
<!-- clearpage ends the page, and also dumps out all floats.
  Floats are things like tables and figures. -->
```
