---
output:
  #bookdown::html_document2: default
  #bookdown::word_document2: default
  bookdown::pdf_document2:
    template: templates/brief_template.tex
    latex_engine: xelatex
documentclass: book
bibliography: references.bib
---

# APD study {#APD-study}

\chaptermark{APD study}

\minitoc <!-- this will include a mini table of contents-->

## Introduction

## Methods

### Participants

```{r, include=FALSE}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(plyr)){install.packages("plyr")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(psych)){install.packages("psych")}
if(!require(english)){install.packages("english")}
if(!require(stringr)){install.packages("stringr")}
if(!require(nparLD)){install.packages("nparLD")}
if(!require(apa)){install.packages("apa")}


require(ggplot2)
require(ggbeeswarm)
require(dplyr)
require(plyr)
require(psych)
require(english)
require(stringr)
require(knitr)
require(kableExtra)
require(tidyr)
require(lme4)
require(sjPlot)
require(car)
require(ggpubr)
require(patchwork)
require(coin)
require(effsize)
require(rstatix)
require(graphics)
require(nparLD)
require(apa)

## Initialisation ----------------------------------------------------------------------------------------------------
date <- Sys.Date()
FileDir <- getwd()

# deviance level for abnormal z-score
CutOff <- 1.96# 1.65

# Filter buttons------------------------------------------------------------------------------------------------------
# 1. Remove NA's and observations with bad adaptive tracks 
CleanData <- 0 # On=1/Off=0 button

# 2. Remove specifc subjects 
RmvSubj <- 1 # On=1/Off=0 button
Subj2Remove <-c("APD14")  #"TD11"

# 3. Remove subjects based on their quality evaluation made by the examiner on the testing day 
QualityCtrl <- 0 # On=1/Off=0 button
rmvEval <- c("Bad") #  "Good" / "Maybe" / "Bad"

# 4. Remove APD subjects based on their diagnosis 
DiagCtrl <- 0 # On=1/Off=0 button
rmvDiag <- c("LiD","susAPD") #  "APD" / "LiD" (i.e., AP deficit and not a DISORDER) / "susAPD"

# 5. Removce APD subjects WITHOUT SPD patterns 
APDsubTypCtrl <- 0 # On=1/Off=0 button
rmvAPDType <- c(NA, "MissingReoprt") #  "SPD"

# 6. Remove outliers |z| > 2 
rmvOutlrs_z = 0
# 7. Remove outliers Cook's distance D
rmvOutlrs_D <- 0
# --------------------------------------------------------------------------------------------------------------------

# get demographics ---------------------------------------------------------------------------------------------------
d<- read.csv(file.path(FileDir,'Files','AllListenersDemographics_SK.csv'),header=T) 

# Clean data
d[is.na(d),]
d <- na.omit(d) # remove rows with missing data

# calculate age from DOB and testing day
if(!require(eeptools)){install.packages("eeptools")}
library(eeptools)

d$Age <- age_calc(as.Date(d$DOB,"%d/%m/%Y"),
                   as.Date(d$TestDate,"%d/%m/%Y"),
                   units = "years", precise = TRUE)
d$Age <- round(d$Age,1)

#unique(d$listener)
#length(unique(d$listener))

# get additional demographics -------------------------------------------------------------------------------------- 
d_Info <- read.csv(file.path(FileDir,'Files','BackgroundInfo.csv'),header=T)
d_Info <- d_Info[,-match(c("DOB", "TestingDay","Age", "Sex","Group"),names(d_Info))]

# merge data frames  -----------------------------------------------------------------------------------------------
d <- merge(d_Info,d,by=c("listener"))
cols <- c("AuditoryTraining","EarProblems","EarProblemsDur","SLT","Grommets","MusicalTraining","FMuse","Otoscopy","NrmlSpchUnderstanding")
d[cols] <- lapply(d[cols], factor)

# Filter data by groups  -------------------------------------------------------------------------------------------
TD <- d %>% filter(Group=="TD") %>% droplevels() 
APD <- d %>% filter(Group=="APD") %>% droplevels()
SexFreq_APD <- count(APD,"Sex")
DiagFreq <- count(APD,"Diagnosis")
SPDFreq <- count(APD,"Subtype")
ClinicFreq <- count(APD,"Clinic")

TD_Age <- describe(TD$Age)
APD_Age <-describe(APD$Age)

Age_min <- ifelse(TD_Age$min >APD_Age$min,TD_Age$min,APD_Age$min)
Age_max <- ifelse(TD_Age$max >APD_Age$max,TD_Age$max,APD_Age$max)

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects 
if (RmvSubj==1){d <- d[ ! d$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include / Subjects based on the quality of their testing 
if (QualityCtrl==1){d <- d[ ! d$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis
if (DiagCtrl==1){d <- d[ ! d$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns 
if (APDsubTypCtrl==1){d <- d[ ! d$Subtype %in% rmvAPDType, ] %>% droplevels()}


# -------------------------------------------------------------------------------------------------------------------

# Filter data by groups  -------------------------------------------------------------------------------------------
Clean.TD <- d %>% filter(Group=="TD") %>% droplevels() 
Clean.APD <- d %>% filter(Group=="APD") %>% droplevels() 

Clean.TD_Age <- describe(Clean.TD$Age)
Clean.APD_Age <-describe(Clean.APD$Age)

SexFreq_Clean.APD <- count(Clean.APD,"Sex")
DiagFreq.Clean <- count(Clean.APD,"Diagnosis")
SPDFreq.Clean <- count(Clean.APD,"Subtype")
ClinicFreq.Clean <- count(Clean.APD,"Clinic")

SexFreq_Clean.TD <- count(Clean.TD,"Sex")

# Test for age difference between the groups
# use Welch approximation t-test due to the uneven sample size

Age.t_test <- t.test(Age~ Group, data=d, conf.level = 0.95, paired = FALSE)
# Results: t = 3.43, df = 40.955, p-value = 0.00139
# There is a significant difference between the groups, with APD children on average ~2 years older than the TD children.

test <- glm(Age ~ Group, data=d)
summary(test)
```

`r  Hmisc::capitalize(as.character(as.english(sum(TD_Age$n,APD_Age$n),english.UK = TRUE)))` primary school children native British English speakers with normal hearing acuity participated in the study. Amongst them `r as.english(sum(APD_Age$n)-1,english.UK = TRUE)` belonged to the APD clinical group (`r SexFreq_APD[1,2]` females) with an average age of `r round(Clean.APD_Age$mean,2)` $\pm$ `r round(Clean.APD_Age$sd,2)` years (range: `r round(Clean.APD_Age$min,2)` - `r round(Clean.APD_Age$max,2)` years). One APD child was excluded from the analysis due to raised thresholds (PTA\>25 dB HL). APD children were recruited in two ways. Children diagnosed with APD at Great Ormond Street Hospital (GOSH) and at the London Hearing and Balance Centre (LHBC), London, UK, and fulfilled the recruitment criteria were identified and contacted by a clinical team member. The parents/caregivers were provided with information about the study and means of contact to express interest in participation. Others were recruited by advertisements in social networks, where parents were requested to fill-out an interest form that included screening questions to ensure they fulfil the participation requirements. [To add percentage for clinics, diagnosed/LiD/susAPD and SPD pattern?]{.correction} The remaining `r as.english(sum(TD_Age$n),english.UK = TRUE)` (`r SexFreq_Clean.TD[1,2]` females) comprised of typically developing control children (TD) with no reported concerns or diagnosis of a language or other cognitive developmental disorders. The TD group average age was `r round(Clean.TD_Age$mean,2)` $\pm$ `r round(Clean.TD_Age$sd,2)` years and ranged between `r round(Clean.TD_Age$min,2)` to `r round(Clean.TD_Age$max,2)` years (A detailed description of the groups is shown in Tab. ??).

Difference in variance for age between the two groups was tested using t-test with Welch degrees of freedom correction for uneven sample-size, showing a significant difference in age between the groups [t(`r round(Age.t_test$parameter,2)`)=`r  round(Age.t_test$statistic,2)`, p=`r round(Age.t_test$p.value,3)`].

The project was approved by the UCL Research Ethics Committee (Project ID Number 0544/006) and the NHS Health Research Authority HRA (REC reference: 18/LO/0250). The testing commenced once an informed consent was given by both the parent/caregiver and the child.

-   Background questionnaire
-   Otoscopic examination was carried out to ensure the eardrum is visible, healthy and intact.
-   Location of the testing
-   duration of the session

Participants from both TD and APD group completed the same battery of tests listed below

### Auditory evaluation

#### Standard audiometry

```{r, label='PTA', fig.cap="APD participants pure-tone audiogram thresholds for standard frequencies plotted for the left and the right ear (black). The shaded grey area represents the TD group range of audiometric thresholds and the white line represents the mean at each frequency. The dashed line represents the threshold criteria of hearing level $\\leq$ 25\ dB\ HL.", echo=FALSE, fig.align='center', figures-side, out.width='85%',fig.width=12, fig.height=6}

# Define axes
# xaxis=c(1:8) # number of frequencies tested
# 250	500	1000	2000	4000	6000	8000
FreqAxis=c("0.25","0.5","1","2","4","8")
frqs=c(0.25,0.5,1,2,4,8)

# min and max of y axis
max	=	max((d[1:nrow(d),28:39]),na.rm=T) + 17
min	=	min(d[1:nrow(d),28:39],na.rm=T) - 10

# Plot overlapping individual audiograms of test group, mean of test group, and mean +/- 1 sd of control group
# Assumes test group and control group are in same .csv file (different columns)

TD = d[grep("TD", d[,1]),] 	 #control group
APD = d[grep("APD", d[,1]),] #test group

# plot left and right ear
#layout(matrix(c(1:2), 1, 2, byrow = TRUE))
par(mfrow=c(1,2),mar=c(0,0,0,1.5),oma=c(7,7,1,1))

for (j in 1:2){
  
  # create empty plot
  plot(frqs,xlim=c(frqs[1],max(frqs)),type="n",axes=FALSE,ann=FALSE,ylim=rev(range(c(min,max))),log = "x")
  box()
  
  mtext(outer=T,side=1,line=3,text="frequency (kHz)",cex=1.5)		
  mtext(outer=T,side=2,line=3,text="threshold (dB HL)",cex=1.5)	
  
  if (j<=1){
    axis(2,col="black",cex.axis=1.5)
    text(5,-14,"Left",cex=1.5)
  }  else {
    text(5,-14,"Right",cex=1.5)
  }
  
  axis(1,at=frqs,lab=FreqAxis,cex.axis=1.5)
  
  # Left ear
  if (j<=1) {
    numCol = 34:39
  } else {
    # Right ear
    numCol = 28:33
  }
  # calculate mean for test group
  avg<-vector()
  for (i in numCol){
    avg[i-(numCol[1]-1)]<-mean(APD[1:length(APD[,1]),i])
  }
  
  ## calculate mean and sd for control group
  stdev <- vector()
  mn <- vector()
  for (i in numCol){
    stdev[i-(numCol[1]-1)]<-sd(TD[1:length(TD[,1]),i],na.rm=T)
    mn[i-(numCol[1]-1)]<-mean(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate min and max for control group
  mnn <- vector()
  mx <- vector()
  for (i in numCol){
    mnn[i-(numCol[1]-1)]<-min(TD[1:length(TD[,1]),i],na.rm=T)
    mx[i-(numCol[1]-1)]<-max(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate upper and lower boundaries of shaded area
  upper <- mnn
  lower <- mx
  
  # plot shaded area (mean +/- 1 sd)
  xx <- c(frqs, rev(frqs))
  yy <- c(lower,rev(upper))
  polygon(xx, yy, col="lightgrey",border=NA)
  
  # plot mean control group
  lines(frqs,mn,col="white",lwd=3)
  
  # plot individual audiograms test group
  for (i in 1:length(APD[,1])){
    lines(frqs,APD[i,numCol])
  }
  
  # plot mean test group
  lines(frqs,avg,lwd=4, col="black")
  
  # plot exclusion criteria line
  #lines(c(0:9), seq(25,25,length=10),lty=2,lwd=3)
  lines(c(0.25, 0.50, 1.00, 2.00, 4.00, 4.00, 2.00, 1.00, 0.50, 0.25), seq(25,25,length=10),lty=2,lwd=3)
  
  if (j<=1){
    yplot <- 35
    # plot legend
    legend(0.24,yplot, c("Mean APD","Individual APD","Mean and range TD","NH criteria"),
           lty=c(1,1,1,2),lwd=c(3,2,8,2),col=c("black","black","lightgrey","black"),cex=0.8,bty=0,box.col="white")

    # Add white line to legend for mean
    segments(x0 = .24, y0 = 42.8, x1 = .33, y1 = 42.8,col = "white", lwd = 3)   
  }
}

```

A standard air conduction pure-tone audiometry was carried out at six octave frequency bands ranging between 0.25 to 8 kHz using ???? audiometer and ??? headphones. Normal hearing acuity was defined as thresholds $\leq$ 25 dB HL for the octave frequency bands between 0.25 to 4 kHz. Thresholds at 8 kHz were $\leq$ 25 dB HL for all the participants, excluding two participants with thresholds at 35 and 30 dB HL in one ear, respectively. One participant from the clinical group (APD) was excluded from the analysis due to raised thresholds predominantly in the right ear (PTA$_{Right}$ = 36.25 dB HL; PTA$_{Left}$ = 13.75 dB HL). Otoscopy inspection of the child's ear canal revealed a large accumulation of cerumen whereby the right eardrum was not visible. The listeners' thresholds for the left and the right ear are plotted in Figure \@ref(fig:PTA). The shaded grey area represents the TD group thresholds range and the white line represents their mean at each frequency. The black lines represents the individual thresholds in the APD group and the group mean is marked by the bold black line. The dashed line represents the maximal thresholds criteria of $\leq$ 25 dB HL for participation in the study. [Results belong here??]{.correction} 


#### Extended high-frequency audiometry (EHFA)

Extended high-frequency pure-tone audiometry was carried out at four $\frac{1}{3}$ octave band frequencies 8, 11, 16, & 20 kHz using a locally developed MATLAB based software which generated and collected the data. Measurements took place at SHaPS, UCL laboratory in an electromagnetically shielded sound proof booth which is typically used for EEG measurements. A Windows PC situated outside the booth was connected via USB to an RME ???? sound card (Audio AG, Haimhausen Germany) and an ER10X Extended-Bandwidth Acoustic Probe System (Etym$\bar{o}$tic Research, Elk Grove Village, IL) which was located in the testing booth. Once the ear probe was placed in the child's ear, an in-situ sound pressure level calibration was performed (chirp noise) using a MATLAB code provided by ????.

Speak with KZ about the measurements

#### Switching task (ST)

The switching task (ST) is a novel speech-on-speech listening task that involves perception of interrupted and periodically segmented speech that is switched between the two ears out-of-phase with an interrupted distractor. Since segments of the target and of the distractor are never presented in the same ear at the same time, it enables to eliminate peripheral (EM) masking, while maintaining high IM for speech distractors. The task assesses the ability to switch attention and integration of binaural information.

Refer to Chapter 2 and briefly describe the stimuli and difference in the methods.

As described in Chapter 2 Section ???, two test versions were used with varying in sentence structure and complexity: 1. ASL 2. CCRM

Masker Types..

#### Spatialised speech-in-noise (LiSNS-UK)

The Listening in Spatialised Noise Sentences UK (LiSNS-UK) assesses the ability to use binaural cues in speech-on-speech listening conditions. The test development, speech material normalisation, and norms standardisation followed @Cameron2007 development steps and are described in detail in Chapter ???. The test uses virtualisation techniques to create spatial distribution of sound sources in space for headphones presentation where target sentences [ASL; @MacLeod1990] are presented in two simultaneous speech distractors (unrelated children's stories spoken by the target talker). It comprises of two main listening conditions, differing in their availability of spatial cues. The target sentences are configured to always appear in front of the listener's head, at 0$^{\circ}$ azimuth on the horizontal plane, with the two streams of speech distractors either co-located in space with the target (S0N0), resulting in relatively poor speech perception, or offset in space, with one distractor to either side of the target at $\pm$ 90$^{\circ}$, resulting in an improvement in speech perception of circa 13 dB [@Cameron2011], typically termed as spatial release from masking (SRM). This SRM advantage is calculated by taking the difference between performance in the co-located condition and the separated condition. The speech distractors were presented continuously throughout a run at a fixed 65? dB SPL output level and comprised of a combination of two out of three different passages children stories. A 1-up/1-down adaptive procedure was used, varying the level of the target talker relative to the distractors depending on listener's correct/incorrect response to measure the listeners' speech reception threshold (SRT), i.e., the signal-to-noise-ratio (SNR) yielding 50% speech intelligibility. A 2 ms long 1 kHz pure-tone was presented 500 ms before the target sentence onset at 65? dB SPL (0 dB SNR) as a reference cue signalling the listener to attend the coming target sentence. The initial target output level was ?? dB SPL with an initial step-size of 4 dB SNR. The step-size was reduced after every reversal, reaching a minimum step-size of 2 dB SNR after three practice reversals. A stopping rule was introduced in case the maximal SNR was reached more than three times and the procedure was considered to be successfully completed in case test reversals were obtained. The SRT was then calculated by averaging test reversals SNRs (i.e., following three practice reversals). Each run consisted of 25 sentences taken from 8? phonemically-balanced test list which were constructed following the normalisation of the speech. In addition, a sentence-specific level correction was applied to the target signal (see Chapter ?? for more information). The order of the listening condition, test lists, target sentences and distractors combinations was fixed across all the participants and started with the collocated condition. Spatialisation was applied by convolving each stimuli with head-related transfer functions (HRTFs) at the corresponding azimuthal direction separately for the left and the right channel. The HRTFs were measured with a Knowles Electronics Manikin for Acoustic Research (KEMAR, REF) manikin with a small pinnae taken from the CIPIC HRTF database[^rmd-basics-cites-and-refs-1] [@Algazi2001; see "special" HRTF data]. A post-equalisation step was applied in order to flatten the magnitude of the headphones frequency response. Headphone-to-ear Transfer Functions (HpTFs) measured with KEMAR manikin for HD-25 supraaural headphones were extracted from @Wierstorf2011 HRTF database. The final mixed stimulus was filtered with the inverse HpTFs separately for the left and the right channel before being combined together as a final step. Every participant was presented with two runs, one for each listening condition (collocated/separated). Testing started following a practice phase of two runs for each of the test conditions with five BKB sentences each [@Bench1979]. Listeners were instructed to verbally repeat the target sentences to the experimenter who was situated alongside the participant in a sound treated chamber. The experimenter scored the response by selecting the correctly repeated keywords on the screen. Listeners were encouraged to guess if unsure while no feedback was given at any time. A loose keyword scoring method was used, whereby errors of case or declension were considered as correct responses. For example, a repetition of the keywords '$<$clown*s*$>$ $<$funny$>$ $<$face*s*$>$' to the stimulus 'The $<$clown$>$ had a $<$funny$>$ $<$face$>$'.

[^rmd-basics-cites-and-refs-1]: The database is available online in: <https://www.ece.ucdavis.edu/cipic/spatial-sound/hrtf-data/>

#### Speech-in-noise (SPIN)

The speech-in-noise test was used as a more realistic listening situation that is widely used in the clinic as opposed to more complex listening tasks as listed above. The normalised ASL sentences were presented in a speech-shaped-noise (SSN) with spectrum matched to the ASL corpus. The SSN onset was 500 ms before the target sentence begin. The exact same adaptive procedure as for the LiSNS-UK was used with the same stop-rules. Each listener was presented with a single run of 25 sentences following a practice phase with seven BKB sentences. The same test list and sentences order was used across all the listeners.

#### The Environmental Auditory Scene Analysis task (ENVASA)

In analogy to the classic 'cocktail-party' scenario, ENVASA is a non-linguistic paradigm [@Leech2009] that measures detection of everyday environmental sounds presented in naturalistic auditory scenes and can be used to asses IM effects as well as sustained selective auditory attention skills. In the task, short environmental target sounds (e.g., a "dog's bark", "door knock" or "bouncing ball") were presented in a dichotic background scene (i.e., the target sound is presented only in one ear) consisting of either a single background scene,presented in both ears, or two background scenes, each presented in a different ear. The number of targets, the onset time and presentation ear varied across trials. Four target/background SNRs were employed split into two categories 'low' (-6 and -3 dB) and 'high' (0 and +3 dB) by varying the target level. Target/background contextual agreement was manipulated by embedding the target sound in a *congruent* background scene that is in agreement with the listener's expectations (e.g., a cow's 'moo' in a farmyard scene) or in an *incongruent* background scene which violate these expectations (e.g., a cow's 'moo' in a traffic scene).

Procedure:

The experiment was carried out using the original code and laptop as used and described by @Leech2009. Sounds were presented via Sennheiser HD-25 headphones (REF) and the participants response was recorded using ???? gamepad. The output level was adjusted to a comfortable level before the test started. The participants were situated in front of the laptop placed on a desk and were instructed to hold the gamepad. Prior to the test begin the listeners were presented with a short child-friendly video covering the task's instructions and demonstrated two test trials. Following the instruction video, the examiner gave the child a short recap of the task's instructions and simulated with the child an exemplary trial to make sure the child is familiarised with the task. The task began with three practice trials with provided feedback, while no further feedback was given in the testing phase.

Every trial was made of two parts, starting with a target audio and visual familiarisation phase before the main target detection phase. Target identification was recorded by pressing one of the three buttons on the gamepad which corresponded to the location of the target objects on the screen. A response was counted as correct only if the participants pushed the corresponding button within 2 s time interval, 300 ms following the target onset. The outcome measure was calculated as the percentage of target sounds correctly identified within a condition (%-correct).

In total there were 92 target sounds presented over 40 trials, with half of the target sounds presented in a single- and half in a dual-background condition. In Occasional foil target items were played at 0 dB SNR without a corresponding picture on the screen and were used to estimate the quality of the participants performance. Each target item was served once as a foil item and their order was randomised.

(ref:Leech2009) Schematic of the ENVASA experimental paradigm [taken from @Leech2009]

```{r, label='ENVASA', fig.cap="(ref:Leech2009)", out.width='65%', fig.align='center', echo=FALSE}

knitr::include_graphics("figures/ENVASAparadigm.png")
```

#### CELF-RS

The Recalling Sentences (RS) sub-test of the Clinical Evaluation of Language Fundamentals Fifth UK edition [CELF-5-UK @HWiig2017] was administered to assess the listeners expressive language ability and has been shown to be a good indicator of the listeners general language skills (REF). In the task the child is presented with pre-recorded sentences of increasing length and complexity and required to repeat sentences without any changes. Scoring were marked by hand by the examiner as instructed by the test manual. The sentences were spoken by a standard southern British English female and were recorded in a sound-treated recording booth at the SHaPS UCL laboratory, London. The sentences were presented using a MATLAB program via headphones using the same experimental equipment as listed above at a comfortable output level of 70 dB HL. The task began with two practice sentences while the number of test items varied depending on the child's age performance. No repetitions or feedback was given during the testing and the test was discontinued in case the child failed to score any points for four consecutive items. Age-scaled score were calculated based on the test norms with a mean score of 10 and SD of 3. Scaled scores within $\pm$ 1 SD from the norm mean (between 8 to 12) are classified as average scores, whereas performance beyond $\pm$ 1 SD are classified as above/below the average score. Thus, the cut-off for abnormally poor performance is a scaled score $\leq$ 7.

### Questionnaires

#### Medical, Neurological, and Pysiological History {.unnumbered}

#### The Evaluation pf Children's Listening and Processing Skills (ECLiPS) {.unnumbered}

The ECLiPS questionnaire [@Barry2014] comprises of 38 items where the users are asked to express their agreement simple statements about the child's listening and other related skills or behaviours using a five-point Likert scale (from "strongly agree" to "strongly disagree"). The ECLiPS was design to identify listening and communication difficulties in children aged 6 to 11 years. Nonetheless, the UK standardisation study (REF) found little to no age effect on scores in many of the scale items, suggesting the testing age could be extended below and beyond the population used for the development. Based on factor analysis the items are grouped into five subcategories: 1. Speech & Auditory Processing (SAP), 2. Environmental & Auditory Sensitivity (EAS), 3. Language, literacy & laterality (L/L/L), 4. Memory & Attention (M&A), 5. Pragmatic & Social skills (PSS). Age- and sex-scaled scores were computed using the test excel scorer.

A score below the 10$^{th}$ percentile (corresponding to a scale score of circa 6) is generally considered clinically significant.

```{=html}
<!--
In the results: compare scores with scores obtained by: https://www.nature.com/articles/s41598-018-25316-9.pdf and Moore et al. 2020 (Listening Difficulties in Children: Behavior and Brain Activation Produced by Dichotic Listening of CV Syllables)
-->
```
#### The Children's Communication Checklist 2$^{nd}$ edition (CCC-2) {.unnumbered}

Communication abilities were assessed using the Children's Communication Checklist second edition questionnaire [CCC-2; @D.V.M.2003] was completed by the child's parent/guardian. The CCC-2 was designed to screen communication problems in children aged 4 to 16 years and comprises of 70 checklist items each comprising of a behaviour statement like "Mixes up words of similar meaning". The respondents are asked to judge how often the behaviours occur using a four-point Likert rating scale: 0. *less than once a week (or never)*, 1. *at least once a week, but not every day*, 2. *once or twice a day*, 3. *several times (more than twice) a day (or always)*. The items are grouped into ten sub-scales of behaviours tapping into different skills (A. Speech, B. Syntax, C. Semantics, D. Coherence, E. Inappropriate initiation, F. Stereotyped language, G. Use of context, H. Non-verbal communication, I. Social relations, J. Interests). Taking the sum of scores for the sub-scales A to H are used to derive the General Communication Composite (GCC) which is used to identify clinically abnormal communication competence. A GCC score \< 55 was found by @Norbury2005 to well separate between control and clinical groups, identifying children with scores at the bottom 10%. Another composite (Social-Interaction Deviance Composite, SIDC) was taken by taking the difference in sum of scales E, H, I, and J from the sum of scales of A to D. Abnormal GCC (\< 55) combined with a negative SIDC score has been shown to be indicative of an autistic spectrum disorder profile [@D.V.M.2003]. The CCC-2 scaled and composite scores were computed using the test excel scorer. Data from one TD child out of forty four children was excluded from the analysis due to inconsistent reports flagged by the test scorer.

## Results

### Standard audiometry

```{r,label='stdAud', include=FALSE, warning=FALSE}
# ---------------------------------------------------------------------------------------------
# get thresholds by frequencies
# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "Freq"
valuecol <- "dBHL"
gathercols <- c("R250","R500","R1000","R2000", "R4000", "R8000",
                "L250","L500","L1000","L2000", "L4000", "L8000")
d_L <- gather_(d, keycol, valuecol, gathercols)

# get ear information as a new column
library(stringr)
d_L$Ear <- ifelse(str_detect(d_L$Freq,"R"),"R","L")
d_L$Ear <- factor(d_L$Ear,levels=c("R","L"))
# d_L$Freq <- transform(str_replace_all(d_L$Freq,c("R"="","L"="")))
d_L$Freq  <- as.factor(revalue(d_L$Freq, c("R250"="250","R500"="500","R1000"="1000","R2000"="2000",
                                           "R4000"="4000","R8000"="8000","L250"="250","L500"="500",
                                           "L1000"="1000","L2000"="2000","L4000"="4000","L8000"="8000")))
d_L$Freq <- factor(d_L$Freq,levels=c("250","500","1000","2000","4000","8000"))
# ---------------------------------------------------------------------------------------------

# get PTAs (0.5 + 1 + 2 + 4 kHz /4):
d <- d %>% group_by(listener) %>%
  dplyr::mutate(
    PTA_R = round(mean(c(R500,R1000,R2000,R4000),na.rm=TRUE),2),
    PTA_L = round(mean(c(L500,L1000,L2000,L4000),na.rm=TRUE),2),
    PTA_RL = round(mean(c(R500,R1000,R2000,R4000,L500,L1000,L2000,L4000),na.rm=TRUE),2)) %>%
  ungroup()

# get PTA in the better ear
d$PTA_BE <- ifelse((d$PTA_R <= d$PTA_L),d$PTA_R,d$PTA_L)

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "PTA"
valuecol <- "dBHL"
gathercols <- c("PTA_R","PTA_L","PTA_RL","PTA_BE")
d_PTA_L <- gather_(d, keycol, valuecol, gathercols)

d_PTA_L$PTA <- factor(d_PTA_L$PTA,levels=c("PTA_R","PTA_L","PTA_RL","PTA_BE"))

# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Frequency & Ear
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

Wilk_HL <- d_L %>%
  group_by(Freq,Ear) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_HL$CI <- sprintf("%.02f - %.02f",round(Wilk_HL$conf.low,2),round(Wilk_HL$conf.high,2))

Wilk_HL_effectSize <- d_L %>%
  group_by(Freq,Ear) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_HL_effectSize$effsize <- round(Wilk_HL_effectSize$effsize,3)

# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by PTA
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

Wilk_PTA <- d_PTA_L %>%
  group_by(PTA) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_PTA$CI <- sprintf("%.02f - %.02f",round(Wilk_PTA$conf.low,2),round(Wilk_PTA$conf.high,2))

Wilk_PTA_effectSize <- d_PTA_L %>%
  group_by(PTA) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_PTA_effectSize$effsize <- round(Wilk_PTA_effectSize$effsize,3)
# --------------------------------------------------------------------------------------------------
# get table:

### For frequencies ###
PTA_tab1 <- d_L %>% ddply(.,~Freq*Ear*Group,summarise,N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2))  %>% 
  arrange(., group_by = Group,Ear)
PTA_tab1 <- PTA_tab1[,-grep("Group",colnames(PTA_tab1))]
# APD first then TD
PTA_tab1 <- cbind(PTA_tab1[1:12,1:ncol(PTA_tab1)],PTA_tab1[13:nrow(PTA_tab1),3:ncol(PTA_tab1)])

### For PTA ###
PTA_tab <-  d_PTA_L %>% ddply(.,~PTA*Group,summarise,Ear = "", N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2))  %>% 
  arrange(., group_by = Group)
PTA_tab <- PTA_tab[,-grep("Group",colnames(PTA_tab))]
PTA_tab <- cbind(PTA_tab[1:4,1:ncol(PTA_tab)],PTA_tab1[5:nrow(PTA_tab),3:ncol(PTA_tab)])
PTA_tab$Ear <- c("R", "L","","")
PTA_tab$PTA <- c("PTA$_{Right}$","PTA$_{Left}$","PTA","BE")

# --------------------------------------------------------------------------------------------------
# combine table
HL_tab1 <- cbind(PTA_tab1,
                 "CI"=Wilk_HL$CI,"p"=round(Wilk_HL$p,2),
                 "effect size (r)"=round(Wilk_HL_effectSize$effsize,2),
                 "magnitude"=Wilk_HL_effectSize$magnitude)
colnames(HL_tab1)[1] = ""

HL_tab2 <- cbind(PTA_tab,
                 "CI"=Wilk_PTA$CI,"p"=round(Wilk_PTA$p,2),
                 "effect size (r)"=round(Wilk_PTA_effectSize$effsize,2),
                 "magnitude"=Wilk_PTA_effectSize$magnitude)
colnames(HL_tab2)[1] = ""

HL_tab <- rbind(HL_tab1,HL_tab2)
```

```{r, label='stdAud-fig', echo=FALSE,fig.cap="Add caption here.",fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%'}
### Frequencies ###
# New facet label names for Ear variable
Ear.labs <- c("Right", "Left")
names(Ear.labs) <- c("R","L")

t1 <- ggplot(d_L, aes(x=Freq,y=dBHL,fill=Group))+ 
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(40,-10),breaks=seq(40,-10,-5))+
  #geom_text(label=d_HF_Cmpr_L$listener)+
  labs(y = "dB HL",x = "Frequency in Hz")+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ Ear, scales = "free", switch = "y", labeller = labeller(Ear = Ear.labs))+
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

### PTA ###
t2 <- ggplot(d_PTA_L, aes(x=PTA, y=dBHL, fill=Group),show.legend=FALSE) +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(15,-5),breaks=seq(15,-5,-5))+
  labs(y = "dB HL",x = "") + 
  scale_x_discrete(labels=c("PTA_R"=expression(bold(PTA[Right])),"PTA_L"=expression(bold(PTA[Left])),
                            "PTA_RL"=expression(bold("PTA")),"PTA_BE"=expression(bold("BE"))))+
  # scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.text.x = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.4)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='stdAud-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
HL_tab$p = ifelse(HL_tab$p<.05,sprintf("\\textbf{%.02f}",HL_tab$p),HL_tab$p)

kbl(HL_tab, booktabs = T, escape = F, caption = "Standard audiometry descriptive and test statistics for group differences tested using Wilcoxon rank-sum test for unpaired samples[note]. PTA$_{Right}$ and PTA$_{Left}$ were calculated by taking the individual mean for thresholds at 0.5, 1, 2 and 4\ kHz in the respective ear. PTA denotes the listeners grand-mean for PTAs in both ears and BE represents the listeners PTA at the better-ear.",
    align = c("lccccccccc")) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" "=2, "APD" = 5, "TD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
  add_footnote(c("significance level = 0.05"), notation = "symbol") %>%
  column_spec(c(8,13),border_left = T) %>% 
  column_spec(14:15, italic = T) %>%
  kable_styling() %>%
  pack_rows("octave frequency bands", 1, 12) %>%
  pack_rows("PTAs and better-ear", 13, 16)
```

```{r,label='stdAud-analysis', eval=FALSE, include=FALSE}

model1 <- lmer(dBHL ~ Ear * Freq * Group * Age  + (1|listener), d_L, REML=FALSE)
model2 <- lmer(dBHL ~ Ear * Freq * Group + (1|listener), d_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear * Freq + (1|listener), d_L, REML=FALSE)
anova(model2,model3)

summary(model2)
tab_model(model2)


model1 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 Ear : Freq : Group +
                 (1|listener), d_L, REML=FALSE)

model2 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 (1|listener), d_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 (1|listener), d_L, REML=FALSE)
anova(model2,model3)
model4 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 (1|listener), d_L, REML=FALSE)
anova(model3,model4)

summary(model3)
tab_model(model3)

Anova(model3,type="II",test.statistic="Chisq")

anova(lm(dBHL ~ Ear * Freq * Group * Age, data = d_L))


# WilkTest <- d_L %>%
#   group_by(Freq) %>%
#   rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE,detailed=TRUE,conf.level = 0.95) %>%
#   rstatix::adjust_pvalue(method = "bonferroni") %>%
#   rstatix::add_significance("p.adj")

PTA_R <- d_PTA_L %>% filter(PTA=="PTA_R") %>% droplevels()
PTA_L <- d_PTA_L %>% filter(PTA=="PTA_L") %>% droplevels()
PTA_RL <- d_PTA_L %>% filter(PTA=="PTA_RL") %>% droplevels()
PTA_BE <- d_PTA_L %>% filter(PTA=="PTA_BE") %>% droplevels()

anova(lm(dBHL ~ Group * Age, data = PTA_R))
anova(lm(dBHL ~ Group * Age, data = PTA_L))
anova(lm(dBHL ~ Group * Age, data = PTA_RL))
anova(lm(dBHL ~ Group * Age, data = PTA_BE))

```

```{r eval=FALSE, fig.align='center', fig.asp=0.5, fig.cap="Add caption here.", fig.width=12, message=FALSE, warning=FALSE, include=FALSE, label='stdAud-PTA', out.width='100%'}
# PTAs by age
t1 <- ggplot(d_PTA_L, aes(x=Age, y=dBHL, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm , fill="#69b3a2", se=TRUE) +
  stat_cor(method = "kendall", cor.coef.name = "tau", aes(color = Group), label.x = 8, label.y = c(5,3.5), 
na.rm = TRUE) +
  stat_regline_equation(label.y = c(-14.2,-15))+
  scale_y_reverse() +
  labs(y = "dB HL",x = "Age (in years)") + 
  # scale_y_continuous(limits = c(-15,12),breaks=seq(-15,12,2)) +
  #scale_y_continuous(limits = c(-15,5),breaks=seq(-15,5,2)) +
  #scale_x_continuous(limits = c(min(AgeNum)-2,max(AgeNum)+2),breaks=seq(min(AgeNum)-2,max(AgeNum)+2,1)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom")

t1 <- t1 + facet_grid(. ~ PTA, scales = "free", switch = "y") +
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))
t1
```

Boxplots of listeners thresholds measured with a standard audiometer at the six octave frequency bands (0.25 to 8 kHz) and their corresponding PTAs are shown in Figure \@ref(fig:stdAud-fig) A-B. The listeners PTAs were calculated separately for the right and left ear (PTA$_{Right}$, PTA$_{Left}$) by taking the mean of thresholds at the frequency bands 0.5, 1, 2 and 4 kHz which are known to be important for speech perception (REF WHO). PTA denotes the listeners grand-mean for PTAs in both ears, form a single measure for the listeners hearing ability, and BE represents the listeners PTA at the better-ear. Descriptive statistics is given in Table \@ref(tab:stdAud-tab), split by groups.

[Do the groups differ in their hearing abilities?]{.correction}  
- To report Wilcoxon or LMEM test? - Wilcoxon test and LMEM found a significant difference between the groups for thresholds in the left ear. Nonetheless, the differences are rather small and clinically negligible, and there is no reason to assume this difference occurred by random.

### Extended high-frequency audiometry (EHFA)

```{r, include=FALSE, warning=FALSE}
d_HF<- read.csv(file.path(FileDir,'Files','EHF_Audiogram_12082020.csv'),header=T) 

d_HF <- merge(d_Info,d_HF,by=c("listener"))
#d_HF <- d_HF[,-match(c("Group.y"),names(d_HF))]
#colnames(d_HF)[2] = "Group"
d_HF$Group <- factor(d_HF$Group,levels=c("TD","APD"))
cols <- c("AuditoryTraining","EarProblems","EarProblemsDur","SLT","Grommets","MusicalTraining","FMuse","NrmlSpchUnderstanding")
d_HF[cols] <- lapply(d_HF[cols], factor)

# Include only HF thresholds ---------------------------------------------------------------------------------------------------

# add Age to the dataframe
d_HF <- d %>%
  select(listener, Age) %>%
  left_join(d_HF, ToAdd, by = "listener")

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "Freq"
valuecol <- "dBHL"
gathercols <- c("R11000","R16000","L11000","L16000")
d_HF_L <- gather_(d_HF, keycol, valuecol, gathercols)
# -------------------------------------------------------------- 
# get ear information as a new column
library(stringr)
d_HF_L$Ear <- ifelse(str_detect(d_HF_L$Freq,"R"),"R","L")
d_HF_L$Ear <- factor(d_HF_L$Ear,levels=c("R","L"))

# set levels
d_HF_L$Freq <- factor(d_HF_L$Freq,levels=c("R11000","R16000","L11000","L16000"))
d_HF_L$Freq  <- revalue(d_HF_L$Freq , c("R11000"="11000", "R16000"="16000",
                                        "L11000"="11000", "L16000"="16000"))
d_HF_L$Freq <- factor(d_HF_L$Freq,levels=c("11000","16000"))
d_HF_L$Group <- factor(d_HF_L$Group,levels=c("APD","TD"))
```

```{r, label='EHF-stats', include=FALSE}
# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Frequency & Ear
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

# remove na's
d_HF_L<- drop_na(d_HF_L,dBHL) %>% droplevels()

Wilk_EHF <- d_HF_L %>%
  group_by(Freq,Ear) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_EHF$CI <- sprintf("%.02f - %.02f",round(Wilk_EHF$conf.low,2),round(Wilk_EHF$conf.high,2))

Wilk_EHF_effectSize <- d_HF_L %>%
  group_by(Freq,Ear) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_EHF_effectSize$effsize <- round(Wilk_EHF_effectSize$effsize,2)

# --------------------------------------------------------------------------------------------------
# get table:
# For frequencies
PTA_tab1 <- d_HF_L %>% ddply(.,~Freq*Ear*Group,summarise,N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2)) %>% arrange(., group_by = Group,Ear)
PTA_tab1 <- PTA_tab1[,-grep("Group",colnames(PTA_tab1))]
PTA_tab1 <- cbind(PTA_tab1[1:4,1:ncol(PTA_tab1)],PTA_tab1[5:nrow(PTA_tab1),3:ncol(PTA_tab1)])

# --------------------------------------------------------------------------------------------------

# get PTAs:
# EHF
d_HF <- d_HF %>% group_by(listener) %>%
  dplyr::mutate(
    PTA_R = round(mean(c(R11000,R16000),na.rm=TRUE),2),
    PTA_L = round(mean(c(L11000,L16000),na.rm=TRUE),2),
    PTA_RL = round(mean(c(R11000,R16000,L11000,L16000),na.rm=TRUE),2)) %>%
  ungroup()

# get PTA in the better ear
d_HF$PTA_BE <- ifelse((d_HF$PTA_R <= d_HF$PTA_L),d_HF$PTA_R,d_HF$PTA_L)
d_HF <- drop_na(d_HF, Group) %>% droplevels()

# -- Change data layout from Wide2Long -----------------------
library(tidyr)
keycol <- "PTA"
valuecol <- "dBHL"
gathercols <- c("PTA_R","PTA_L","PTA_RL","PTA_BE")
d_HF_PTA_L <- gather_(d_HF, keycol, valuecol, gathercols)

d_HF_PTA_L <- drop_na(d_HF_PTA_L, dBHL) %>% droplevels()
d_HF_PTA_L$PTA <- factor(d_HF_PTA_L$PTA,levels=c("PTA_R","PTA_L","PTA_RL","PTA_BE"))
d_HF_PTA_L$Group <- factor(d_HF_PTA_L$Group,levels=c("APD","TD"))
# --------------------------------------------------------------------------------------------------
# Compare group difference for PTAs
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------
Wilk_EHF_PTA <- d_HF_PTA_L %>%
  group_by(PTA) %>%
  rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_EHF_PTA$CI <- sprintf("%.02f - %.02f",round(Wilk_EHF_PTA$conf.low,2),round(Wilk_EHF_PTA$conf.high,2))

Wilk_EHF_PTA_effectSize <- d_HF_PTA_L %>%
  group_by(PTA) %>%
  wilcox_effsize(data =., dBHL ~ Group, paired=FALSE, detailed=TRUE)
Wilk_EHF_PTA_effectSize$effsize <- round(Wilk_EHF_PTA_effectSize$effsize,2)

# --------------------------------------------------------------------------------------------------
# get table:
### For PTA ###
PTA_tab <-  d_HF_PTA_L %>% ddply(.,~PTA*Group,summarise,Ear = "", N=length(dBHL),median=round(median(dBHL,na.rm=TRUE),2),sd=round(sd(dBHL,na.rm=TRUE),2), min=round(min(dBHL,na.rm=TRUE),2),max=round(max(dBHL,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
PTA_tab <- PTA_tab[,-grep("Group",colnames(PTA_tab))]
PTA_tab <- cbind(PTA_tab[1:4,1:ncol(PTA_tab)],PTA_tab[5:nrow(PTA_tab),3:ncol(PTA_tab)])
PTA_tab$Ear <- c("R", "L","","")
PTA_tab$PTA <- c("PTA$_{Right}$","PTA$_{Left}$","PTA","BE")

# --------------------------------------------------------------------------------------------------
# combine table
EHF_tab1 <- cbind(PTA_tab1,
                 "CI"=Wilk_EHF$CI,"p"=round(Wilk_EHF$p,2),
                 "effect size (r)"=round(Wilk_EHF_effectSize$effsize,2),
                 "magnitude"=Wilk_EHF_effectSize$magnitude)
colnames(EHF_tab1)[1] = ""

EHF_tab2 <- cbind(PTA_tab,
                 "CI"=Wilk_EHF_PTA$CI,"p"=round(Wilk_EHF_PTA$p,2),
                 "effect size (r)"=round(Wilk_EHF_PTA_effectSize$effsize,2),
                 "magnitude"=Wilk_EHF_PTA_effectSize$magnitude)
colnames(EHF_tab2)[1] = ""

EHF_tab <- rbind(EHF_tab1,EHF_tab2)
```

```{r, label='EHFAud-fig', echo=FALSE,fig.cap="Add caption here.",fig.align='center', fig.width=10, fig.asp=0.5, out.width='100%'}
### Frequencies ###

# New facet label names for Ear variable
Ear.labs <- c("Right", "Left")
names(Ear.labs) <- c("R","L")
d_HF_L$Group <- factor(d_HF_L$Group,levels=c("APD","TD"))

t1 <- ggplot(d_HF_L, aes(x=Freq,y=dBHL,fill=Group),show.legend=FALSE)+ 
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(45,-5),breaks=seq(45,-5,-5))+
  #geom_text(label=d_HF_Cmpr_L$listener)+
  labs(y = "dB HL",x = "Frequency in Hz")+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ Ear, scales = "free", switch = "y", labeller = labeller(Ear = Ear.labs))+
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

### PTA ###
d_HF_PTA_L$Group <- factor(d_HF_PTA_L$Group,levels=c("APD","TD"))
t2 <- ggplot(d_HF_PTA_L, aes(x=PTA, y=dBHL, fill=Group),show.legend=FALSE) +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,colour="blue", shape=1)+
  scale_y_reverse(limits = c(45,-5),breaks=seq(45,-5,-5))+
  labs(y = "dB HL",x = "") + 
  scale_x_discrete(labels=c("PTA_R"=expression(bold(PTA[Right])),"PTA_L"=expression(bold(PTA[Left])),
                            "PTA_RL"=expression(bold("PTA")),"PTA_BE"=expression(bold("BE"))))+
  # scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(0.6,0.4)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='EHF-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
EHF_tab$p = ifelse(EHF_tab$p<.05,sprintf("\\textbf{%.02f}",EHF_tab$p),EHF_tab$p)

kbl(EHF_tab, booktabs = T,escape = F,caption = "Extended high frequency hearing screening descriptive statistics and group difference analysis by frequency and ear or PTA.",
    align = c("lccccccccc"),format = "latex") %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" " = 2, "APD" = 5, "TD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
  column_spec(c(8,13),border_left = T) %>% 
  column_spec(14:15, italic = T) %>%
  kable_styling() %>%
  pack_rows("octave frequency bands", 1, 4) %>%
  pack_rows("PTAs and better-ear", 5, 8)
```

```{r,label='EHF-analysis', eval=FALSE, include=FALSE}

# model1 <- lmer(dBHL ~ Ear * Freq * Group * Age  + (1|listener), d_HF_L_EHF, REML=FALSE)
# model2 <- lmer(dBHL ~ Ear * Freq * Group  + (1|listener), d_HF_L_EHF, REML=FALSE)
# anova(model1,model2)
# model3 <- lmer(dBHL ~ Ear * Freq + (1|listener), d_HF_L_EHF, REML=FALSE)
# anova(model2,model3)
# 
# summary(model2)
# tab_model(model2)


model1 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 Ear : Freq : Group +
                 (1|listener), d_HF_L, REML=FALSE)

model2 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 Freq : Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model1,model2)
model3 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 Ear : Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model2,model3)
model4 <- lmer(dBHL ~ Ear + Freq + Group +
                 Ear : Freq +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model3,model4)
model5 <- lmer(dBHL ~ Ear + Freq + Group +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model4,model5)
model6 <- lmer(dBHL ~ Ear + Freq +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model5,model6)
model7 <- lmer(dBHL ~ Ear +
                 (1|listener), d_HF_L, REML=FALSE)
anova(model6,model7)

summary(model6)
tab_model(model6)

Anova(model5,type="II",test.statistic="Chisq")

anova(lm(dBHL ~ Ear * Freq * Group * Age, data = d_L))


# WilkTest <- d_L %>%
#   group_by(Freq) %>%
#   rstatix::wilcox_test(data =., dBHL ~ Group, paired=FALSE,detailed=TRUE,conf.level = 0.95) %>%
#   rstatix::adjust_pvalue(method = "bonferroni") %>%
#   rstatix::add_significance("p.adj")
```

The listeners' thresholds measured with the ER10X at the EHFs 11 and 16 kHz are plotted in Figure \@ref(fig:EHF) for the left and the right ear. The shaded grey area represents the TD group thresholds range and the white line represents their mean at each frequency. The black lines represents the individual thresholds in the APD group and the group mean is marked by the bold black line. A comparison of the group means indicates that the differences in thresholds are small. Again, boxplots of the listeners thresholds by frequency and ear as well as PTAs are shown in Figure \@ref(fig:EHFAud-fig) A-B. Descriptive statistics and Wilcoxon rank-sum test outcomes for group comparison (unpaired samples) is given in Table \@ref(tab:EHF-tab), split by groups.

[Difference between groups]{.correction} Difference in thresholds between the groups across frequencies (11 & 16 kHz) and ears (left/right) as well as for the calculated PTA and BE measures were tested using a Wilcoxon rank-sum test for unpaired samples ('rstatix::wilcox_test' with bonferroni adjustment; REF). No significant difference was found between the groups for all thresholds (all p\>.05; see Table \@ref(tab:EHF-tab)). A LMEM model with **frequency** and **ear** as fixed factors showed similar results and thus was not reported here.

<!-- [Difference in HL between audiogram types?]{.correction}  -->

<!-- First, the quality(?) of the thresholds measured with the non-standard ER10X audiogram was tested by comparing the individuals thresholds with those obtained with the standard audiometer. This was tested group-wise for thresholds at 8\ kHz measured in the left and the right ear using Wilcoxon signed rank test for paired samples ('rstatix::wilcox_test' with bonferroni adjustment; REF). The test showed a significant difference in thresholds between the two audiogram type for the TD group in both right (p=`r round(Wilk_EHF$p.adj[1],3)`, effect size r=`r round(Wilk_EHF_effectSize$effsize[1],3)`) and the left ear (p=`r round(Wilk_EHF$p.adj[2],3)`, r=`r round(Wilk_EHF_effectSize$effsize[2],3)`). No significant difference was found in the APD group in both ears (right: p=`r round(Wilk_EHF$p.adj[3],3)`, r=`r round(Wilk_EHF_effectSize$effsize[3],3)`; left: p=`r round(Wilk_EHF$p.adj[4],3)`, r=`r round(Wilk_EHF_effectSize$effsize[4],3)`).  -->

```{r, label='EHF', fig.cap="APD participants pure-tone thresholds for extended high-frequencies plotted for the left and the right ear (black). The shaded grey area represents the TD group range of audiometric thresholds and the white line represents the mean at each frequency.", echo=FALSE, fig.align='center', figures-side, out.width='85%',fig.width=12, fig.height=6}
d_HF <- data.frame(d_HF)
# Define axes
# xaxis=c(1:4) # number of frequencies tested
# 11000 16000
FreqAxis = c("11","16")
frqs=c(11,16)

# min and max of y axis
max	=	max((d_HF[1:nrow(d_HF),35:36]),na.rm=T) + 17
min	=	min(d_HF[1:nrow(d_HF),35:36],na.rm=T) - 10

# Plot overlapping individual audiograms of test group, mean of test group, and mean +/- 1 sd of control group
# Assumes test group and control group are in same .csv file (different columns)

TD = d_HF[grep("TD", d_HF[,27]),] 	#control group (Group is in column 29)
APD = d_HF[grep("APD", d_HF[,27]),] #test group

# plot left and right ear
#layout(matrix(c(1:2), 1, 2, byrow = TRUE))
par(mfrow=c(1,2),mar=c(0,0,0,1.5),oma=c(7,7,1,1))

for (j in 1:2){
  
  # create empty plot
  plot(frqs,xlim=c(frqs[1],max(frqs)),type="n",axes=FALSE,ann=FALSE,ylim=rev(range(c(min,max))),log = "x")
  box()
  
  mtext(outer=T,side=1,line=3,text="frequency (kHz)",cex=1.5)		
  mtext(outer=T,side=2,line=3,text="threshold (dB HL)",cex=1.5)	
  
  if (j<=1){
    axis(2,col="black",cex.axis=1.5)
    text(14,-8,"Left",cex=1.5)
  }  else {
    text(14,-8,"Right",cex=1.5)
  }
  
  axis(1,at=frqs,lab=FreqAxis,cex.axis=1.5)
  
  # if (j<=1){
  #   axis(2,at=c(0,10,20,30,40,50,60),cex.axis=1.5)
  # }
  
  # if (j<=1) {
  #   numCol = 14:21
  # } else {
  #   numCol = 6:13
  # }
  
  if (j<=1) {
    numCol = 35:36
  } else {
    numCol = 44:45
  }
  # calculate mean for test group
  avg<-vector()
  for (i in numCol){
    avg[i-(numCol[1]-1)]<-mean(APD[1:length(APD[,1]),i],na.rm=T)
  }
  
  ## calculate mean and sd for control group
  stdev <- vector()
  mn <- vector()
  for (i in numCol){
    stdev[i-(numCol[1]-1)]<-sd(TD[1:length(TD[,1]),i],na.rm=T)
    mn[i-(numCol[1]-1)]<-mean(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate min and max for control group
  mnn <- vector()
  mx <- vector()
  for (i in numCol){
    mnn[i-(numCol[1]-1)]<-min(TD[1:length(TD[,1]),i],na.rm=T)
    mx[i-(numCol[1]-1)]<-max(TD[1:length(TD[,1]),i],na.rm=T)
  }
  
  # calculate upper and lower boundaries of shaded area
  upper <- mnn
  lower <- mx
  
  # plot shaded area (mean +/- 1 sd)
  xx <- c(frqs, rev(frqs))
  yy <- c(lower,rev(upper))
  polygon(xx, yy, col="lightgrey",border=NA)
  
  # plot individual audiograms test group
  for (i in 1:length(APD[,1])){
    lines(frqs,APD[i,numCol])
  }
  
  # plot mean control group
  lines(frqs,mn,col="white",lwd=4)
  
  # plot mean test group
  lines(frqs,avg,lwd=4, col="black")
  
  if (j<=1){
    yplot <- 50
    # plot legend
    legend(11,yplot, c("Mean APD","Individual APD","Mean and range TD"),lty=c(1,1,1),lwd=c(3,1,8),col=c("black","black","lightgrey"),cex=0.8,bty=0,box.col="white")
    #legend(.25,yplot, c("Mean older adults","Individual older adults","Mean and range young adults"),lty=c(1,1,1),lwd=c(3,1,1),col=c("black","black","white"),cex=1.3,box.col="white")
    
    segments(x0 = 11, y0 = 58.5, x1 = 11.4, y1 = 58.5,col = "white", lwd = 3)
  }
}
```

### Switching task (ST)

#### Data Analysis {.unnumbered}
[*Outliers & missing data*]{.correction}
```{r, eval=FALSE, include=FALSE}
# ASL <- read.csv(file.path(FileDir,"Files",'ST-ASL_2020-08-19.csv'),header=T)
# CCRM <- read.csv(file.path(FileDir,"Files",'ST-CCRM_2020-08-19.csv'),header=T)
# 
# if (RmvSubj==1){ASL <- ASL[ ! ASL$listener %in% Subj2Remove, ] %>% droplevels()}
# 
# graphics::hist(LevsPC~CondCode,data=ASL)
# 
# ASL$LevsPC_p2 <- ifelse(ASL$LevsPC<=.36,ASL$LevsPC_p*-1,ASL$LevsPC_p)
# 
# ASLOutliers <- ASL[which(ASL$LevsPC_p2<=0),]
# hist(LevsPC~CondCode,data=ASLOutliers)

# CCRM ---------------------------------------------------------------------------------
# hist(LevsPC~CondCode,data=CCRM)
#
# # flag p-values as negative for LevsPC <= .36
# CCRM$LevsPC_p2 <- ifelse(CCRM$LevsPC<=.36,CCRM$LevsPC_p*-1,CCRM$LevsPC_p)
#
# CCRMOutliers <- CCRM[which(CCRM$LevsPC_p2<=0),]
# hist(LevsPC~CondCode,data=CCRMOutliers)
#
# knitr::kable(CCRMOutliers) %>%
#   kable_styling() %>%
#   scroll_box(width = "100%", height = "400px")
#
# hist(LevsPC~CondCode,data=CCRMOutliers)
```

As a first step, the listeners adaptive track and psychometric functions (PF) were manually inspected for abnormalities. The proportion of correct keywords within the final test trials (LevsPC) was calculated as a measure describing the success of the adaptive procedure. Since the adaptive procedure was set to yield 50\%-correct, a successful procedure is expected to be within the 50\% range. A binomial statistical test was applied to identify observations that significantly differ from 50\%. Observations with LevsPC $\leq$ 35\% were flagged as possible outliers and were further inspected (see Figure ??). Interestingly, the majority of the flagged cases belonged to the CCRM test condition where targets were presented with a competing CCRM-type sentences (CCRM_F). Three observations out of 215 (5 conditions x 43 listeners) were flagged for data measured with the ASL corpus, and 29 observations out of 258 (6 conditions x 43 listeners) were flagged for data measured with the CCRM corpus. As expected, most of the identified cases were for observations measured with the more demanding conditions with speech distractors (see Figure ??). In five cases (2 ASL; 3 CCRM) we were able to confidently determine that the listener's true score was near to ceiling, and thus these observations were set to the maximum DC (0.97). In other cases it was not possible to confidently determine the true SRdT, either because the maximum number or trials were presented before a minimum number of test reversals were obtained (CCRM\ =\ 1; ASL\ =\ 2), or due to aberrant adaptive tracks (CCRM\ =\ 5). Since all these cases belonged to more challenging test conditions with speech distractors, it is very likely that the children's true score is at celling. Thus, to account that, rather than removing these observations, which will consequently reduce the statistical power, they were set to a DC of 1, which is above the task's upper DC limit of 0.97.

[*Regression lines + z-scores*]{.correction}
<!-- For further analysis, listener-specific age-independent scores were estimated using a linear regression model. The model was fitted separately for each test version (ASL/CCRM) per test condition and was estimated from the TD data only with %-correct as the dependent variable and age as a predictor. Standard residuals were calculated for each listener, based on the model prediction, resulting in age-independent residuals that are comparable to z-scores for data with normal distribution, with a mean and SD of approximately 0 and 1, respectively. Since the main goal of the study was to find a measure that is able to well separate between the APD group and the typically developed control group, individual differences and group differences were explored using a deviance analysis procedure proposed by @Ramus2003. Abnormal scores were defined by a deviance cut-off of $\pm$ 1.65 SD from the TD group mean. Thus, circa 90\% of the normal population residuals are expected to be within the deviance range of $\pm$ 1.65. Occasional occurrence of abnormal scores in the normal population is not unusual in behavioural measures. Therefore, since the prediction of the residuals is based on the control data, such outliers may skew the TD group true mean or SD and thus may introduce an error in the model prediction. For this reason, the procedure included two steps: i. following the initial estimation of the listeners residuals, outliers in the TD group were identified and trimmed from the data set (outside mean $\pm$ 1.65); ii. next, the linear regression was reapplied for the 'trimmed' TD group and standardised residuals were recalculated for all the listeners, including the trimmed TD observations.   -->

Age-independent scores were estimated using a linear regression model. The model was fitted condition-wise separately for each test version (ASL/CCRM) and was based on the control group data only with %-correct as the dependent variable and age as a predictor. A two-steps model comparison was performed to test the assumption that performance displays a monotonic linear relationship with age versus a non-monotonic (segmented) linear relationship. Extreme outliers were initially trimmed from the TD group to reduce noise in the data and to improve the models fit. In the first step, both models were computed and the best model was selected based on a model comparison using analysis of variance **anova()** test. Standard residuals were next calculated for each TD listener, based on the selected model prediction. The standardised residuals are age-independent and are comparable to z-scores for data with normal distribution, with a mean and SD of approximately 0 and 1, respectively. Since the main goal of the study was to find a measure that is able to well separate between the APD group and the typically developed control group, individual differences and group differences were explored using a deviance analysis procedure proposed by @Ramus2003. Abnormal scores were defined by a two-tailed deviance cut-off of $\pm$ 1.65 SD from the TD group mean. Thus, circa 90\% of the normal population residuals are expected to be within the deviance range of $\pm$ 1.65. Occasional occurrence of abnormal scores in the normal population is not unusual in behavioural measures. Therefore, since the prediction of the residuals is based on the control data, such outliers may skew the TD group true mean or SD and thus may introduce an error in the model prediction. Therefore, in the second step, TD outliers (with standardised residuals below/above TD mean $\pm$ 1.65) were trimmed from the data and the two models were re-fitte and compared again. Finally, the selected model with the best fit was used to calculate the standardised residuals for all the listeners, including the trimmed TD observations and the APD group.

[*parametric data assumptions*]{.correction}
Inspection of the data revealed that the assumption of normal distribution (Shapiro Wilk test) and the assumption of homogeneity of variance (Levene's test) were not met. Thus, the relationship between the listeners SRdTs and their age was analysed separately for each group per condition using Kendall's tau ($\tau$) which is a non-parametric correlation test (Kendall's $\tau$ and p values are displayed in Figure\ \@ref(fig:ST-Age)\ A-B). Similar to Spearman's rho coefficient, Kendall's $\tau$ ranges between +1 and -1, denoting an optimal correlation at both extremes. The test is recommended for small sample size and a large number of tied ranks (REF Andy fields book p181), which fits to the restricted range possible outcomes in the ST task due to the nature of the adaptive procedure. 


ADD HERE: Description about nParLD
Rank-based ANOVA type statistic test (ATS) was used f2 ld f1 type test (between/within...)
--> nparLD offers different test statistics, whereas due to the small sample-size the ANOVA-type test statistic was preferred (Noguchi al., 2012). 

other tests were considered and delievered the same results!! 
```{r, message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
# remove(ASL)
# remove(CCRM)

# Load DC data ------------------------------------------------------------------
d_ST<- read.csv(file.path(FileDir,'Files',"ST_2020-10-28.csv"),header=T) 

# merge the two dataframes
d_ST <- merge(d_ST,d,by=c("listener","Group"))

## LONG format ---------------------------------------------
# material is grouped together
d_ST$CondCode <- factor(d_ST$CondCode,levels=c("Q-ASLN-NoAlt","Q-ASLN-Alt","AMSSN-ASLN-Alt","MDR_F-ASLN-Alt","ENG_F-ASLN-Alt",
                                               "Q-CCRM-NoAlt","Q-CCRM-Alt","AMSSN-CCRM-Alt","MDR_F-CCRM-Alt","ENG_F-CCRM-Alt","CCRM_F-CCRM-Alt"))

levels(d_ST$Background)
d_ST$Background <- factor(d_ST$Background,levels=c("Quiet","AMSSN", "MDR_F", "ENG_F", "CCRM_F"))
levels(d_ST$ear)
d_ST$ear <- factor(d_ST$ear,levels=c("B","A"))
levels(d_ST$material)
d_ST$Group <- factor(d_ST$Group,levels=c("APD","TD"))

# Filter data by material --------------------------------------------------------------------------------------------
ASLN <- d_ST %>% filter(material=="ASLN") %>% droplevels() # Only ASLN
CCRM <- d_ST %>% filter(material=="CCRM") %>% droplevels() # Only CCRM

# Clean data ---------------------------------------------------------------------------------------------------------

# Remove subjects with no uRev:
# ASL:
ASLN[is.na(ASLN$uRevs),] # APD10: Run 2 & 3
# remove rows with missing data
# ASLN <- drop_na(ASLN, uRevs) %>% droplevels()

# CCRM:
CCRM[is.na(CCRM$uRevs),] # APD12: Run 5
# remove rows with missing data
# CCRM <- drop_na(CCRM, uRevs) %>% droplevels()

#########################################
##   get z-scores by speech material   ##
#########################################
# source("functions/getZ.R")

# 1. ASLN
# get direction of the z-scores for the trimming of TD's abnormal scores
# ASLN$zDirection <- -1
# 
# # get z-scores
# Output <- getZ(ASLN,CutOff)
# ASLN      <- Output[[1]]
# ASLN.label_TD       <- Output[[2]]
# ASLN.label_APD      <- Output[[3]]
# # zScores_Sum    <- Output[[4]]
# # zScores_Sum_TD <- Output[[5]]
# 
# # 2. CCRM
# # get direction of the z-scores for the trimming of TD's abnormal scores
# CCRM$zDirection <- -1
# Output <- getZ(CCRM,CutOff)
# CCRM      <- Output[[1]]
# CCRM.label_TD       <- Output[[2]]
# CCRM.label_APD      <- Output[[3]]
# zScores_Sum    <- Output[[4]]
# zScores_Sum_TD <- Output[[5]]

```

```{r,fig.align='center', fig.width=6, fig.asp=1.5, out.width='100%', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
#########################################
##   get z-scores by speech material   ##
#########################################

# fit individual models with and without a knot per condition & group and compare them:
source("Functions/getBestFit.R")

# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # Output[[11]] : TD trimmed data
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
TempRemove_ASL <- c("TD11_T_Run3_Q-ASLN-NoAlt_none_0dB_16-Nov-2019_14-33_ASL.csv",
                  "TD04_T_Run1_Q-ASLN-NoAlt_none_0dB_02-Jun-2019_12-13_ASL.csv",
                  "TD11_T_Run4_Q-ASLN-Alt_none_0dB_16-Nov-2019_14-35_ASL.csv",
                  "TD11_T_Run1_AMSSN-ASLN-Alt_0dB_16-Nov-2019_14-23_ASL.csv",
                  "TD04_T_Run2_AMSSN-ASLN-Alt_0dB_02-Jun-2019_12-15_ASL.csv")
ASLN$TempRmv <- ifelse((ASLN$fileName %in% TempRemove_ASL)==TRUE,1,0)

### Q-NoAlt ###
df <- ASLN %>% filter(CondCode=="Q-ASLN-NoAlt" & Group=="TD" & TempRmv <1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))


Output <- getBestFit(ASLN,"Q-ASLN-NoAlt",CutOff,slope1_temp,int1_temp,8,05)
df_1 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
# -------------------
# get kendall's tau:
# with model prediction
# cor_1 <- cor.test(x=df_1$Age[which(df_1$Group=="TD")],
#                  y=df_1$predicted[which(df_1$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_1 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_1 <- apa::cor_apa(cor_1,format ="text",print = FALSE)
# -------------------
    
bootTau<-function(df,i) cor(df$Age[i], df$uRevs[i], use = "complete.obs", method = "kendall")
library(boot)
boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


# summary(lm(FinalM_5,data=df_5))



### Q-Alt ###
df <- ASLN %>% filter(CondCode=="Q-ASLN-Alt" & Group=="TD" & TempRmv <1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))


Output <- getBestFit(ASLN,"Q-ASLN-Alt",CutOff,slope1_temp,int1_temp,10)
df_2 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))
# -------------------
# get kendall's tau:
# with model prediction
# cor_2 <- cor.test(x=df_2$Age[which(df_2$Group=="TD")],
#                  y=df_2$predicted[which(df_2$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_2 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_2 <- apa::cor_apa(cor_2,format ="text",print = FALSE)
# -------------------
boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)

### AMSSN-Alt ###
Output <- getBestFit(ASLN,"AMSSN-ASLN-Alt",CutOff)
df_3 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_3<- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))
# -------------------
# get kendall's tau:
# with model prediction
# cor_3 <-cor.test(x=df_3$Age[which(df_3$Group=="TD")],
#                  y=df_3$predicted[which(df_3$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_3 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_3 <- apa::cor_apa(cor_3,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### MDR-Alt ###
Output <- getBestFit(ASLN,"MDR_F-ASLN-Alt",CutOff)
df_4 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
L4<- sprintf("slope = %s, intcpt = %s, brk = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2),
             round(FinalM_4$m$getAllPars()[3],2))
# -------------------
# get kendall's tau:
# with model prediction
# cor_4 <-cor.test(x=df_4$Age[which(df_4$Group=="TD")],
#                  y=df_4$predicted[which(df_4$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_4 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_4 <- apa::cor_apa(cor_4,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### ENG-Alt ###
Output <- getBestFit(ASLN,"ENG_F-ASLN-Alt",CutOff)
df_5 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_5 <- if(Output[[8]]==1){FinalM_5=Output[[6]]}else{FinalM_5=Output[[7]]}
L5<- cbind("slope"=FinalM_5$m$getAllPars()[1],"intcpt"=FinalM_5$m$getAllPars()[2])
L5<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_5$m$getAllPars()[1],2),
             round(FinalM_5$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
cor_5 <-cor.test(x=df_5$Age[which(df_5$Group=="TD")],
                 y=df_5$predicted[which(df_5$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_5 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_5 <- apa::cor_apa(cor_5,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


## combine all conditions together
ASLN <- rbind(df_1,df_2,df_3,df_4,df_5)
# FinalM.ASL <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4,FinalM_5)
Lines.ASL <- rbind(L1,L2,L3,L4,L5)
corAll.ASL <- rbind(cor_1,cor_2,cor_3,cor_4,cor_5)

# get outliers: 
ASLN <- ASLN %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(ASLN,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))
```

```{r,fig.align='center', fig.width=6, fig.asp=1.5, out.width='100%', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}
#########################################
##   get z-scores by speech material   ##
#########################################
# fit individual models with and without a knot per condition & group and compare them:

source("Functions/getBestFit.R")
# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # Output[[11]] : TD trimmed data
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
TempRemove_CCRM <- c("TD15_T_Run5_Q-CCRM-NoAlt_CCRM-M_All_Targets_none_0dB_07-Dec-2019_15-04_CCRM.csv",
                     "TD12_T_Run1_Q-CCRM-Alt_CCRM-M_All_Targets_none_0dB_25-Nov-2019_12-19_CCRM.csv",
                     "TD05_T_Run6_ENG_F-CCRM-Alt_0dB_22-Sep-2019_12-08_CCRM.csv")
CCRM$TempRmv <- ifelse((CCRM$fileName %in% TempRemove_CCRM)==TRUE,1,0)

### Q-NoAlt ###
Output <- getBestFit(CCRM,"Q-CCRM-NoAlt",CutOff)
df_1 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_1 <-cor.test(x=df_1$Age[which(df_1$Group=="TD")],
#                  y=df_1$predicted[which(df_1$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_1 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_1 <- apa::cor_apa(cor_1,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### Q-Alt ###
df <- CCRM %>% filter(CondCode=="Q-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"Q-CCRM-Alt",CutOff,-slope1_temp,int1_temp,8)
df_2 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_2 <-cor.test(x=df_2$Age[which(df_2$Group=="TD")],
#                  y=df_2$predicted[which(df_2$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_2 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_2 <- apa::cor_apa(cor_2,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### AMSSN ###
df <- CCRM %>% filter(CondCode=="AMSSN-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"AMSSN-CCRM-Alt",CutOff,-slope1_temp,int1_temp,8.5)
df_3 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_3 <- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_3 <-cor.test(x=df_3$Age[which(df_3$Group=="TD")],
#                  y=df_3$predicted[which(df_3$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_3 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_3 <- apa::cor_apa(cor_3,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### MDR_F ###
df <- CCRM %>% filter(CondCode=="MDR_F-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

# Output <- getBestFit(CCRM,"MDR_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,11.5,0.078)
Output <- getBestFit(CCRM,"MDR_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,10,0.5)
df_4 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
L4<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_4 <-cor.test(x=df_4$Age[which(df_4$Group=="TD")],
#                  y=df_4$predicted[which(df_4$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_4 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_4 <- apa::cor_apa(cor_4,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### ENG_F ###
df <- CCRM %>% filter(CondCode=="ENG_F-CCRM-Alt" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
# geom_point()+
# geom_text(label=df$listener, size=3, colour="blue") +
# labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"ENG_F-CCRM-Alt",CutOff,slope1_temp,int1_temp,8,0.5)
df_5 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_5 <- if(Output[[8]]==1){FinalM_5=Output[[6]]}else{FinalM_5=Output[[7]]}
L5<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_5$m$getAllPars()[1],2),
             round(FinalM_5$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_5 <-cor.test(x=df_5$Age[which(df_5$Group=="TD")],
#                  y=df_5$predicted[which(df_5$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_5 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_5 <- apa::cor_apa(cor_5,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)


### CCRM_F ###
df <- CCRM %>% filter(CondCode=="CCRM_F-CCRM-Alt" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(CCRM,"CCRM_F-CCRM-Alt",CutOff,-0.1173,1.7272,8.8838)
df_6 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_6 <- if(Output[[8]]==1){FinalM_6=Output[[6]]}else{FinalM_6=Output[[7]]}
L6<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_6$m$getAllPars()[1],2),
             round(FinalM_6$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_6 <-cor.test(x=df_6$Age[which(df_6$Group=="TD")],
#                  y=df_6$predicted[which(df_6$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_6 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="kendall")
# get label for the scatterplot
cor_6 <- apa::cor_apa(cor_6,format ="text",print = FALSE)
# -------------------

boot_kendall <- boot(TD_trimmed, bootTau, 2000) 
boot_kendall
boot.ci(boot_kendall)

## combine all conditions together
CCRM <- rbind(df_1,df_2,df_3,df_4,df_5,df_6)
# FinalM.CCRM <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4,FinalM_5,FinalM_6)
Lines.CCRM <- rbind(L1,L2,L3,L4,L5,L6)
corAll.CCRM <- rbind(cor_1,cor_2,cor_3,cor_4,cor_5,cor_6)

# get outliers: 
CCRM <- CCRM %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(CCRM,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))
```

```{r,label='ST-Assumptions', echo=FALSE,results='hide',message=FALSE,warning=FALSE, include=FALSE}
################################ Assumptions testing ################################ 

# ---------------- uRevs ------------------------------------------------------------

############
# ASLN #####
############

# linear model
w1 <- lm(uRevs~ CondCode + Group, data = ASLN)

# 1. Normality (Shapiro-Wilk test) --> NOT met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(ASLN$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(ASLN$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- ASLN %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> NOT met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=ASLN,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = ASLN))

# Option 3:
# per condition
VarTest <- ASLN %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

############
# CCRM #####
############

# linear model
w1 <- lm(uRevs~ CondCode + Group, data = CCRM)

# 1. Normality (Shapiro-Wilk test) --> NOT met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(CCRM$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(CCRM$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- CCRM %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> NOT met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=CCRM,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = CCRM))

# Option 3:
# per condition
VarTest <- CCRM %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

# ---------------- z_trim -------------------------------------------------------

############
# ASLN #####
############

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = ASLN)

# 1. Normality (Shapiro-Wilk test) --> NOT met! (4/10)
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(ASLN$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(ASLN$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- ASLN %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=ASLN,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = ASLN))

# Option 3:
# per condition
VarTest <- ASLN %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

############
# CCRM #####
############

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = CCRM)

# 1. Normality (Shapiro-Wilk test) --> NOT met! (3/10)
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(CCRM$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(CCRM$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- CCRM %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=CCRM,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = CCRM))

# Option 3:
# per condition
VarTest <- CCRM %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

```

```{r, echo=FALSE,message=FALSE, warning=FALSE,results='hide'}
# get adults data for for the boxplots: 
d_study2 <- read.csv(file.path(FileDir,'Files','StudyII_AdultData.csv'),header=T) 

d_study2 <- d_study2 %>% filter(CondCode=="Q_ASL_TarB" | CondCode=="Q_CCRM_TarB" | CondCode=="DSDG_ASL_TarB+MskB" |
                            CondCode=="DSDG_CCRM_TarB+MskB" | CondCode=="SSDG_CCRM_TarB+MskB") %>% droplevels() 

d_study2$CondCode <- revalue(d_study2$CondCode, c("DSDG_ASL_TarB+MskB"="ENG_F-ASLN-Alt","DSDG_CCRM_TarB+MskB"="ENG_F-CCRM-Alt", "Q_ASL_TarB"="Q-ASLN-Alt", "Q_CCRM_TarB"="Q-CCRM-Alt", "SSDG_CCRM_TarB+MskB"="CCRM_F-CCRM-Alt"))

d_study2$CondCode <- factor(d_study2$CondCode,levels=c("Q-ASLN-Alt", "Q-CCRM-Alt", "ENG_F-ASLN-Alt", "ENG_F-CCRM-Alt","CCRM_F-CCRM-Alt"))

# select columns of interest from the main data frame
d_adults <- d_study2[,c("Listener","Age","Material","CondCode","duty")]

# get HW data
d_studyHW <- read.csv(file.path(FileDir,'Files','HW_YOnly_Upto35Yrs_n14_meanSRdT.csv'),header=T) 

d_studyHW <- d_studyHW %>% filter(Condition=="AMSSN" | Condition=="MDR_F") %>% droplevels() 

d_studyHW$Condition <- revalue(d_studyHW$Condition, c("AMSSN"="AMSSN-ASLN-Alt","MDR_F"="MDR_F-ASLN-Alt"))

d_studyHW$Material <- "ASL"

colnames(d_studyHW)[2] <- "Listener"
colnames(d_studyHW)[3] <- "CondCode"
colnames(d_studyHW)[13] <- "duty"

d_studyHW <- d_studyHW[,c("Listener","Age","Material","CondCode","duty")]

d_adults <- rbind(d_adults,d_studyHW)
d_adults$Age=14
colnames(d_adults)[5] <- "uRevs"
d_adults$Group="TD"

# Filter data by material  --------------------------------------------------------------------------------------
ASLN_adults <- d_adults %>% filter(Material=="ASL") %>% droplevels() # Only ASL
CCRM_adults <- d_adults %>% filter(Material=="CCRM") %>% droplevels() # Only CCRM
```

```{r eval=FALSE, include=FALSE}
# --------------------------------------------------------------------------------------------------
# Wilcox test / Mann-Whitney U test for non-parametric data 
# (when normality assumption is violated) for independent two samples
# library(rstatix)

# ## ASL #####
# Wilcox_ASL <- ASLN %>%
#   group_by(CondCode) %>%
#   rstatix::wilcox_test(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE) %>%
#   adjust_pvalue(method = "bonferroni") %>%
#   add_significance("p.adj")
# Wilcox_ASL$CI <- sprintf("%.02f - %.02f",round(Wilcox_ASL$conf.low,2),round(Wilcox_ASL$conf.high,2))
# 
# Wilcox_ASL_effectSize <- ASLN %>%
#   group_by(CondCode) %>%
#   wilcox_effsize(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE)
# 
# ## CCRM #####
# Wilcox_CCRM <- CCRM %>%
#   group_by(CondCode) %>%
#   rstatix::wilcox_test(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE) %>%
#   adjust_pvalue(method = "bonferroni") %>%
#   add_significance("p.adj")
# Wilcox_CCRM$CI <- sprintf("%.02f - %.02f",round(Wilcox_CCRM$conf.low,2),round(Wilcox_CCRM$conf.high,2))
# 
# Wilcox_CCRM_effectSize <- CCRM %>%
#   group_by(CondCode) %>%
#   wilcox_effsize(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE)
# 
# # --------------------------------------------------------------------------------------------------
# # get table for z- scores and stats:
# 
# # For ASL
# ASL_tab <- ASLN %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
#   arrange(., group_by = Group)
# ASL_tab <- ASL_tab[,-grep("Group",colnames(ASL_tab))]
# # APD first then TD
# ASL_tab <- cbind(ASL_tab[1:5,1:ncol(ASL_tab)],ASL_tab[6:nrow(ASL_tab),2:ncol(ASL_tab)])
# ASL_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt")
# 
# # For CCRM
# CCRM_tab <- CCRM %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
#   arrange(., group_by = Group)
# CCRM_tab <- CCRM_tab[,-grep("Group",colnames(CCRM_tab))]
# # APD first then TD
# CCRM_tab <- cbind(CCRM_tab[1:6,1:ncol(CCRM_tab)],CCRM_tab[7:nrow(CCRM_tab),2:ncol(CCRM_tab)])
# CCRM_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt","CCRM\\_F-Alt")
# # --------------------------------------------------------------------------------------------------
# # combine table
# ASL_tab <- cbind(ASL_tab,
#                  "CI"=Wilcox_ASL$CI,"p"=round(Wilcox_ASL$p,2),
#                  "effect size (r)"=round(Wilcox_ASL_effectSize$effsize,2),
#                  "magnitude"=Wilcox_ASL_effectSize$magnitude)
# colnames(ASL_tab)[1] = ""
# 
# CCRM_tab <- cbind(CCRM_tab,
#                  "CI"=Wilcox_CCRM$CI,"p"=round(Wilcox_CCRM$p,2),
#                  "effect size (r)"=round(Wilcox_CCRM_effectSize$effsize,2),
#                  "magnitude"=Wilcox_CCRM_effectSize$magnitude)
# colnames(CCRM_tab)[1] = ""
# 
# ST_tab <- rbind(ASL_tab,CCRM_tab)

```

```{r message=FALSE, warning=FALSE, include=FALSE, results='hide'}
# remove CCRM_F condition
CCRM_s <- CCRM %>% filter(CondCode!="CCRM_F-CCRM-Alt") %>% 
  dplyr::select(., listener, Group, material, CondCode, z_trim) %>% droplevels()

# remove material affiliation in conditions name
CCRM_s$CondCode <- revalue(CCRM_s$CondCode, c("Q-CCRM-NoAlt"="Q-NoAlt","Q-CCRM-Alt"="Q-Alt",
                                              "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                                              "ENG_F-CCRM-Alt"="ENG_F-Alt"))
ASLN_s <- ASLN %>% dplyr::select(., listener, Group, material, CondCode, z_trim) %>% droplevels()
ASLN_s$CondCode <- revalue(ASLN_s$CondCode, c("Q-ASLN-NoAlt"="Q-NoAlt","Q-ASLN-Alt"="Q-Alt",
                                              "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt",
                                              "ENG_F-ASLN-Alt"="ENG_F-Alt"))

ST <- rbind(ASLN_s, CCRM_s)
ST <- data.frame(ST)
# levels(ST$material)
# levels(ST$Group)
# levels(ST$CondCode)

ST.nparLD <- nparLD(z_trim ~ CondCode * Group * material, data = ST, subject = "listener", description = TRUE, plot.CI=TRUE)

ST.nparLD <- data.frame(round(ST.nparLD$ANOVA.test,3))

### CCRM only
CCRM <- data.frame(CCRM)
CCRM.nparLD <- nparLD(z_trim ~ CondCode * Group, data = CCRM, subject = "listener", description = TRUE, plot.CI=TRUE)

CCRM.nparLD <- data.frame(CCRM.nparLD$ANOVA.test)


##### uRevs
ANOVA.ASL <- aov(uRevs~CondCode * Group * Age, data = ASLN)
summary(ANOVA.ASL)

ANOVA.CCRM <- aov(uRevs~CondCode * Group * Age, data = CCRM)
summary(ANOVA.CCRM)

############################ ARCHIVE ############################

# install.packages("nparLD")
# Does not work because of missing obs (n=2!). The package info says it can deal with several missing values if they are declered as 'NA'. I tried it and it didn't work as well.
# library("nparLD")
# ASLN <- data.frame(ASLN)
# ASL.f1.ld.f1 <- nparLD(z_trim ~ CondCode * Group, data = ASLN, subject = "listener", description = FALSE, plot.CI=FALSE)
# # ASL.f1.ld.f1$ANOVA.test
# 
# CCRM <- data.frame(CCRM)
# CCRM.f1.ld.f1 <- nparLD(z_trim ~ CondCode * Group, data = CCRM, subject = "listener", description = FALSE,plot.CI=FALSE)
# # CCRM.f1.ld.f1$ANOVA.test
# 
# ST_ANOVA_tab <- cbind(round(ASL.f1.ld.f1$ANOVA.test,2),
#                       round(CCRM.f1.ld.f1$ANOVA.test,2))
# rownames(ST_ANOVA_tab) = c("Group","Condition","Group:Condition")
# ST_ANOVA_tab <- data.frame(ST_ANOVA_tab)
# # mark all the significant p's
# ST_ANOVA_tab$p.value = ifelse(ST_ANOVA_tab$p.value<.05,sprintf("\\textbf{%.02f}",ST_ANOVA_tab$p.value),ST_ANOVA_tab$p.value)
# ST_ANOVA_tab$p.value.1 = ifelse(ST_ANOVA_tab$p.value.1<.05,sprintf("\\textbf{%.02f}",ST_ANOVA_tab$p.value.1),ST_ANOVA_tab$p.value.1)
```

```{r, label='ST-ANOVAtab', echo=FALSE}
ST.nparLD$p.value = ifelse(ST.nparLD$p.value<.05,sprintf("\\textbf{%0.3f}",ST.nparLD$p.value),ST.nparLD$p.value)
colnames(ST.nparLD)[3] <- "p-value"


row.names(ST.nparLD) <- c("Group","Condition","Material","Group:Condition","Material:Condition",
          "Group:Material","Group:Condition:Material")
colnames(ST.nparLD)[3] <- "p-value"

kbl(ST.nparLD,booktabs = T, escape = F,caption = "Add caption here",
    align = c("lccc"),format = "latex",digits = 3) %>%
  add_footnote(c("significance level = 0.05"), notation = "symbol") %>%
  column_spec(4, italic = T)

# use this if you want to fore latex to print the table in an exact location!
# latex_options = c("hold_position")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# For ASL
ASL_tab <- ASLN %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
ASL_tab <- ASL_tab[,-grep("Group",colnames(ASL_tab))]
# APD first then TD
ASL_tab <- cbind(ASL_tab[1:5,1:ncol(ASL_tab)],ASL_tab[6:nrow(ASL_tab),2:ncol(ASL_tab)])
ASL_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt")

# For CCRM
CCRM_tab <- CCRM %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
  arrange(., group_by = Group)
CCRM_tab <- CCRM_tab[,-grep("Group",colnames(CCRM_tab))]
# APD first then TD
CCRM_tab <- cbind(CCRM_tab[1:6,1:ncol(CCRM_tab)],CCRM_tab[7:nrow(CCRM_tab),2:ncol(CCRM_tab)])
CCRM_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt","CCRM\\_F-Alt")
# --------------------------------------------------------------------------------------------------
# combine table
colnames(ASL_tab)[1] = ""
colnames(CCRM_tab)[1] = ""

ST_tab <- rbind(ASL_tab,CCRM_tab)

######################### ARCHIVE ######################### 

# --------------------------------------------------------------------------------------------------
# ##  non-parametric Wilcoxon Rank-Sum Test Mann-Whitney U test for independent 2 samples
# # (when normality assumption is violated)  ** With permutation **
# # [approximate (random-sampling/Monte Carlo)]
# # see: https://mac-theobio.github.io/QMEE/permutation_examples.html
# source("Functions/getPermWilcoxInd.R")
# 
# ASLN <- data.frame(ASLN)
# Output <- getPermWilcoxInd(ASLN,"z_trim","Group","CondCode")
# Wilcox_ASL <- Output[[2]]
# Wilcox_ASL <- Wilcox_ASL[,-c(1,4)]
# 
# CCRM <- data.frame(CCRM)
# Output <- getPermWilcoxInd(CCRM,"z_trim","Group","CondCode")
# Wilcox_CCRM <- Output[[2]]
# Wilcox_CCRM <- Wilcox_CCRM[,-c(1,4)]
# # --------------------------------------------------------------------------------------------------
# # get table for z- scores and stats:
# 
# # For ASL
# ASL_tab <- ASLN %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
#   arrange(., group_by = Group)
# ASL_tab <- ASL_tab[,-grep("Group",colnames(ASL_tab))]
# # APD first then TD
# ASL_tab <- cbind(ASL_tab[1:5,1:ncol(ASL_tab)],ASL_tab[6:nrow(ASL_tab),2:ncol(ASL_tab)])
# ASL_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt")
# 
# # For CCRM
# CCRM_tab <- CCRM %>% ddply(.,~CondCode*Group,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) %>% 
#   arrange(., group_by = Group)
# CCRM_tab <- CCRM_tab[,-grep("Group",colnames(CCRM_tab))]
# # APD first then TD
# CCRM_tab <- cbind(CCRM_tab[1:6,1:ncol(CCRM_tab)],CCRM_tab[7:nrow(CCRM_tab),2:ncol(CCRM_tab)])
# CCRM_tab$CondCode <- c("Quiet-NoAlt","Quiet-Alt","AMSSN-Alt","MDR\\_F-Alt","ENG\\_F-Alt","CCRM\\_F-Alt")
# # --------------------------------------------------------------------------------------------------
# # combine table
# ASL_tab <- cbind(ASL_tab,Wilcox_ASL)
# colnames(ASL_tab)[1] = ""
# 
# CCRM_tab <- cbind(CCRM_tab,Wilcox_CCRM)
# colnames(CCRM_tab)[1] = ""
# 
# ST_tab <- rbind(ASL_tab,CCRM_tab)
```

```{r, label='ST-Age', fig.cap="Scatterplot and linear regression lines for the listeners SRdTs measured with the switching task with the ASL (A) and CCRM speech corpus (B) as a function of age. Red indicates data from the APD group and green indicates data from the TD control group. The grey area represents the regression line 95\\% confidence interval. Reference data for normal hearing adults taken from Chapter 2 is given in the boxplots.", fig.align='center', fig.width=14, fig.asp=0.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE,fig.pos='h'}

dat_text.ASL <- data.frame(
  label = c(Lines.ASL[1],Lines.ASL[2],Lines.ASL[3],Lines.ASL[4],Lines.ASL[5]),
  label2 = c(corAll.ASL[1],corAll.ASL[2],corAll.ASL[3],corAll.ASL[4],corAll.ASL[5]),
  CondCode   = levels(ASLN$CondCode),
  Group = "TD")

dat_text.CCRM <- data.frame(
  label = c(Lines.CCRM[1],Lines.CCRM[2],Lines.CCRM[3],Lines.CCRM[4],Lines.CCRM[5],Lines.CCRM[6]),
  label2 = c(corAll.CCRM[1],corAll.CCRM[2],corAll.CCRM[3],corAll.CCRM[4],corAll.CCRM[5],corAll.CCRM[6]),
  CondCode   = levels(CCRM$CondCode),
  Group = "TD")

###### ASL ##############
t1 <- ggplot(ASLN, aes(x=Age, y=uRevs, color=Group)) +
  geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
  geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
  geom_point(size=2,alpha=1) +
  # geom_text(label=ASLN$listener, size=3)+
  geom_line(data=filter(ASLN, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(ASLN,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.ASL, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 3.5)+
  geom_text(data = dat_text.ASL, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 3.5)+
  geom_boxplot(ASLN_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
  labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                      labeller = labeller(CondCode = c("Q-ASLN-NoAlt" ="Quiet-NoAlt","Q-ASLN-Alt"="Quiet-Alt",
                                                       "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt","ENG_F-ASLN-Alt"="ENG_F-Alt"))) +
  theme(panel.spacing.x = unit(0,"line"),
        strip.background = element_rect(fill="white", color="white"),
        strip.text = element_text(face = "bold", size = 11))

###### CCRM ##############
t2 <- ggplot(CCRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
  geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
  geom_point(size=2, alpha=1) +
  # geom_text(label=CCRM$listener, size=3)+
  geom_line(data=filter(CCRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(CCRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.CCRM, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3, size = 3.5)+
  geom_text(data = dat_text.CCRM, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 3.5)+
  geom_boxplot(CCRM_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
  labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
  scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t2 <- t2 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                      labeller = labeller(CondCode = c("Q-CCRM-NoAlt" ="Quiet-NoAlt","Q-CCRM-Alt"="Quiet-Alt",
                                                       "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                                                       "ENG_F-CCRM-Alt"="ENG_F-Alt","CCRM_F-CCRM-Alt"="CCRM_F-Alt"))) +
  theme(panel.spacing.x = unit(0,"line"),
        strip.background = element_rect(fill="white", color="white"),
        strip.text = element_text(face = "bold", size = 11))

(t1 + t2) + plot_layout(ncol = 1, nrow = 2, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))

############################################# ARCHIVE #############################################

# ###### ASL ##############
# t1 <- ggplot(ASLN, aes(x=Age, y=uRevs, color=Group)) +
#   geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
#   geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
#   geom_point(size=2) +
#   geom_smooth(aes(group=Group,colour=Group),method="lm" , fill="#69b3a2", se=TRUE) +
#   stat_cor(method = "kendall", cor.coef.name = "tau", aes(color = Group), label.x = 7.5, label.y = c(1.05,1), 
# na.rm = TRUE) +
#   stat_regline_equation(label.x = 7.5,label.y = c(0.015,-0.05))+
#   geom_boxplot(ASLN_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
#   labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
#   scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
#   scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
#   theme_bw() +
#   theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
#         axis.title.x = element_text(size=11, face="bold"),
#         axis.title.y = element_text(size=11, face="bold"),
#         legend.title = element_text(size=11, face="bold"),
#         legend.text  = element_text(size=10, face="bold"),
#         legend.position = "bottom",
#         legend.direction = "horizontal",
#         legend.background = element_blank(),
#         legend.box.background = element_rect(colour = "black"))
# 
# t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
#                 labeller = labeller(CondCode = c("Q-ASLN-NoAlt" ="Quiet-NoAlt","Q-ASLN-Alt"="Quiet-Alt",
#                             "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt","ENG_F-ASLN-Alt"="ENG_F-Alt"))) +
#     theme(panel.spacing.x = unit(0,"line"),
#           strip.background = element_rect(fill="white", color="white"),
#           strip.text = element_text(face = "bold", size = 11))
# 
# ###### CCRM ##############
# t2 <- ggplot(CCRM, aes(x=Age, y=uRevs, color=Group)) +
#   geom_hline(yintercept=0.97, linetype="dashed",color = "black", size=0.5)+
#   geom_hline(yintercept=0.05, linetype="dashed",color = "black", size=0.5)+
#   geom_point(size=2, alpha=1) +
#   # geom_text(label=CCRM$listener, size=3)+
#   geom_smooth(aes(group=Group,colour=Group),method="lm" , fill="#69b3a2", se=TRUE) +
#   stat_cor(method = "kendall", cor.coef.name = "tau", aes(color = Group), label.x = 7.5, label.y = c(1.05,1), 
# na.rm = TRUE) +
#   stat_regline_equation(label.x = 7.5,label.y = c(0.015,-0.05))+
#   geom_boxplot(CCRM_adults,mapping = aes(x = 14 , y = uRevs),color="black") +
#   labs(y = "SRdTs (proportion of duty cycle)",x = "Age (in years)") + 
#   scale_y_continuous(limits = c(-0.05,1.05),breaks=seq(0,1,0.1)) +
#   scale_x_continuous(breaks=seq(7,14,1),labels=c("7","8","9","10","11","12","13","18-35"))+
#   theme_bw() +
#   theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
#         axis.title.x = element_text(size=11, face="bold"),
#         axis.title.y = element_text(size=11, face="bold"),
#         legend.title = element_text(size=11, face="bold"),
#         legend.text  = element_text(size=10, face="bold"),
#         legend.position = "bottom",
#         legend.direction = "horizontal",
#         legend.background = element_blank(),
#         legend.box.background = element_rect(colour = "black"))
# 
# t2 <- t2 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
#                 labeller = labeller(CondCode = c("Q-CCRM-NoAlt" ="Quiet-NoAlt","Q-CCRM-Alt"="Quiet-Alt",
#                             "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
#                             "ENG_F-CCRM-Alt"="ENG_F-Alt","CCRM_F-CCRM-Alt"="CCRM_F-Alt"))) +
#     theme(panel.spacing.x = unit(0,"line"),
#           strip.background = element_rect(fill="white", color="white"),
#           strip.text = element_text(face = "bold", size = 11))
# 
# (t1 + t2) + plot_layout(ncol = 1, nrow = 2, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
#   theme(legend.position='bottom',        
#         legend.direction = "horizontal",
#         legend.background = element_blank(),
#         legend.box.background = element_rect(colour = "black"),
#         plot.tag = element_text(face = 'bold'))
```

#### SRdTs by age {.unnumbered}
Since the age of the TD/APD children that participated in the present study spanned between circa 7 to 13 years, a developmental age effect was expected, where performance was expected to improve with an increasing age. To inspect this effect across the different test conditions and speech material (ASL/CCRM), scatterplots and linear regression lines for the listeners SRdTs as a function of age are shown in Figure\ \@ref(fig:ST-Age)\ A-B. The effect of age was tested against the TD group only since the variability in scores in the TD group is expected to be relatively smaller than in the clinical APD group. Therefore, any interpretation based on the APD regression lines should be carried out cautiously. The TD regression lines were determined based on model comparison and outliers trimming procedure to improve the model's fit (see section ??). Regular regression lines were found to be the most parsimonious in describing the relationship between the TD children performance and their age. This was the case in all test conditions but the MDR_F distractor in the ASL material, where a segmented line was found to give the best fit. Based on the segmented line, DC improved with age by circa 0.1 per year until reaching a plateau at the age of 9.5 years. Inspection of the regression lines revealed a clear developmental effect in both speech material, where SRdTs improved with age (smaller SRdT $\rightarrow$ better performance), with a larger improvement in performance when additional distractor is presented. While the trend in performance was similar in both speech materials, as expected, CCRM sentences were more intelligible, with performance for the CCRM corpus shifted towards lower (i.e., more difficult) DC relative to performance for the ASL corpus. This is due to the more simple speech material and the restricted alternative responses of the CCRM matrix-based sentences.
  
<!-- Inspection of the data revealed that the assumption of normal distribution (Shapiro Wilk test) and the assumption of homogeneity of variance (Levene's test) were not met. Thus, the relationship between the listeners SRdTs and their age was analysed separately for each group per condition using Kendall's tau ($\tau$) which is a non-parametric correlation test (Kendall's $\tau$ and p values are displayed in Figure\ \@ref(fig:ST-Age)\ A-B). Similar to Spearman's rho coefficient, Kendall's $\tau$ ranges between +1 and -1, denoting an optimal correlation at both extremes. The test is recommended for small sample size and a large number of tied ranks (REF Andy fields book p181), which fits to the restricted range possible outcomes in the ST task due to the nature of the adaptive procedure.  -->

The effect of age on performance of the trimmed TD group was analysed using Kendall's $\tau$ non-parametric correlation test, with Kendall's $\tau$ and p-values displayed in Figure\ \@ref(fig:ST-Age)\ A-B, split by speech material and condition. The test results showed a mixed developmental trend across conditions and test material. There was a significant correlation (moderate effect size) between age and SRdTs for the test conditions Quiet-NoAlt, MDR_F, and ENG_F when measured with the ASL material, and for ENG_F and CCRM_F for the CCRM speech material, whereas no significant correlation was found for the remaining conditions (*all p's\ >\ 0.05*).

A closer look at the linear lines shows several interesting trends. Firstly, the improvement in performance by age was more prominent for speech distractors, with relatively steeper slopes than for the non-speech distractor (AMSSN) or for conditions without a distractor. Furthermore, alternation on it's own had only a small impact on performance when comparing performance for the target sentences in quiet with and without alternations. Moreover, only speech distractors resulted noticeable decrement in performance (i.e., increased SRdTs), whereas performance for AMSSN was fairly similar to the Quiet conditions. Interestingly, when comparing the regression lines, there appears to be a relatively larger separation between the groups for data measured with the CCRM speech material, especially for AMSSN, but also for the speech distractors. However, it is possible that the APD reggression lines do not reflect the true population due to due to the large spread in performance and the small sample size and thus any interpertation should be taken with a pinch of salt. Another interesting observation is that the children showed little-to-no *masking-release* for speech spoken in an unfamiliar language (MDR_F) when compared with a distractor spoken in English (ENG_F). This is in agreement with findings in the adults study in Chapter\ \@ref(Chpt2). Lastly, it is apparent from the figure that performance for CCRM_F distractor was near-to-ceiling for some children, mostly among the APD group.

An exploratory comparison between between the children's data measured in the present study with data measured across young NH adults collected in Chapter\ \@ref(Chpt2) further highlight the strong developmental trend, with SRdTs still not entirely "adult-like" even at the age of 13 years, especially for speech distractos (see boxplots in Figure\ \@ref(fig:ST-Age)\ A-B). The children in both groups seems to be markedly susceptible to competing CCRM sentences or familiar/unfamiliar speech presented with ASL sentences, with performance at the age of 12 years still largely differing from those obtained by the adults. On the other hand, by the age of 12 years the TD children reached near to "adult-like" performance when CCRM target sentences were presented with with ENG_F speech distractor or when ASL sentences were presented with AMSSN distractor.

<!-- For Discussion:
- Different age distribution btw the groups.
- Only speech maskers degraded performance.
- little-to-no masking-release for speech spoken in a foreign language (MDR) when compared with ENG masker.
- Clear age effect: norms by age per condition and the need for more data in adolescence to have a fuller picture of the developmental trend. 
-->

```{r, label='ST-z', fig.cap="Boxplots of the listeners age-independent standardised residuals for data measured with the ASL (A) and the CCRM corpus (B). Residuals were calculated seperately for each condition and are based on a model predicton for TD group only. The grey area represents the deviance cut-off for abnormal score (SD $\\pm$\ 1.65 below/above the TD mean), where about 90\\% of the normal population is e expected to lay within. The dashed line represents the theorethical TD group mean (z = 0).", fig.align='center', fig.width=10, fig.asp=.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# ASL_Outlier <- ASLN[which(ASLN$z_trim>1.65),] %>% droplevels()
# ggplot(ASL_Outlier, aes(x=listener, fill = Group)) + geom_histogram(alpha = .5, bins=25, position = "identity",stat="count") + theme_classic()
# var_select = c("listener")
# count_freq = count(ASL_Outlier, var_select)

###### ASL ##############
t1 <- ggplot(ASLN, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,shape=1,colour="blue")+
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.48, y=1, angle=90, size=5)+
  annotate(geom ="text",  x=1, y = 7.5, label = "ST-ASL", size=9, face="bold",fontface=2) +
  # geom_text(aes(label = ifelse(ASLN$z_trim>1.65,ASLN$listener,"")),
            # position = position_dodge2(width = .8,padding = 0.1))+
  scale_y_continuous(limits = c(-5,8),breaks=seq(-5,8,2))+
  scale_x_discrete(labels=c("Q-ASLN-NoAlt" ="Quiet-NoAlt","Q-ASLN-Alt"="Quiet-Alt",
                            "AMSSN-ASLN-Alt"="AMSSN-Alt","MDR_F-ASLN-Alt"="MDR_F-Alt","ENG_F-ASLN-Alt"="ENG_F-Alt"))+
  labs(y = "standardised residual (z-score)" ,x = NULL)+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"))

###### CCRM #############
# CCRM_Outlier <- CCRM[which(CCRM$z_trim>1.65),] %>% droplevels()
# ggplot(CCRM_Outlier, aes(x=listener, fill = Group)) + geom_histogram(alpha = .5, bins=25, position = "identity",stat="count") + theme_classic()
# var_select = c("listener")
# count_freq = count(ASL_Outlier, var_select)

t2 <- ggplot(CCRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_quasirandom(dodge.width=0.9,shape=1,colour="blue")+
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.5, y=3, angle=90, size=5)+
  annotate(geom ="text",  x=1.3, y = 7.5, label = "ST-CCRM", size=9, face="bold",fontface=2) +
  # geom_text(aes(label = ifelse(CCRM$z_trim>1.65,CCRM$listener,"")),
            # position = position_dodge2(width = .8,padding = 0.1))+
  scale_y_continuous(limits = c(-3,8),breaks=seq(-3,8,2))+
  scale_x_discrete(labels=c("Q-CCRM-NoAlt" ="Quiet-NoAlt","Q-CCRM-Alt"="Quiet-Alt",
                            "AMSSN-CCRM-Alt"="AMSSN-Alt","MDR_F-CCRM-Alt"="MDR_F-Alt",
                            "ENG_F-CCRM-Alt"="ENG_F-Alt","CCRM_F-CCRM-Alt"="CCRM_F-Alt"))+
  labs(y = "standardised residual (z-score)" ,x = NULL)+ 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"))

library(patchwork)
(t1 + t2) + plot_layout(ncol = 1, nrow = 2, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, label='ST-tab', echo=FALSE}
# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf

# mark all the significant p's
# ST_tab$p = ifelse(ST_tab$p<.05,sprintf("\\textbf{%.02f}",ST_tab$p),ST_tab$p)

kbl(ST_tab,booktabs = T, escape = F,caption = "Switching task descriptives for standardised residuals (z-scores) calculated for data measured with the ASL and CCRM speech material.",
    align = c("lcccccccccc"),format = "latex") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" ", "APD" = 5, "TD" = 5)) %>%
  column_spec(c(7),border_left = T) %>%
  kable_styling() %>%
  pack_rows("ASL", 1, 5) %>%
  pack_rows("CCRM", 6, 11)
```

#### Age-independent z-scores {.unnumbered}

[*Boxplots & abnormal scores by conditions*]{.correction}
Age-independent (standardised residuals) z-scores were calculated based on the TD group data using a multiple-case study approach (@Ramus2003; see section ??? for more details). Boxplots of the listeners age-independent z-scores is shown in Figure \@ref(fig:ST-z)\ A-B, for the ASL and CCRM speech material respectively. Scores were calculated separately for each test condition, with better performance indicated by smaller z-score. The grey area marks the two-tailed 1.65 deviance cut-off for abnormal score from the control group mean (z $\approx$ 0), where only about 10\% of the normal population is expected to score below/above it. Overall, APD children performance in both test versions was noticeably poorer, with higher median z-scores than compared with the TD children. 

The next paragraphs will cover the examination and analysis of the individuals and group differences separately for each test version.

##### ASL corpus {.unnumbered}  
  
Surprisingly, APD children were most susceptible to the non-switched condition where the target sentences were presented in quiet (Quiet-NoAlt) and the switched condition where the target sentences were presented with a non-speech distractor (AMSSN), with a median score laying above the norms range (see grey area). In addition, APD children performance was noticeably poorer for speech distractor spoken in an unfamiliar language (MDR_F), with performance just within the norms range. Approximately half of the APD children exhibited abnormal scores for Quiet-NoAlt (10/20, 50%) and AMSSN (11/20, 55%) conditions. Paradoxically, the APD children showed a greater difficulty in repeating the target ASL sentences in quiet without switching (Quiet-NoAlt) than with switching (Quiet-Alt). Another interesting observation is that the APD children did not benefit from release of masking for a speech distractor spoken in an unfamiliar language (MDR_F) as opposed to a familiar speech spoken in English (ENG_F). This sits well with our previous findings with adults where adults showed no benefit for MDR_F speech masker (see chapter ???). Moreover, not only that the APD children did not get any release of masking, they even showed a further decrement in performance, with a high proportion of APD children exhibiting abnormal score (9/20 = 45.0%), while only few APD children were abnormal for ENG_F condition (4/20 = 55.0%). TD children performance on the other hand was relatively similar in both conditions, with only few children outside the norm (MDR_F: 3/23 = 13.0%; ENG_F: 1/19 = 4.3%). 

##### CCRM corpus {.unnumbered}  
  
  
Figure \@ref(fig:ST-z)\ B reveals a similar trend as seen for the ASL sentences, however with a more modest differences between the two groups. AMSSN yielded the largest separation, where 45% (9/20) of the APD children had abnormal scores and with a median score of 1.62, which is close to the +1.65 upper deviance cut-off. In comparison, only 13% of the TD children (3/23) had abnormal performance for AMSSN condition. As seen in the ASL corpus, Quiet-NoAlt showed relatively larger separation between the groups where performance of 35% (7/20) of the APD children was abnormal, as opposed to circa 9% (2/23) in the TD group. As for the speech distractors, 30% (6/20), 25% (5/20) and 20% (4/20) of the APD children had abnormal score for ENG_F,MDR_F and CCRM_F conditions, respectively. The percentage of abnormal scores in the TD group were relatively low with 13% (3/20) for ENG_F, circa 4% (1/23) for MDR_F, 0% for CCRM_F.  

[*nparLD() full 2x2x5 model*]{.correction}  
  
A three-way 2\ x\ 2\ x\ 5 factorial design with repeated measures was used to test the main effects of Group, Condition, and Material as well as their interaction on performance in the task (with z-scores as dependent variable). Note that the CCRM test condition with CCRM-type sentences as distractor (CCRM_F) was not was not included in the model since there was no comparable condition for the ASL speech material. Inspection of the standardised residuals z-scores revealed that the assumption of normal distribution (Shapiro Wilk test) was rejected for data measured with both speech material. Furthermore, homogeneity of the variance in the APD group was rejected for the ASL corpus (Levene's test; *F(4,95)\ =\ 2.71*, *p\ <\ 0.05*). Thus, due to the small sample size and the incomplete fulfilment of parametric statistical methods assumptions, a non-parametric approach was adopted. This was tested with a rank-based ANOVA-type statistic test (ATS) using the *nparLD()* function (nparLD package, REF), which is a robust method for small datasets with outliers or skewed scores (see Jos Feys, 2016 for a good introduction for robust nonparametric techniques). The *nparLD ATS* test results is given in Table\ \@ref(tab:ST-ANOVAtab). No significant three-way or two-way interactions were found (Group\ x Condition\ x\ Material, Group\ x\ Material, Material\ x\ Condition, and Group\ x\ Condition; all *p's\ >\ 0.05*), while there was a highly significant main effect of Group (*p\ < 0.0001'*) and a strong main effect of Condition (*p\ < 0.001'*). Other non-parametric tests procedures gave similar results. 

[Discussion or here?]{.correction}  
  
The lack of significant interaction (Group x Condition or Group x Condition x Material), is somewhat surprising and and do not reflect some of the differences seen in Figure ?? between the two groups for certain conditions or the overall difference in performance between the speech materials. These disagreement mat suggest that the model is under-powered to test that.

[*additional model for CCRM_F?*]{.correction}
An additional 2\ x\ 6 model was included to test the effect of CCRM-type distractor on performance in the CCRM speech material, with Group and Condition as predictors and z-scores as dependent variable using *nparLD ATS* test for between\ x\ within design (f1.ld.f1). The ATS test found a strong significant difference between the groups (`r sprintf("Statistic = %0.3f, df = %0.3f, p < %0.1f", CCRM.nparLD[1,1], CCRM.nparLD[1,2],CCRM.nparLD[1,3])`), while no significant main effect was found for Condition (`r sprintf("Statistic = %0.3f, df = %0.3f, p = %0.3f", CCRM.nparLD[2,1], CCRM.nparLD[2,2],CCRM.nparLD[2,3])`) nor for Group x\ Condition interaction (`r sprintf("Statistic = %0.3f, df = %0.3f, p = %0.3f", CCRM.nparLD[3,1], CCRM.nparLD[3,2],CCRM.nparLD[3,3])`).

[*ROC curves table?*]{.correction}

[*Switching effect (derived measures)*]{.correction}

```{r,echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# Get derived measures ----------------------------------------------------------------------

###### ASLN ######
# change data from Long2Wide
ASLN_w <- ASLN %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim")) %>%
  ungroup()
colnames(ASLN_w)[1:length(ASLN_w)] <- gsub("-", "_", colnames(ASLN_w[,c(1:length(ASLN_w))]))
  
# -- get derived scores --------------------------------------
# uRevs
# ASLN_w$ASLN_QAlt_vs_QNoAlt   <-  ASLN_w$uRevs_Q_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_AMSSN_vs_QNoAlt  <-  ASLN_w$uRevs_AMSSN_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_MDR_vs_QNoAlt    <-  ASLN_w$uRevs_MDR_F_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt
# ASLN_w$ASLN_ENG_vs_QNoAlt    <-  ASLN_w$uRevs_ENG_F_ASLN_Alt - ASLN_w$uRevs_Q_ASLN_NoAlt

# z-scores
ASLN_w$ASLN_QAlt_vs_QNoAlt_z   <-  ASLN_w$z_trim_Q_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_AMSSN_vs_QNoAlt_z  <-  ASLN_w$z_trim_AMSSN_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_MDR_vs_QNoAlt_z    <-  ASLN_w$z_trim_MDR_F_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt
ASLN_w$ASLN_ENG_vs_QNoAlt_z    <-  ASLN_w$z_trim_ENG_F_ASLN_Alt - ASLN_w$z_trim_Q_ASLN_NoAlt

# -- Change data layout from Wide2Long -----------------------
# ASLN_L_uRevs <- ASLN_w %>% 
#   select(listener,Age, Group, ASLN_QAlt_vs_QNoAlt, ASLN_AMSSN_vs_QNoAlt,
#          ASLN_MDR_vs_QNoAlt, ASLN_ENG_vs_QNoAlt) %>%
#   pivot_longer(
#     cols = c("ASLN_QAlt_vs_QNoAlt","ASLN_AMSSN_vs_QNoAlt",
#              "ASLN_MDR_vs_QNoAlt","ASLN_ENG_vs_QNoAlt"), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "uRevs") %>%
#   ungroup()

ASLN_L_z <- ASLN_w %>% 
    dplyr::select(listener, Age, Group, ASLN_QAlt_vs_QNoAlt_z, ASLN_AMSSN_vs_QNoAlt_z,
         ASLN_MDR_vs_QNoAlt_z, ASLN_ENG_vs_QNoAlt_z) %>%
  pivot_longer(
    cols = c("ASLN_QAlt_vs_QNoAlt_z","ASLN_AMSSN_vs_QNoAlt_z",
             "ASLN_MDR_vs_QNoAlt_z","ASLN_ENG_vs_QNoAlt_z"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()

###### CCRM ######
# change data from Long2Wide
CCRM_w <- CCRM %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim")) %>%
  ungroup()
colnames(CCRM_w)[1:length(CCRM_w)] <- gsub("-", "_", colnames(CCRM_w[,c(1:length(CCRM_w))]))

# -- get derived scores --------------------------------------
# uRevs
# CCRM_w$CCRM_QAlt_vs_QNoAlt   <-  CCRM_w$uRevs_Q_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_AMSSN_vs_QNoAlt  <-  CCRM_w$uRevs_AMSSN_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_MDR_vs_QNoAlt    <-  CCRM_w$uRevs_MDR_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_ENG_vs_QNoAlt    <-  CCRM_w$uRevs_ENG_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt
# CCRM_w$CCRM_CCRM_vs_QNoAlt   <-  CCRM_w$uRevs_CCRM_F_CCRM_Alt - CCRM_w$uRevs_Q_CCRM_NoAlt

# z-scores
CCRM_w$CCRM_QAlt_vs_QNoAlt_z   <-  CCRM_w$z_trim_Q_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_AMSSN_vs_QNoAlt_z  <-  CCRM_w$z_trim_AMSSN_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_MDR_vs_QNoAlt_z    <-  CCRM_w$z_trim_MDR_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_ENG_vs_QNoAlt_z    <-  CCRM_w$z_trim_ENG_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt
CCRM_w$CCRM_CCRM_vs_QNoAlt_z   <-  CCRM_w$z_trim_CCRM_F_CCRM_Alt - CCRM_w$z_trim_Q_CCRM_NoAlt

# -- Change data layout from Wide2Long -----------------------
# CCRM_L_uRevs <- CCRM_w %>% 
#   select(listener, Age, Group, CCRM_QAlt_vs_QNoAlt, CCRM_AMSSN_vs_QNoAlt,
#          CCRM_MDR_vs_QNoAlt, CCRM_ENG_vs_QNoAlt,CCRM_CCRM_vs_QNoAlt) %>%
#   pivot_longer(
#     cols = c("CCRM_QAlt_vs_QNoAlt","CCRM_AMSSN_vs_QNoAlt",
#              "CCRM_MDR_vs_QNoAlt","CCRM_ENG_vs_QNoAlt","CCRM_CCRM_vs_QNoAlt"), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "uRevs") %>%
#   ungroup()

CCRM_L_z <- CCRM_w %>% 
    dplyr::select(listener, Age, Group, CCRM_QAlt_vs_QNoAlt_z, CCRM_AMSSN_vs_QNoAlt_z,
         CCRM_MDR_vs_QNoAlt_z, CCRM_ENG_vs_QNoAlt_z,CCRM_CCRM_vs_QNoAlt_z) %>%
  pivot_longer(
    cols = c("CCRM_QAlt_vs_QNoAlt_z","CCRM_AMSSN_vs_QNoAlt_z",
             "CCRM_MDR_vs_QNoAlt_z","CCRM_ENG_vs_QNoAlt_z","CCRM_CCRM_vs_QNoAlt_z"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()
```

```{r, label='ST-CorASL', fig.cap="Add caption here.", fig.align='center', fig.width=8, fig.asp=.8, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

############ ASL ############
ASLN_w$Group <- factor(ASLN_w$Group,levels=c("APD","TD"))

library(ggExtra)

t1 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_Q_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "Quiet-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_AMSSN_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "AMSSN-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_MDR_F_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "MDR_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(ASLN_w, aes(x=z_trim_Q_ASLN_NoAlt, y=z_trim_ENG_F_ASLN_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "ENG_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"),
        legend.position=c(0.85,0.2))

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

library(cowplot)
plot_grid(t1,t2,t3,t4, ncol=2, nrow = 2)
```

```{r, label='ST-CorCCRM', fig.cap="Add caption here.", fig.align='center', fig.width=8, fig.asp=1.2, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
############ CCRM ############
CCRM_w$Group <- factor(CCRM_w$Group,levels=c("APD","TD"))

t1 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_Q_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "Quiet-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_AMSSN_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "AMSSN-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_MDR_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "MDR_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_ENG_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "ENG_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

t5 <- ggplot(CCRM_w, aes(x=z_trim_Q_CCRM_NoAlt, y=z_trim_CCRM_F_CCRM_Alt, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,color=Group),method="lm", se=TRUE, alpha=0.2,show.legend = FALSE) +
  # stat_cor(method = "pearson", aes(color = Group), label.x = -1.5) +
  stat_cor(method = "kendall", cor.coef.name = "tau",aes(color = Group), label.x = 2.5) +
  labs(y = "CCRM_F-Alt",x = "Quiet-NoAlt") + 
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"),
        legend.direction = "horizontal",
        legend.position=c(0.35,0.905))

t5 <- ggMarginal(t5, type="boxplot",groupFill = TRUE)

plot_grid(t1,t2,t3,t4,t5, ncol=2, nrow = 3)
```


### Spatialised speech-in-noise (LiSNS-UK)

```{r, echo=FALSE,results='hide',message=FALSE,warning=FALSE}

# Load LiSNS data ---------------------------------------------------------------------------------------------------
d_LiSNS <- read.csv(file.path(FileDir,'Files','LiSNS_2020-08-19.csv'),header=T) 

d_LiSNS$CondCode  <- as.factor(revalue(d_LiSNS$CondCode,c("SpchInNz"="SSN", "LiSNS-S0N0"="S0N0", "LiSNS-S0N90"="S0N90")))

d_LiSNS <- d_LiSNS[ ! d_LiSNS$listener %in% "APD08", ] %>% droplevels()

# Add age info ------------------------------------------------------------------------------------------------------
# merge the two dataframes
d_LiSNS <- merge(d_LiSNS,d,by=c("listener"))
colnames(d_LiSNS)[4] <- "Group"
## LONG format ---------------------------------------------

# Convert Long2Wide by uRevs and zScores
d_LiSNS_w <- d_LiSNS %>%
  pivot_wider(
    id_cols = "listener",
    names_from = "CondCode",
    values_from = c("uRevs")) %>%
  ungroup()

# get SRM by listener
d_LiSNS_w$SRM <-  d_LiSNS_w$`S0N0` - d_LiSNS_w$`S0N90`

## get z-scores by speech material

# add age 
d_LiSNS_w <- d %>%
  dplyr::select(listener, Age, Group) %>%
  left_join(d_LiSNS_w, ToAdd, by = "listener")

d_LiSNS_w <- d_LiSNS_w[ ! d_LiSNS_w$listener %in% "APD08", ] %>% droplevels()

# change to long to fit the function
LiSNS <- d_LiSNS_w %>%
  pivot_longer(
    cols = c("SSN","S0N0","S0N90","SRM"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "uRevs") 

```

```{r, label='LiSNS', message=FALSE,warning=FALSE, echo=FALSE, results='hide'}

source("functions/getBestFit.R")

# getBestFit(df,CondCodeName,CutOff,slope1,int1,brk,slope2)
  # --------------------------------------------
  # Input: 
  # df           : the complete tests data frame
  # CondCodeName : test condition of interest
  # CutOff       : cut-off value for TD group z scores trimming for outliers
  #
  # Optional inputs for **broken lines fit only** 
  # nls() enables to manually feed some parameters and it gradually reduce them. 
  # If the start parameters are too far from the actual value the model won't converge.
  # see discussion here: https://stats.stackexchange.com/questions/183653/getting-the-right-starting-values-for-an-nls-model-in-r
  # slope1/2 : slopes
  # int1     : intercept
  # brk      : brake point
  # --------------------------------------------  
  # Output:  
  # Output[[1]]  : df_All
  # Output[[2]]  : m1.linear
  # Output[[3]]  : m1.TwoLines
  # Output[[4]]  : ComprMdls1
  # Output[[5]]  : preFinalModel
  # Output[[6]]  : m2.linear
  # Output[[7]]  : m2.TwoLines
  # Output[[8]]  : postFinalModel
  # Output[[9]]  : ComprMdls2
  # Output[[10]] : plots
  # --------------------------------------------

# Obvious outliers to temporary remove in the initial stage of model fit.
# This might help to get a more accurate fit.
# All observations where returned in the final stage, for z-scores calculation!
LiSNS$TempRmv <- ifelse((LiSNS$listener %in% c("TD03","TD11") & 
                           LiSNS$CondCode ==c("S0N0"))==TRUE,1,0)

### SSN ###
df <- LiSNS %>% filter(CondCode=="SSN" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"SSN",CutOff,slope1_temp,int1_temp,9.5)
df_1 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_1 <- if(Output[[8]]==1){FinalM_1=Output[[6]]}else{FinalM_1=Output[[7]]}
L1<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_1$m$getAllPars()[1],2),
             round(FinalM_1$m$getAllPars()[2],2))
# -------------------
# get kendall's tau:
# with model prediction
# cor_1 <- cor.test(x=df_1$Age[which(df_1$Group=="TD")],
#                  y=df_1$predicted[which(df_1$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_1 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="pearson")
# get label for the scatterplot
cor_1 <- apa::cor_apa(cor_1,format ="text",print = FALSE)
# -------------------


### S0N0 ###
df <- LiSNS %>% filter(CondCode=="S0N0" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"S0N0",CutOff,slope1_temp,10,8.5,4)
df_2 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_2 <- if(Output[[8]]==1){FinalM_2=Output[[6]]}else{FinalM_2=Output[[7]]}
L2<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_2$m$getAllPars()[1],2),
             round(FinalM_2$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_2 <- cor.test(x=df_2$Age[which(df_2$Group=="TD")],
#                  y=df_2$predicted[which(df_2$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_2 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="pearson")
# get label for the scatterplot
cor_2 <- apa::cor_apa(cor_2,format ="text",print = FALSE)
# -------------------


### S0N90 ###
df <- LiSNS %>% filter(CondCode=="S0N90" & Group=="TD" & TempRmv<1) %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

# Output <- getBestFit(LiSNS,"S0N90",CutOff,-1.2,2,11.7,12.1)
Output <- getBestFit(LiSNS,"S0N90",CutOff,slope1_temp,int1_temp,11.7,2)
df_3 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_3 <- if(Output[[8]]==1){FinalM_3=Output[[6]]}else{FinalM_3=Output[[7]]}
L3<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_3$m$getAllPars()[1],2),
             round(FinalM_3$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_3 <- cor.test(x=df_3$Age[which(df_3$Group=="TD")],
#                  y=df_3$predicted[which(df_3$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_3 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="pearson")
# get label for the scatterplot
cor_3 <- apa::cor_apa(cor_3,format ="text",print = FALSE)
# -------------------


### SRM ###
df <- LiSNS %>% filter(CondCode=="SRM" & Group=="TD") %>% droplevels()
slope1_temp <- mean(df$uRevs)
int1_temp <- mean(df$Age)
# ggplot(df, aes(x=Age,y=uRevs))+ 
#   geom_point()+
#   geom_text(label=df$listener, size=3, colour="blue") +
#   labs(title = levels(df$CondCode))

Output <- getBestFit(LiSNS,"SRM",CutOff,0.18,5.7,8.7)
df_4 <- Output[[1]]  # df_All
TD_trimmed = Output[[11]]
FinalM_4 <- if(Output[[8]]==1){FinalM_4=Output[[6]]}else{FinalM_4=Output[[7]]}
L4<- sprintf("slope = %s, intcpt = %s",
             round(FinalM_4$m$getAllPars()[1],2),
             round(FinalM_4$m$getAllPars()[2],2))

# -------------------
# get kendall's tau:
# with model prediction
# cor_4 <- cor.test(x=df_4$Age[which(df_4$Group=="TD")],
#                  y=df_4$predicted[which(df_4$Group=="TD")],method="kendall")
# with only TD trimmed data
cor_4 <- cor.test(x=TD_trimmed$Age,y=TD_trimmed$uRevs,method="pearson")
# get label for the scatterplot
cor_4 <- apa::cor_apa(cor_4,format ="text",print = FALSE)
# -------------------

# combine all conditions together
LiSNS <- data.frame(rbind(df_1,df_2,df_3,df_4))
# FinalM.LiSNS <- list(FinalM_1,FinalM_2,FinalM_3,FinalM_4)
Lines.LiSNS <- rbind(L1,L2,L3,L4)
corAll.LiSNS <- rbind(cor_1,cor_2,cor_3,cor_4)

# Convert data from Lond2Wide to include SRM zscores
LiSNS_w <- LiSNS %>% 
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("uRevs","z_trim",)) %>%
  ungroup()

# ----------------------------------------------------------------------------------------------
# replace SRM z-scores:
LiSNS_w$z_trim_SRM <-  LiSNS_w$z_trim_S0N0 - LiSNS_w$z_trim_S0N90
  
# ugly but works..
# change again to long format
LiSNS_z <- LiSNS_w %>%
  pivot_longer(
    cols = c("z_trim_SSN","z_trim_S0N0","z_trim_S0N90","z_trim_SRM"), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "z_trim") %>%
  ungroup()

LiSNS_z <- data.frame(LiSNS_z)
LiSNS_z <- LiSNS_z %>%
transform(CondCode=str_replace(CondCode,"z_trim_",""))
# change conditions order for the plot
LiSNS_z$CondCode <- factor(LiSNS_z$CondCode,levels=c("SSN", "S0N0", "S0N90", "SRM"))
#levels(LiSNS$group)
LiSNS_z$Group <- factor(LiSNS_z$Group,levels=c("APD", "TD"))

# merge dataframes with uRevs and z-scores together
LiSNS <- LiSNS %>%
  dplyr::select(listener,Group,CondCode,uRevs,predicted) %>%
  left_join(LiSNS_z, ToAdd, by = c("listener","Group","CondCode"))

# get outliers: 
LiSNS <- LiSNS %>% group_by(CondCode) %>%
  mutate(Outlier = ifelse(z_trim > CutOff,1,0))

ddply(LiSNS,~CondCode*Group,summarise,nConde= length(listener),nOutlier=sum(Outlier, na.rm=TRUE),prcntOutlier=round((sum(Outlier,na.rm=TRUE)/length(listener)*100),1))

# Some stats and plots--------------------------------------------------------------------------------------------

# summarise condition across listeners 
# uRevs
ddply(LiSNS,~CondCode*Group,summarise,N=length(uRevs),mean=mean(uRevs,na.rm=TRUE),sd=sd(uRevs,na.rm=TRUE), min=min(uRevs,na.rm=TRUE),max=max(uRevs,na.rm=TRUE)) 
# z-trim
ddply(LiSNS,~CondCode*Group,summarise,N=length(z_trim),mean=mean(z_trim,na.rm=TRUE),sd=sd(z_trim,na.rm=TRUE), min=min(z_trim,na.rm=TRUE),max=max(z_trim,na.rm=TRUE)) 

################################ ARCHIVE ################################
## get z-scores by speech material
# source("functions/getZ.R")

# # get direction of the z-scores for the trimming of TD's abnormal scores
# zNegative <- c("SSN","S0N0","S0N90")
# d_LiSNS_L$zDirection <- ifelse((d_LiSNS_L$CondCode %in% zNegative)==TRUE,-1,1)
# 
# # get z-scores
# Output <- getZ(d_LiSNS_L,CutOff)
# 
# df_normed        <- Output[[1]]
# # label_TD       <- Output[[2]]
# # label_APD      <- Output[[3]]
# # zScores_Sum    <- Output[[4]]
# # zScores_Sum_TD <- Output[[5]]
# 
# LiSNS <- df_normed
# 
# # change conditions order for the plot
# LiSNS$CondCode <- factor(LiSNS$CondCode,levels=c("SSN", "S0N0", "S0N90", "SRM"))
# LiSNS$Group <- factor(LiSNS$Group,levels=c("APD", "TD"))
# 
# # Convert data from Lond2Wide to include SRM z-scores
# LiSNS_w <- LiSNS %>% 
#   pivot_wider(
#     id_cols = c("listener","Group","Age"),
#     names_from = "CondCode",
#     values_from = c("uRevs","z_trim")) %>%
#   ungroup()
# 
# # get SRM by listener
# # zScores
# LiSNS_w$z_trim_SRM <-  LiSNS_w$z_trim_S0N0 - LiSNS_w$z_trim_S0N90
# 
# # change again to long format
# LiSNS_z <- LiSNS_w %>%
#   pivot_longer(
#     cols = c("z_trim_SSN","z_trim_S0N0","z_trim_S0N90","z_trim_SRM"), 
#     names_to = "CondCode", 
#     names_ptypes = list(CondCode = factor()),
#     values_to = "z_trim") %>%
#   ungroup()
# 
# LiSNS_z <- data.frame(LiSNS_z)
# LiSNS_z <- LiSNS_z %>%
# transform(CondCode=str_replace(CondCode,"z_trim_",""))
# # change conditions order for the plot
# LiSNS_z$CondCode <- factor(LiSNS_z$CondCode,levels=c("SSN", "S0N0", "S0N90", "SRM"))
# #levels(LiSNS$group)
# LiSNS_z$Group <- factor(LiSNS_z$Group,levels=c("APD", "TD"))
# 
# # merge dataframes with uRevs and z-scores together
# LiSNS <- d_LiSNS_L %>%
#   dplyr::select(listener,CondCode, uRevs) %>%
#   left_join(LiSNS_z, ToAdd, by = c("listener","CondCode"))
# 
# LiSNS  <- drop_na(LiSNS, uRevs) %>% droplevels()
# 
# LiSNS$Group <- factor(LiSNS$Group,levels=c("APD", "TD"))

########################################################################
```

```{r,label='LiSNS-Assumptions', echo=FALSE,results='hide',message=FALSE,warning=FALSE,include=FALSE}
################################ Assumptions testing ################################ 

# ---------------- uRevs ------------------------------------------------------------
# linear model
w1 <- lm(uRevs~ CondCode + Group, data = LiSNS)

# 1. Normality (Shapiro-Wilk test) --> is met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(LiSNS$uRevs, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
qqline(LiSNS$uRevs, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- LiSNS %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(uRevs)

# 2. Homoggeneity of variance (Levene's test) --> ~ is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(uRevs ~ CondCode * Group, data=LiSNS,center=median)

# Option 2: 
DescTools::LeveneTest(lm(uRevs~ CondCode, data = LiSNS))

# Option 3:
# per condition
VarTest <- LiSNS %>%
  rstatix::group_by(Group) %>%
  levene_test(uRevs ~ CondCode)

# ---------------- z_trim -------------------------------------------------------

# linear model
w1 <- lm(z_trim~ CondCode + Group, data = LiSNS)

# 1. Normality (Shapiro-Wilk test) --> is met!
# data is normally distributed if p >.05

# QQ plot of residuals
qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
qqnorm(LiSNS$z_trim, pch = 1, frame = FALSE,main = "z_trim - Normal Q-Q Plot")
qqline(LiSNS$z_trim, col = "red", lwd = 2)
qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- LiSNS %>%
  group_by(CondCode, Group) %>%
  rstatix::shapiro_test(z_trim)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05

# Option 1:
car::leveneTest(z_trim ~ CondCode * Group, data=LiSNS,center=median)

# Option 2: 
DescTools::LeveneTest(lm(z_trim~ CondCode, data = LiSNS))

# Option 3:
# per condition
VarTest <- LiSNS %>%
  rstatix::group_by(Group) %>%
  levene_test(z_trim ~ CondCode)

```

```{r, label='LiSNS-ztab', echo=FALSE}

# Some stats and plots--------------------------------------------------------------------------------------------
# summarise condition across listeners 
# z-scores
LiSNS_z_tab_TD <- LiSNS %>% filter(Group=="TD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 
colnames(LiSNS_z_tab_TD)[1] = ""

LiSNS_z_tab_APD <- LiSNS %>% filter(Group=="APD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 

# get table
LiSNS_z_tab <- cbind(LiSNS_z_tab_TD,LiSNS_z_tab_APD[2:6])
colnames(LiSNS_z_tab)[1] = ""

# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(LiSNS_z_tab, escape = F, booktabs = T, caption = "LiSNS standard residuals (z-scores) descriptives by group.",
    align = c("lccccccccc"),format = "latex") %>% 
  add_header_above(c(" ", "TD" = 5, "APD" = 5))

######################################## ARCHIVE ######################################## 

# Some stats and plots--------------------------------------------------------------------------------------------
# summarise condition across listeners 
# z-scores
# LiSNS_z_tab_TD <- LiSNS %>% filter(Group=="TD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 
# colnames(LiSNS_z_tab_TD)[1] = ""
# 
# LiSNS_z_tab_APD <- LiSNS %>% filter(Group=="APD") %>% ddply(.,~CondCode,summarise,N=length(z_trim),median=round(median(z_trim,na.rm=TRUE),2),sd=round(sd(z_trim,na.rm=TRUE),2), min=round(min(z_trim,na.rm=TRUE),2),max=round(max(z_trim,na.rm=TRUE),2)) 

# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Condition
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------
# 
# Wilk_LiSNS <- LiSNS %>%
#   group_by(CondCode) %>%
#   rstatix::wilcox_test(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE) %>%
#   adjust_pvalue(method = "bonferroni") %>%
#   add_significance("p.adj")
# Wilk_LiSNS$CI <- sprintf("%.02f - %.02f",round(Wilk_LiSNS$conf.low,2),round(Wilk_LiSNS$conf.high,2))
# 
# Wilk_LiSNS_effectSize <- LiSNS %>%
#   group_by(CondCode) %>%
#   wilcox_effsize(data =., z_trim ~ Group, paired=FALSE, detailed=TRUE)
# Wilk_LiSNS_effectSize$effsize <- round(Wilk_LiSNS_effectSize$effsize,3)

# ----- $$$$$
# p-values with permutations (using coin package) are very similar to test without (using rstatix package).
# Because the coin package requieres messy looping, I decided to use the cleaner/easier alternative.

# results_p <- numeric(length(levels(LiSNS$CondCode))) 
# effectSize <- data.frame()
# for (nCond in 1:length(levels(LiSNS$CondCode))) {
#   # get all subjects' scores in a single condition 
#   nCondData <- LiSNS[which(LiSNS$CondCode == levels(LiSNS$CondCode)[nCond]),]
#   results_p[nCond] <- pvalue(coin::wilcox_test(z_trim~ Group, data = nCondData,
#                                          p.adjust.method ="bonferroni",na.rm=TRUE, paired = FALSE,
#                                          distribution=approximate(nresample=999999)))[1]
#   # optional: get effect size (r):
#   effectSize[nCond,1:7] <- rstatix::wilcox_effsize(z_trim~ Group, data = nCondData, paired = FALSE)
#   }
# 
# effectSize$effsize <- round(effectSize$effsize,3)
# colnames(effectSize)[4] = "effect-size (r)"
# --------------------------------------------------------------------------------------------------
# get table
# LiSNS_z_tab <- cbind(LiSNS_z_tab_TD,LiSNS_z_tab_APD[2:6],
#                  "CI"=Wilk_LiSNS$CI,"p"=round(Wilk_LiSNS$p,2),
#                  "effect size (r)"=round(Wilk_LiSNS_effectSize$effsize,2),
#                  "magnitude"=Wilk_LiSNS_effectSize$magnitude)
# colnames(LiSNS_z_tab)[1] = ""
# 
# # mark all the significant p's
# LiSNS_z_tab$p = ifelse(LiSNS_z_tab$p<.05,sprintf("\\textbf{%.02f}",LiSNS_z_tab$p),LiSNS_z_tab$p)
# 
# # prepare table using kbl()
# # for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
# kbl(LiSNS_z_tab, escape = F, booktabs = T, caption = "LiSNS standard residuals (z-scores) descriptive statistics and group difference analysis by test measures.",
#     align = c("lccccccccc"),format = "latex") %>% 
#   kable_styling(latex_options = c("scale_down")) %>%
#   add_header_above(c(" ", "TD" = 5, "APD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
#   column_spec(12,border_left = T) %>% column_spec(13:14, italic = T)
```

```{r, label='LiSNS-Age', fig.cap="Scatterplot and linear regression lines for the LiSN-S UK and SPIN SRTs (A) and the derived measure SRM (B) as a function of the listeners age. Red indicates data from the APD group and green indicates data from the TD control group. The grey area represents the regression line 95\ \\% confidence interval.", fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE}
# get some sub dataframes: 
LiSNS_Col_Sep <- LiSNS %>% filter(CondCode!="SRM" & CondCode!="SSN") %>% droplevels()
LiSNS_Col_Sep  <- drop_na(LiSNS_Col_Sep, uRevs) %>% droplevels()

LiSNS_NoSRM <- LiSNS %>% filter(CondCode!="SRM") %>% droplevels()
LiSNS_NoSRM <- drop_na(LiSNS_NoSRM, uRevs) %>% droplevels()

LiSNS_SRM <- LiSNS %>% filter(CondCode=="SRM") %>% droplevels()
LiSNS_SRM  <- drop_na(LiSNS_SRM, uRevs) %>% droplevels()

LiSNS_SSN <- LiSNS %>% filter(CondCode=="SSN") %>% droplevels()
LiSNS_SSN  <- drop_na(LiSNS_SSN, uRevs) %>% droplevels()

# LiSNS by age (SSN, S0N0 & S0N90)
dat_text.LiSNS <- data.frame(
  label = c(Lines.LiSNS[1],Lines.LiSNS[2],Lines.LiSNS[3]),
  label2 = c(corAll.LiSNS[1],corAll.LiSNS[2],corAll.LiSNS[3]),
  CondCode   = levels(LiSNS_NoSRM$CondCode),
  Group = "TD")

t1 <- ggplot(LiSNS_NoSRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_point(size=2) +
  geom_line(data=filter(LiSNS_NoSRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(LiSNS_NoSRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.LiSNS, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 4)+
  geom_text(data = dat_text.LiSNS, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 4)+
  labs(y = "Speech Reception Threshold, SRT (in dB SNR)",x = "Age (in years)") + 
  scale_y_continuous(limits = c(-15,5),breaks=seq(-15,5,2)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "none")

t1 <- t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y") +
     # ggtitle("LiSNS - Scores by age") + 
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

# LiSNS by age (SRM)
dat_text.LiSNS2 <- data.frame(
  label = c(Lines.LiSNS[4]),
  label2 = c(corAll.LiSNS[4]),
  CondCode   = levels(LiSNS_SRM$CondCode),
  Group = "TD")

t2 <- ggplot(LiSNS_SRM, aes(x=Age, y=uRevs, color=Group)) +
  geom_point(size=2) +
  geom_line(data=filter(LiSNS_SRM, Group=="TD"),aes(x = Age, y = predicted), size=1) +
  geom_smooth(data=filter(LiSNS_SRM,Group=="APD"),method="lm" , aes(group=Group), se=FALSE) +
  geom_text(data = dat_text.LiSNS2, mapping = aes(x = -Inf, y = -Inf, label = label),
            hjust = -0.05, vjust = -3,size = 4)+
  geom_text(data = dat_text.LiSNS2, mapping = aes(x = -Inf, y = -Inf, label = label2),
            hjust = -0.06, vjust = -1, size = 4)+
  labs(y = "dB",x = "Age (in years)") + 
  scale_y_continuous(limits = c(0,13),breaks=seq(0,13,2)) +
  theme_bw() +
  theme(axis.text = element_text(size = 10, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.position = "none")

t2 <- t2 + facet_grid(. ~ CondCode, scales = "free", switch = "y") +
    theme(panel.spacing.x = unit(0,"line"),
          strip.background = element_rect(fill="white", color="white"),
          strip.text = element_text(face = "bold", size = 11))

library(patchwork)
(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1.5,.5)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
##### Test Age effect (uRevs) #####

# for lmer() analysis see: https://verbingnouns.github.io/notebooks/prose_statistics.nb.html 
# or: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr
# May be useful too: https://exeter-data-analytics.github.io/StatModelling/mixed-effects-models.html#model-checking-with-mixed-models
# RMEL vs. ML: https://web.stanford.edu/class/psych252/section/Mixed_models_tutorial.html

# keep only S0N0 & S0N90:
LiSNS_2 <- LiSNS %>% filter(CondCode!="SSN" & CondCode!="SRM") %>% droplevels() 
LiSNS_2 <- drop_na(LiSNS_2, uRevs)

## --------------------
# [From: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr]
# The model selection process recommended by Zuur et al. (2009) is a top-down strategy and goes as follows:
# 
# 1. fit a full model (he even recommends “beyond optimal” i.e. more complex than you’d expect or want it to be)
# 2. sort out the random effects structure (use REML likelihoods or REML AIC or BIC)
# 3. sort out fixed effects structure (either use REML the F-statistic or the t-statistic or 
#    compare nested ML models - keep your random effects constant)
# 4. once you arrive at the final model present it using REML estimation
## --------------------

##### Select model with the best fit"

# Saturated model including 2-way interaction and lower level fixed effects:
model1 <- lmer(uRevs~CondCode*Group*Age+(1|listener), LiSNS_2, REML=FALSE)
summary(model1)
tab_model(model1)
# visreg::visreg(model1)

# -----------------------------------------------------------------------------------------------------
# Chose model with the best fit (top-down stepwise method)
# test for best fit by comparing the reduced full model with a simpler model until p is significant  (<.05):
# -----------------------------------------------------------------------------------------------------
(model2<-update(model1,  ~ . - CondCode:Group:Age))
anova(model1,model2)
summary(model2)
# model2: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group + 
# model2:     CondCode:Age + Group:Age
# model1: uRevs ~ CondCode * Group * Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model2    9 352.88 374.76 -167.44   334.88                     
# model1   10 354.84 379.15 -167.42   334.84 0.0384  1     0.8447

(model3<-update(model2,  ~ . - Group:Age))
anova(model2,model3)
summary(model3)
# model3: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group + 
# model3:     CondCode:Age
# model2: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group + 
# model2:     CondCode:Age + Group:Age
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model3    8 351.06 370.50 -167.53   335.06                     
# model2    9 352.88 374.76 -167.44   334.88 0.1761  1     0.6748

(model4<-update(model3,  ~ . - CondCode:Age))
anova(model3,model4)
summary(model4)
# model4: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group
# model3: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group + 
# model3:     CondCode:Age
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model4    7 350.42 367.43 -168.21   336.42                     
# model3    8 351.06 370.50 -167.53   335.06 1.3595  1     0.2436

(model5<-update(model4,  ~ . - CondCode:Group))
anova(model4,model5)
summary(model5)
# model5: uRevs ~ CondCode + Group + Age + (1 | listener)
# model4: uRevs ~ CondCode + Group + Age + (1 | listener) + CondCode:Group
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model5    6 348.43 363.02 -168.22   336.43                     
# model4    7 350.42 367.43 -168.21   336.42 0.0143  1      0.905

(model6<-update(model5,  ~ . - Age))
anova(model5,model6)
summary(model6)
# model6: uRevs ~ CondCode + Group + (1 | listener)
# model5: uRevs ~ CondCode + Group + Age + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# model6    5 357.90 370.05 -173.95   347.90                         
# model5    6 348.43 363.02 -168.22   336.43 11.469  1  0.0007077 ***

# --> **model5 gives the best fit!** 

# uRevs ~ CondCode + Group + Age + (1 | listener)

# BestModel (model10):
BestModel <- lmer(uRevs ~ CondCode + Group + Age + (1 | listener), LiSNS_2, REML=FALSE)
tab_model(BestModel, 
          show.se =TRUE,
          show.stat = TRUE,
          show.icc = FALSE,
          show.ngroups = TRUE,
          show.obs = TRUE)

##### Test main effects:
# -----------------------------------------------------------------------------------------------------
# test main effects by comparing the FULL model to a simplified model without the predictor/interaction term.
# e.g., anova(m1,m2), anova(m1,m3), anova(m1,m4),...
# -----------------------------------------------------------------------------------------------------
# How to deal with main efect testing when there is a significant interaction: see https://stats.stackexchange.com/questions/378652/testing-the-significance-of-a-main-effect-using-model-comparison-when-an-intera

# OPTION 1: (something is strange with Chisq..)
MainEffects1.m1 <- afex::mixed(uRevs ~ CondCode + Group + Age + (1 | listener), data = LiSNS_2, method = "LRT",REML=FALSE)
# returned the following warning: $$$$
# Contrasts set to contr.sum for the following variables: CondCode, Group, listener
# Numerical variables NOT centered on 0: Age
# If in interactions, interpretation of lower order (e.g., main) effects difficult.

# lme4 reported (at least) the following warnings for 'CondCode':
#   * boundary (singular) fit: see ?isSingularMixed Model Anova Table (Type 3 tests, LRT-method)
# 
# Model: uRevs ~ CondCode + Group + Age + (1 | listener)
# Data: LiSNS_2
# Df full model: 6
#     Effect df      Chisq p.value
# 1 CondCode  1 140.37 ***   <.001
# 2    Group  1     2.76 +    .097
# 3      Age  1  11.69 ***   <.001
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘+’ 0.1 ‘ ’ 1


# OPTION 2: (Looks very similar to results "by-hand"!!)
# with Wald "Chisq" test
MainEffects2.m1 <- rstatix::Anova(BestModel,type="II",test.statistic="Chisq")
MainEffects2.m1
# Analysis of Deviance Table (Type II Wald chisquare tests)
# 
# Response: uRevs
#             Chisq Df Pr(>Chisq)    
# CondCode 639.7145  1  < 2.2e-16 ***
# Group      2.6452  1   0.103864    
# Age       12.5134  1   0.000404 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


# OPTION 3:
# Age
(BestModel.1 <- update(BestModel,  . ~ . -Age))
Age.Anova <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: uRevs ~ CondCode + Group + (1 | listener)
# BestModel: uRevs ~ CondCode + Group + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.1    5 357.90 370.05 -173.95   347.90                         
# BestModel      6 348.21 362.80 -168.11   336.21 11.688  1  0.0006291 ***

# Group
(BestModel.2<-update(BestModel, . ~ . - Group))
Group.Anova <- anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: uRevs ~ CondCode + Age + (1 | listener)
# BestModel: uRevs ~ CondCode + Group + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)  
# BestModel.2    5 348.97 361.12 -169.48   338.97                       
# BestModel      6 348.21 362.80 -168.11   336.21 2.7562  1    0.09688 .

# CondCode
(BestModel.3<-update(BestModel, . ~ . - CondCode))
CondCode.Anova <- anova(BestModel,BestModel.3)
summary(BestModel.3)
# BestModel.3: uRevs ~ Group + Age + (1 | listener)
# BestModel: uRevs ~ CondCode + Group + Age + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
# BestModel.3    5 486.59 498.74 -238.29   476.59                         
# BestModel      6 348.21 362.80 -168.11   336.21 140.37  1  < 2.2e-16 ***

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
LiSNS_AgeTab <- data.frame(rbind(
  c("Condition",CondCode.Anova$Df[2],CondCode.Anova$Chisq[2],sprintf("\\textbf{<0.001}")),
  c("Group",Group.Anova$Df[2],Group.Anova$Chisq[2],sprintf("\\textbf{%0.3f}",Group.Anova$`Pr(>Chisq)`[2])),
  c("Age",Age.Anova$Df[2],Age.Anova$Chisq[2], sprintf("\\textbf{<0.001}"))))

LiSNS_AgeTab[,c(2:3)]= apply(LiSNS_AgeTab[,c(2:3)], 2, function(x) as.numeric(as.character(x)))

colnames(LiSNS_AgeTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# -------------------------------------------------------------------------
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
# Test for age effect -----------------------------------------------------------------------------------

# # Simple ANOVA -------------------------------------------
# # S0N0 & S0N90:
# ANOVA1.m1 <- aov(uRevs~CondCode * Group * Age, data = LiSNS_Col_Sep)
# summary(ANOVA1.m1)
# # SRM only:
# ANOVA2.m1 <- aov(uRevs~Group * Age, data = LiSNS_SRM)
# summary(ANOVA2.m1)
# # SSN only:
# ANOVA3.m1 <- aov(uRevs~ Group * Age, data = LiSNS_SSN)
# summary(ANOVA3.m1)
# 
# # LMEM (collocated vs. separated) ------------------------
# # S0N0 & S0N90:
# model1 <- lmer(uRevs~CondCode + Group + Age +
#                  CondCode:Group +
#                  CondCode:Age +
#                  Group:Age +
#                  CondCode:Group:Age +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# 
# model2 <- lmer(uRevs~CondCode + Group + Age +
#                  CondCode:Group +
#                  CondCode:Age +
#                  Group:Age +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# anova(model1,model2)
# model3 <- lmer(uRevs~CondCode + Group + Age +
#                  CondCode:Group +
#                  CondCode:Age +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# anova(model2,model3)
# model4 <- lmer(uRevs~CondCode + Group + Age +
#                  CondCode:Group +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# anova(model3,model4)
# model5 <- lmer(uRevs~CondCode + Group + Age +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# model6 <- lmer(uRevs~CondCode + Group +
#                  (1|listener), LiSNS_Col_Sep, REML=FALSE)
# anova(model5,model6)
# summary(model5)
# tab_model(model5)
# 
# Anova(model5,type="II",test.statistic="Chisq")
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
##### Test z_trim #####

# for lmer() analysis see: https://verbingnouns.github.io/notebooks/prose_statistics.nb.html 
# or: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr
# May be useful too: https://exeter-data-analytics.github.io/StatModelling/mixed-effects-models.html#model-checking-with-mixed-models

## --------------------
# [From: https://ourcodingclub.github.io/tutorials/mixed-models/#fixedstr]
# The model selection process recommended by Zuur et al. (2009) is a top-down strategy and goes as follows:
# 
# 1. fit a full model (he even recommends “beyond optimal” i.e. more complex than you’d expect or want it to be)
# 2. sort out the random effects structure (use REML likelihoods or REML AIC or BIC)
# 3. sort out fixed effects structure (either use REML the F-statistic or the t-statistic or 
#    compare nested ML models - keep your random effects constant)
# 4. once you arrive at the final model present it using REML estimation
## --------------------

##### Select model with the best fit

# Saturated model including 2-way interaction and lower level fixed effects:
model1 <- lmer(z_trim~CondCode*Group+(1|listener), LiSNS_2, REML=FALSE)
summary(model1)
tab_model(model1)
# visreg::visreg(model1)

# -----------------------------------------------------------------------------------------------------
# Chose model with the best fit (top-down stepwise method)
# test for best fit by comparing the reduced full model with a simpler model until p is significant  (<.05):
# -----------------------------------------------------------------------------------------------------
(model2<-update(model1,  ~ . - CondCode:Group))
anova(model1,model2)
summary(model2)
# model2: z_trim ~ CondCode + Group + (1 | listener)
# model1: z_trim ~ CondCode * Group + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)
# model2    5 252.58 264.74 -121.29   242.58                     
# model1    6 254.06 268.64 -121.03   242.06 0.5299  1     0.4666

(model3<-update(model2,  ~ . - Group))
anova(model2,model3)
summary(model3)
# model3: z_trim ~ CondCode + (1 | listener)
# model2: z_trim ~ CondCode + Group + (1 | listener)
#        npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)  
# model3    4 255.11 264.83 -123.55   247.11                       
# model2    5 252.58 264.74 -121.29   242.58 4.5222  1    0.03346 *

# ***** ---> Best model: model2!

# z_trim ~ CondCode + Group + (1 | listener)

# BestModel (model10):
BestModel <- lmer(z_trim ~ CondCode + Group + (1 | listener), LiSNS_2, REML=FALSE)
tab_model(BestModel, 
          show.se =TRUE,
          show.stat = TRUE,
          show.icc = FALSE,
          show.ngroups = TRUE,
          show.obs = TRUE)

##### Test main effects:
# -----------------------------------------------------------------------------------------------------
# test main effects by comparing the FULL model to a simplified model without the predictor/interaction term.
# e.g., anova(m1,m2), anova(m1,m3), anova(m1,m4),...
# -----------------------------------------------------------------------------------------------------
# How to deal with main efect testing when there is a significant interaction: see https://stats.stackexchange.com/questions/378652/testing-the-significance-of-a-main-effect-using-model-comparison-when-an-intera

# Group
(BestModel.1 <- update(BestModel,  . ~ . -Group))
Group.Anova <- anova(BestModel,BestModel.1)
summary(BestModel.1)
# BestModel.1: z_trim ~ CondCode + (1 | listener)
# BestModel: z_trim ~ CondCode + Group + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)  
# BestModel.1    4 255.65 265.38 -123.83   247.65                       
# BestModel      5 253.13 265.29 -121.57   243.13 4.5179  1    0.03354 *

# CondCode
(BestModel.2<-update(BestModel, . ~ . - CondCode))
CondCode.Anova <- anova(BestModel,BestModel.2)
summary(BestModel.2)
# BestModel.2: z_trim ~ Group + (1 | listener)
# BestModel: z_trim ~ CondCode + Group + (1 | listener)
#             npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)  
# BestModel.2    4 256.27 265.99 -124.14   248.27                       
# BestModel      5 253.13 265.29 -121.57   243.13 5.1345  1    0.02346 *

# -------------------------------------------------------------------------
# get table
# -------------------------------------------------------------------------
LiSNS_zTab <- data.frame(rbind(
  c("Condition",CondCode.Anova$Df[2],CondCode.Anova$Chisq[2], CondCode.Anova$`Pr(>Chisq)`[2]),
  c("Group",Group.Anova$Df[2],Group.Anova$Chisq[2],Group.Anova$`Pr(>Chisq)`[2])))

LiSNS_zTab[,c(2:4)]= apply(LiSNS_zTab[,c(2:4)], 2, function(x) as.numeric(as.character(x)))

colnames(LiSNS_zTab)[1:4] <- c("Main effects","Df",sprintf("$\\chi^{2}$"),"p")
# mark all the significant p's
LiSNS_zTab$p = ifelse(LiSNS_zTab$p<.05,sprintf("\\textbf{%0.3f}",LiSNS_zTab$p),LiSNS_zTab$p)


# -------------------------------------------------------------------------
```

```{r, label='LiSNS-zfig', fig.cap="Add caption here.", fig.align='center', fig.width=12, fig.asp=0.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE}

t1 <- ggplot(LiSNS_NoSRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=1),outlier.shape=NA)+ 
  # scale_fill_manual(values = c("#00BFC4", "#F8766D")) +
  #geom_text(label=d$listener)+
  labs(y = "standardised residual (z-score)",x = "") + 
  guides(fill=guide_legend(title="Group")) + 
  geom_quasirandom(dodge.width=1,shape=1,colour="blue") +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  geom_vline(xintercept=c(1.5,2.5), linetype=1,color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("$\\leftarrow$ better performance"),x=0.4, y=2, angle=90, size=5)+
  scale_y_continuous(limits = c(-2,5),breaks=seq(-2,5,1)) +
  scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

t2 <- ggplot(LiSNS_SRM, aes(x=CondCode,y=z_trim,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-1.64, ymax=1.64),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=1),outlier.shape=NA)+ 
  # scale_fill_manual(values = c("#00BFC4", "#F8766D")) +
  #geom_text(label=d$listener)+s
  labs(y = "standardised residual (z-score)",x = "", label = "SRM") + 
  guides(fill=guide_legend(title="Group")) + 
  geom_quasirandom(dodge.width=1,shape=1,colour="blue") +
  geom_hline(yintercept=0, linetype="dashed",color = "black", size=0.5) +
  annotate("text", label = latex2exp::TeX("better performance $\\rightarrow$"),x=0.45, y=0.5, angle=90, size=5)+
  scale_y_continuous(limits = c(-4,3),breaks=seq(-4,3,1)) +
  scale_x_discrete(position = "top")+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        axis.ticks.x = element_line(colour = "transparent"),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.33)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))
```

#### SRTs by age {.unnumbered}

The distribution of the listeners SRTs by age, split by group, and their corresponding linear regression lines are shown in Figure \@ref(fig:LiSNS-Age) A. Due to time constrains and the large test battery, each participant was presented only once with each condition -- spatially collocated (S0N0) and the spatially separated (S0N90). Participants were also presented with a non-spatialised condition, where the same speech material was presented in a speech-shaped-noise (SSN), resulting in a total of three SRTs obtained for each listener. Additionally, the listeners SRM, calculated by taking the individual's difference between scores in the two spatialised conditions (SRM\ =\ S0N0\ -\ S0N90) is shown in Figure \@ref(fig:LiSNS-Age) B.

As previously reported by other LiSN-S test versions (e.g., Cameron et al., ,2007; REFs), the figures suggests a developmental trend in performance, with an overall improvement in performance with age. S0N90 showed the strongest age effect, with near to 1 dB improvement in performance per 1 year increase (TD slope = -0.84). The regression lines slope for S0N0 and SSN conditions where shallower, with roughly half a dB improvement in performance per 1 year increase ( with TD slope of -0.51 and -0.47, respectively). Difference in performance with age for the SRM derived measure was negligible, with a predicted improvement in SRM of circa 1 dB between the age of 7 and 13 years.

[*Pearson correlation*]{.correction}  
  
Pearson's ($\rho$) correlation test confirmed the trend seen in the scatterplots, where all three test condition (SSN, S0N0 and S0N90) showed  a significant moderate correlation between SRTs and age for the trimmed TD group, whereas no significant correlation was found for the SRM derived measure.

[*LMEM*]{.correction}  
  
A three-way 2\ x\ 2 factorial design with repeated measures was used to test the main effects of Group (APD/TD), Condition (SON0/S0N90) and Age with SRTs as dependent variable. Interaction terms were included as well as a random intercept for subects. Note that only the spatialised test conditions were included. Since the parametric model assumptions (normal distribution and homogeneity of the variance) were met, a parametric approach was selected based on a linear mixed-effects regression model (LMEM'), using the **lmer()** function (lme4 package, REF). The model that was found to give the best fit and main effects are giving in Table\ \@ref(tab:LiSNS-AgeLMEM). Model selection was based on a backward model selection procedure using a likelihood ratio test ($\chi^{2}$). The final model did not include interaction terms and thus indicating that the two groups behaved in a similar way across the two test conditions. The model revealed a highly significant main effect of Age and Condition as well as a strong main effect of Group. 

```{r,label='LiSNS-AgeLMEM',echo=FALSE,warning=FALSE, message=FALSE}
kbl(LiSNS_AgeTab, booktabs = T,escape = F,caption = "Add caption here.",
    align = c("lccc"),format = "latex",digits = 3) %>% 
  add_header_above(c("SRT ~ Condition + Group + Age + (1 | Subjects)" = 4)) %>%
  add_footnote(c("significance level = 0.05"), notation = "symbol") %>%
  column_spec(4, italic = T) 
```
  
#### Age-independent z-scores {.unnumbered}  
  
Boxplots of the listeners age-corrected standardised residuals z-scores (blue circles) collapsed across the different test conditions are shown in Figure \@ref(fig:LiSNS-zfig), separately for the APD group (red) and TD group (green). The z-scores were calculated in the exact same way as for the ST task. Again, the dashed lines indicate the TD group mean ($\sim$ 0), and the grey area indicate the lower and upper limit of normal population scores (TD mean $\pm$ 1.96). Descriptive statistics collapsed by group and test conditions are given in Table \@ref(tab:LiSNS-ztab). Overall, when compared with the control group, the APD children exhibited poorer performance (i.e., higher z-score) across all three test conditions as well as for the derived SRM measure.

SSN and S0N0 test conditions yielded the largest separation between the groups, however the spread in scores was relatively large and the percentage of abnormal performance in the APD group was small, with circa 16\% (3/19) and 26\% (5/19), respectively. Whereas, only about 10% of the APD children exhibited an abnormal score for S0N90 test condition and for the SRM measure. 
  
[*LMEM model*]{.correction} 
  
Differences between the groups for the spatialised conditions S0N0 and S0N90 was tested for a 2\ x\ 2 factorial design LMEM model was used with z-score as a dependent variable and random intercept for subjects. Model assumptions for normal distribution and homogeneity of variance was verified. The model that was found to give the best fit did not include a two-way interaction term between the main effects Group and Condition, thus suggesting again that the two groups behaved in a similar way in the two test conditions (see Table\ \@ref(tab:LiSNS-zLMEM). Comparison of the full model with a simplified model without each of the predictors revealed a significant effect of both Condition and Group. 
  
```{r,label='LiSNS-zLMEM',echo=FALSE,warning=FALSE, message=FALSE}
kbl(LiSNS_zTab, booktabs = T,escape = F,caption = "Add caption here.",
    align = c("lccc"),format = "latex",digits = 3) %>% 
  add_header_above(c("z ~ Condition + Group + (1 | Subjects)" = 4)) %>%
  add_footnote(c("significance level = 0.05"), notation = "symbol") %>%
  column_spec(4, italic = T) 
```


[*Correlation between conditions (z-score)*]{.correction}



```{r, label='LiSNS-cor', fig.cap="Add caption here.", fig.align='center', fig.asp=0.5, fig.width=12, out.width='100%', ,echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

library(ggExtra)

t1 <- ggplot(LiSNS_w, aes(x=z_trim_S0N0, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_S0N0", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t1 <- ggMarginal(t1, type="boxplot",groupFill = TRUE)

t2 <- ggplot(LiSNS_w, aes(x=z_trim_SRM, y=z_trim_S0N0, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SRM", "z_trim_"), y = str_remove("z_trim_S0N0", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t2 <- ggMarginal(t2, type="boxplot",groupFill = TRUE)

t3 <- ggplot(LiSNS_w, aes(x=z_trim_SRM, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SRM", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t3 <- ggMarginal(t3, type="boxplot",groupFill = TRUE)

t4 <- ggplot(LiSNS_w, aes(x=z_trim_SSN, y=z_trim_S0N0, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
  labs(x = str_remove("z_trim_SSN", "z_trim_"), y = str_remove("z_trim_S0N0", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none") 

t4 <- ggMarginal(t4, type="boxplot",groupFill = TRUE)

t5 <- ggplot(LiSNS_w, aes(x=z_trim_SSN, y=z_trim_S0N90, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm, se=TRUE, alpha=0.2,show.legend = FALSE) +
  stat_cor(method = "pearson", aes(color = LiSNS_w$Group), label.x = -1) +
labs(x = str_remove("z_trim_SSN", "z_trim_"), y = str_remove("z_trim_S0N90", "z_trim_"))+
  theme_bw()+
  theme(axis.text = element_text(size = 12, face="bold",colour = "black"),
        axis.title.x = element_text(size=12, face="bold"),
        axis.title.y = element_text(size=14, face="bold"),
        legend.title = element_text(size=12, face="bold"),
        legend.position="none")

t5 <- ggMarginal(t5, type="boxplot",groupFill = TRUE)

cowplot::plot_grid(t1,t2,t3,t4,t5, ncol=3, nrow = 2)

```

[*comparison with clinical data?*]{.correction}

### The Environmental Auditory Scene Analysis task (ENVASA)

```{r, echo=FALSE,results='hide',message=FALSE,warning=FALSE}
## -------------------------------------------------------------------------------------------------------
# Load data and remove outliers first
## -------------------------------------------------------------------------------------------------------
d_ENVASA_w <- read.csv(file.path(FileDir,'Files','ENVASA_2020-09-10.csv'),header=T)
colnames(d_ENVASA_w)[3] <- "Group"
d_ENVASA_w <- d %>%
  dplyr::select(listener, Age) %>%
  right_join(d_ENVASA_w, ToAdd, by = "listener")
d_ENVASA_w <- d_ENVASA_w[,-match(c("X"),names(d_ENVASA_w))]

ENVASA_TD  <- d_ENVASA_w[which(d_ENVASA_w$Group=="TD"),]
mean_TD <- round(mean(ENVASA_TD$IncongHighSNRPC_s),0)
SD_TD <- round(sd(ENVASA_TD$IncongHighSNRPC_s),0)
CutOff_TD <- round(mean_TD - SD_TD,0)
CutOff_TD2 <- round(mean_TD - 2*SD_TD,0)

ENVASA_APD <- d_ENVASA_w[which(d_ENVASA_w$Group=="APD"),]
mean_APD <- mean(ENVASA_APD$IncongHighSNRPC_s)
SD_APD <- sd(ENVASA_APD$IncongHighSNRPC_s)
CutOff_APD <- mean_APD - SD_APD

ENVASA_TD$listener[which(ENVASA_TD$IncongHighSNRPC_s<CutOff_TD)]
ENVASA_TD$IncongHighSNRPC_s[which(ENVASA_TD$IncongHighSNRPC_s<CutOff_TD)]

ENVASA_APD$listener[which(ENVASA_APD$IncongHighSNRPC_s<CutOff_APD)]
ENVASA_APD$IncongHighSNRPC_s[which(ENVASA_APD$IncongHighSNRPC_s<CutOff_APD)]

# remove scores below 2 SD (less conservative approach):
d_ENVASA_w <- d_ENVASA_w[ ! d_ENVASA_w$listener %in% "TD15", ] %>% droplevels()

nTD_ENVASA <- length(d_ENVASA_w$listener[which(d_ENVASA_w$Group=="TD")])
nAPD_ENVASA <- length(d_ENVASA_w$listener[which(d_ENVASA_w$Group=="APD")])

## -------------------------------------------------------------------------------------------------------
# get derived scores & shorten levels names (derived measures are re-calculated again using the z-transformed scores)
## -------------------------------------------------------------------------------------------------------
# Contextual pop-out effect (i.e. incongruent.-congruent)
# Combined data
d_ENVASA_w$Diff_High <- d_ENVASA_w$IncongHighSNRPC - d_ENVASA_w$CongHighSNRPC
d_ENVASA_w$Diff_Low <-  d_ENVASA_w$IncongLowSNRPC - d_ENVASA_w$CongLowSNRPC
d_ENVASA_w$Diff_Total <-d_ENVASA_w$IncongruentPC - d_ENVASA_w$CongruentPC

# Single/dual
d_ENVASA_w$Diff_High_s <- d_ENVASA_w$IncongHighSNRPC_s - d_ENVASA_w$CongHighSNRPC_s
d_ENVASA_w$Diff_Low_s <-  d_ENVASA_w$IncongLowSNRPC_s - d_ENVASA_w$CongLowSNRPC_s
d_ENVASA_w$Diff_Total_s <-d_ENVASA_w$IncongruentPC_s - d_ENVASA_w$CongruentPC_s

d_ENVASA_w$Diff_High_d <- d_ENVASA_w$IncongHighSNRPC_d - d_ENVASA_w$CongHighSNRPC_d
d_ENVASA_w$Diff_Low_d <-  d_ENVASA_w$IncongLowSNRPC_d - d_ENVASA_w$CongLowSNRPC_d
d_ENVASA_w$Diff_Total_d <-d_ENVASA_w$IncongruentPC_d - d_ENVASA_w$CongruentPC_d

d_ENVASA_w$RTLonger_2sPC <- round((d_ENVASA_w$RTLonger_2s/92)*100,2)
d_ENVASA_w$RTLonger_2sPC_s <- round((d_ENVASA_w$RTLonger_2s_s/92)*100,2)
d_ENVASA_w$RTLonger_2sPC_d <- round((d_ENVASA_w$RTLonger_2s_d/92)*100,2)

# Change data layout from Wide2Long:
d_ENVASA_L <- d_ENVASA_w %>%
  pivot_longer(
    cols = c(RTLonger_2s:RTLonger_2sPC_d), 
    names_to = c("CondCode"), 
    names_ptypes = list(CondCode = factor()),
    values_to = "PC") %>% 
    ungroup()

# Single vs dual background
d_ENVASA_L_sd <- d_ENVASA_L[ d_ENVASA_L$CondCode %in%
                               c("CongruentPC_s", "CongLowSNRPC_s", "CongHighSNRPC_s","IncongruentPC_s",
                                 "IncongLowSNRPC_s","IncongHighSNRPC_s","LowSNRPC_s","HighSNRPC_s","TotalPC_s","CatchFalsePC_s",
                                 "RTLonger_2sPC_s","Diff_High_s","Diff_Low_s","Diff_Total_s",
                                 "CongruentPC_d", "CongLowSNRPC_d", "CongHighSNRPC_d","IncongruentPC_d",
                                 "IncongLowSNRPC_d","IncongHighSNRPC_d","LowSNRPC_d","HighSNRPC_d","TotalPC_d","CatchFalsePC_d",
                                 "RTLonger_2sPC_d","Diff_High_d","Diff_Low_d","Diff_Total_d"), ] %>% droplevels()
# combined data only
d_ENVASA_L_c <- d_ENVASA_L[ d_ENVASA_L$CondCode %in%
                               c("CongruentPC", "CongLowSNRPC", "CongHighSNRPC","IncongruentPC",
                                 "IncongLowSNRPC","IncongHighSNRPC","LowSNRPC","HighSNRPC", "TotalPC",
                                 "CatchFalsePC","RTLonger_2sPC","Diff_High","Diff_Low","Diff_Total"), ] %>% droplevels()

d_ENVASA_L_sd$CondCode <- revalue(d_ENVASA_L_sd$CondCode, c("CongruentPC_s"="C_s",
                                                      "CongHighSNRPC_s"="C_High_s", 
                                                      "CongLowSNRPC_s"="C_Low_s",
                                                      "IncongruentPC_s"="I_s",
                                                      "IncongHighSNRPC_s"="I_High_s",
                                                      "IncongLowSNRPC_s"="I_Low_s",
                                                      "LowSNRPC_s"="Low_s",
                                                      "HighSNRPC_s"="High_s",
                                                      "TotalPC_s"="Total_s",
                                                      "CatchFalsePC_s"="CatchFalse_s",
                                                      "RTLonger_2sPC_s"="RTLonger_2s_s",
                                                      "Diff_High_s"="DiffHigh_s",
                                                      "Diff_Low_s"="DiffLow_s",
                                                      "Diff_Total_s"="DiffTotal_s",

                                                      "CongruentPC_d"="C_d",
                                                      "CongHighSNRPC_d"="C_High_d", 
                                                      "CongLowSNRPC_d"="C_Low_d",
                                                      "IncongruentPC_d"="I_d",
                                                      "IncongHighSNRPC_d"="I_High_d",
                                                      "IncongLowSNRPC_d"="I_Low_d",
                                                      "LowSNRPC_d"="Low_d",
                                                      "HighSNRPC_d"="High_d",
                                                      "TotalPC_d"="Total_d",
                                                      "CatchFalsePC_d"="CatchFalse_d",
                                                      "RTLonger_2sPC_d"="RTLonger_2s_d",
                                                      "Diff_High_d"="DiffHigh_d",
                                                      "Diff_Low_d"="DiffLow_d",
                                                      "Diff_Total_d"="DiffTotal_d"))

d_ENVASA_L_c$CondCode <- revalue(d_ENVASA_L_c$CondCode, c("CongruentPC"="C",
                                                          "CongHighSNRPC"="C_High",
                                                          "CongLowSNRPC"="C_Low",
                                                          "IncongruentPC"="I",
                                                          "IncongHighSNRPC"="I_High",
                                                          "IncongLowSNRPC"="I_Low",
                                                          "LowSNRPC"="Low",
                                                          "HighSNRPC"="High",
                                                          "TotalPC"="Total",
                                                          "CatchFalsePC"="CatchFalse",
                                                          "RTLonger_2sPC"="RTLonger_2s",
                                                          "Diff_High"="DiffHigh",
                                                          "Diff_Low"="DiffLow",
                                                          "Diff_Total"="DiffTotal")) 

# remove non-raw conditions 
d_ENVASA_L_sd_raw <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in%
                               c("C_Low_s","C_High_s","I_Low_s","I_High_s",
                                 "C_Low_d","C_High_d","I_Low_d","I_High_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode, "_s")=="TRUE","Single","Dual")
# get SNR / Congruent/Incongruent info:
d_ENVASA_L_sd_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
d_ENVASA_L_sd_raw$SNR <- ifelse(str_detect(d_ENVASA_L_sd_raw$CondCode,"High")=="TRUE","High","Low")

d_ENVASA_L_sd_raw$BackgroundType <- factor(d_ENVASA_L_sd_raw$BackgroundType , levels = c("Single","Dual"))
d_ENVASA_L_sd_raw$MaskerType <- factor(d_ENVASA_L_sd_raw$MaskerType , levels = c("Congruent","Incongruent"))
d_ENVASA_L_sd_raw$SNR <- factor(d_ENVASA_L_sd_raw$SNR , levels = c("Low","High"))

# get dataframe with difference scores
d_ENVASA_L_sd_diff <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in% 
                                    c("DiffHigh_s","DiffLow_s","DiffTotal_s",
                                      "DiffHigh_d","DiffLow_d","DiffTotal_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_diff$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_diff$CondCode, "_s")=="TRUE","Single","Dual")
d_ENVASA_L_sd_diff$BackgroundType <- factor(d_ENVASA_L_sd_diff$BackgroundType , levels = c("Single","Dual"))
# get SNR info:
d_ENVASA_L_sd_diff$SNR <- ifelse(str_detect(d_ENVASA_L_sd_diff$CondCode,"High")=="TRUE","High","Low")
d_ENVASA_L_sd_diff$SNR <- factor(d_ENVASA_L_sd_diff$SNR , levels = c("Low","High"))

# get dataframe with difference scores
d_ENVASA_L_c_diff <- d_ENVASA_L_c[ d_ENVASA_L_c$CondCode %in% 
                                    c("DiffHigh","DiffLow","DiffTotal"), ] %>% droplevels()
# get dataframe for combined scores
d_ENVASA_L_c_Total <- d_ENVASA_L_c[ d_ENVASA_L_c$CondCode %in% "Total", ] %>% droplevels()

# get dataframe for combined scores
d_ENVASA_L_Total  <- d_ENVASA_L_sd[ d_ENVASA_L_sd$CondCode %in%
                               c("Total_s","Total_d"), ] %>% droplevels()

d_ENVASA_L_Total <- rbind(d_ENVASA_L_Total,d_ENVASA_L_c_Total)

## -------------------------------------------------------------------------------------------------------
# get z-transformed scores and re-calculate the derived measures
## -------------------------------------------------------------------------------------------------------
## get z-scores by speech material
source("functions/getZ.R")

# get direction of the z-scores for the trimming of TD's abnormal scores
zNegative <- c("CatchFalse_s","CatchFalse_d","RTLonger_2s_s","RTLonger_2s_d")
d_ENVASA_L_sd$zDirection <- NULL
d_ENVASA_L_sd$zDirection <- ifelse((d_ENVASA_L_sd$CondCode %in% zNegative)==TRUE,-1,1)

zNegative <- c("CatchFalse","RTLonger_2s")
d_ENVASA_L_c$zDirection <- NULL
d_ENVASA_L_c$zDirection <- ifelse((d_ENVASA_L_c$CondCode %in% zNegative)==TRUE,-1,1)

#Change PC name to uRevs (ugly solution to use getZ...)
colnames(d_ENVASA_L_sd)[5] <- "uRevs"
colnames(d_ENVASA_L_c)[5] <- "uRevs"

# get z-scores
Output <- getZ(d_ENVASA_L_sd,CutOff)
d_ENVASA_L_sd <- Output[[1]]

Output <- getZ(d_ENVASA_L_c,CutOff)
d_ENVASA_L_c <- Output[[1]]

# change back column name to PC (ugly solution to use getZ...)
colnames(d_ENVASA_L_sd)[5] <- "PC"
colnames(d_ENVASA_L_c)[5] <- "PC"

# change from Long2Wide format to get derived measures
d_ENVASA_sd_w <- d_ENVASA_L_sd %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("z_trim")) %>%
  ungroup()

d_ENVASA_c_w <- d_ENVASA_L_c %>%
  pivot_wider(
    id_cols = c("listener","Group","Age"),
    names_from = "CondCode",
    values_from = c("z_trim")) %>%
  ungroup()

# Contextual pop-out effect (i.e. incongruent.-congruent)
# Combined data
d_ENVASA_c_w$Diff_High  <- d_ENVASA_c_w$I_High - d_ENVASA_c_w$C_High
d_ENVASA_c_w$Diff_Low   <- d_ENVASA_c_w$I_Low - d_ENVASA_c_w$C_Low
d_ENVASA_c_w$Diff_Total <- d_ENVASA_c_w$I - d_ENVASA_c_w$C

# Single/dual
d_ENVASA_sd_w$Diff_High_s  <- d_ENVASA_sd_w$I_High_s - d_ENVASA_sd_w$C_High_s
d_ENVASA_sd_w$Diff_Low_s   <- d_ENVASA_sd_w$I_Low_s - d_ENVASA_sd_w$C_Low_s
d_ENVASA_sd_w$Diff_Total_s <- d_ENVASA_sd_w$I_s - d_ENVASA_sd_w$C_s

d_ENVASA_sd_w$Diff_High_d  <- d_ENVASA_sd_w$I_High_d - d_ENVASA_sd_w$C_High_d
d_ENVASA_sd_w$Diff_Low_d   <- d_ENVASA_sd_w$I_Low_d - d_ENVASA_sd_w$C_Low_d
d_ENVASA_sd_w$Diff_Total_d <- d_ENVASA_sd_w$I_d - d_ENVASA_sd_w$C_d

# change data from Wide2Long
d_ENVASA_L_sd_z <- d_ENVASA_sd_w %>%
  pivot_longer(
    cols = c(CatchFalse_s:Diff_Total_d), 
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()

d_ENVASA_L_c_z <- d_ENVASA_c_w %>%
  pivot_longer(
    cols = c(CatchFalse:Diff_Total),
    names_to = "CondCode", 
    names_ptypes = list(CondCode = factor()),
    values_to = "zScore") %>% 
  ungroup()

## -------------------------------------------------------------------------------------------------------
# get separate data frames for the different plots
## -------------------------------------------------------------------------------------------------------
                              
# remove non-raw conditions 
d_ENVASA_L_sd_z_raw <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in%
                               c("C_Low_s","C_High_s","I_Low_s","I_High_s",
                                 "C_Low_d","C_High_d","I_Low_d","I_High_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_z_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode, "_s")=="TRUE","Single","Dual")
# get SNR / Congruent/Incongruent info:
d_ENVASA_L_sd_z_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
d_ENVASA_L_sd_z_raw$SNR <- ifelse(str_detect(d_ENVASA_L_sd_z_raw$CondCode,"High")=="TRUE","High","Low")

d_ENVASA_L_sd_z_raw$BackgroundType <- factor(d_ENVASA_L_sd_z_raw$BackgroundType , levels = c("Single","Dual"))
d_ENVASA_L_sd_z_raw$MaskerType <- factor(d_ENVASA_L_sd_z_raw$MaskerType , levels = c("Congruent","Incongruent"))
d_ENVASA_L_sd_z_raw$SNR <- factor(d_ENVASA_L_sd_z_raw$SNR , levels = c("Low","High"))

# get dataframe with difference scores
d_ENVASA_L_sd_z_diff <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in% 
                                    c("DiffHigh_s","DiffLow_s","DiffTotal_s",
                                      "DiffHigh_d","DiffLow_d","DiffTotal_d"), ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_sd_z_diff$BackgroundType <- ifelse(str_detect(d_ENVASA_L_sd_z_diff$CondCode, "_s")=="TRUE","Single","Dual")
d_ENVASA_L_sd_z_diff$BackgroundType <- factor(d_ENVASA_L_sd_z_diff$BackgroundType , levels = c("Single","Dual"))
# get SNR info:
d_ENVASA_L_sd_z_diff$SNR <- ifelse(str_detect(d_ENVASA_L_sd_z_diff$CondCode,"High")=="TRUE","High","Low")
d_ENVASA_L_sd_z_diff$SNR <- factor(d_ENVASA_L_sd_z_diff$SNR , levels = c("Low","High"))

# get dataframe for combined scores
d_ENVASA_L_sd_z_Total <- d_ENVASA_L_sd_z <- d_ENVASA_L_sd_z[ d_ENVASA_L_sd_z$CondCode %in%
                               c("Total_s","Total_d"), ] %>% droplevels()

# remove non-raw conditions 
d_ENVASA_L_c_z_raw <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in%
                               c("C_Low","C_High","I_Low","I_High",
                                 "C_Low","C_High","I_Low","I_High"), ] %>% droplevels()

# get dataframe with difference scores
d_ENVASA_L_c_z_diff <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in% 
                                    c("DiffHigh","DiffLow","DiffTotal"), ] %>% droplevels()

# get dataframe for combined scores
d_ENVASA_L_c_z_Total <- d_ENVASA_L_c_z[ d_ENVASA_L_c_z$CondCode %in% "Total", ] %>% droplevels()

# get background info (single/dual)                                      
d_ENVASA_L_c_z_raw$BackgroundType <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode, "_s")=="TRUE","Single","Dual")
# get SNR / Congruent/Incongruent info:
d_ENVASA_L_c_z_raw$MaskerType <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode,"C")=="TRUE","Congruent","Incongruent")
d_ENVASA_L_c_z_raw$SNR <- ifelse(str_detect(d_ENVASA_L_c_z_raw$CondCode,"High")=="TRUE","High","Low")

d_ENVASA_L_c_z_raw$BackgroundType <- factor(d_ENVASA_L_c_z_raw$BackgroundType , levels = c("Single","Dual"))
d_ENVASA_L_c_z_raw$MaskerType <- factor(d_ENVASA_L_c_z_raw$MaskerType , levels = c("Congruent","Incongruent"))
d_ENVASA_L_c_z_raw$SNR <- factor(d_ENVASA_L_c_z_raw$SNR , levels = c("Low","High"))

# combine scores
d_ENVASA_L_Total_z <- rbind(d_ENVASA_L_sd_z_Total,d_ENVASA_L_c_z_Total)
```

```{r, label='ENVASA-Age', eval=FALSE, include=FALSE, warning=FALSE}

## Test assumptions

# ------------------------------------------------
# 1. Normality (Shapiro test) 
# linear model

Total_s <- d_ENVASA_L_Total[ d_ENVASA_L_Total$CondCode %in% "Total_s", ] %>% droplevels()
Total_d <- d_ENVASA_L_Total[ d_ENVASA_L_Total$CondCode %in% "Total_d", ] %>% droplevels()
Total <- d_ENVASA_L_Total[ d_ENVASA_L_Total$CondCode %in% "Total", ] %>% droplevels()

w1 <- lm(PC~ Group+Age, data = Total_s)
w2 <- lm(PC~ Group+Age, data = Total_d)
w3 <- lm(PC~ Group+Age, data = Total)
# Option 1:
shapiro.test(residuals(w1))
# p-value = 0.02637 ---> normal distr is rejected!
shapiro.test(residuals(w2))
# p-value = 0.008685 ---> normal distr is rejected!
shapiro.test(residuals(w3))
# p-value = 0.002974 ---> normal distr is rejected!

# ------------------------------------------------
# 2. Homogeneity of variance test (Levene's test)
# Interpretation: homogeneity is met if p>.05

# Option 1:
car::leveneTest(PC ~ Group, data=Total_s)
# Results: p value = 0.3101
# Interpretation: test is significant, i.e., the null hypothesis that the variance is not equal is rejected. ==> Assumption of homogeneity is met!
car::leveneTest(PC ~ Group, data=Total_d)
# Results: p value = 0.2418
car::leveneTest(PC ~ Group, data=Total)
# Results: p value = 0.2243

# ------------------------------------------------
# simple anova per condition
Anova.Total_s <- aov(PC~Group*Age, data = Total_s)
summary(Anova.Total_s)

Anova.Total_d <- aov(PC~Group*Age, data = Total_d)
summary(Anova.Total_d)

Anova.Total <- aov(PC~Group*Age, data = Total)
summary(Anova.Total)

# ------------------------------------------------
```

```{r,label='ENVASA-plots1', fig.cap="Scatterplot and linear regression lines for the ENVASA task \\%-correct as a function of age for single background, dual background and combined measure. Red indicates data from the APD group and green indicates data from the TD control group. The grey area represents the regression line 95\ \\% confidence interval.", echo=FALSE, fig.align='center', message=FALSE, out.width='100%', warning=FALSE}
# Total PC scores by age
# Kendall rank correlation test (Kendall's tau) for non-parametric data with a small sample size
# See debate here: https://www.researchgate.net/post/Does_Spearmans_rho_have_any_advantage_over_Kendalls_tau

d_ENVASA_L_Total$CondCode <- factor(d_ENVASA_L_Total$CondCode,levels=c("Total_s", "Total_d", "Total"))

t1 <- ggplot(d_ENVASA_L_Total, aes(x=Age, y=PC, color=Group)) +
  geom_point(size=2) +
  geom_smooth(aes(group=Group,colour=Group),method=lm , fill="#69b3a2", se=TRUE, alpha=0.3) +
  stat_cor(method = "kendall", cor.coef.name = "tau", aes(color = Group), label.x = 8, label.y = c(30,35), 
na.rm = TRUE) +
  #geom_smooth(method=lm , color="red", fill="#69b3a2", se=TRUE) +
  labs(y = "% correct",x = "Age") + 
  scale_y_continuous(limits = c(0,100),breaks=seq(0,100,10))+
  scale_x_continuous(breaks=seq(7,13,1),labels=c("7","8","9","10","11","12","13"),limits=c(7, 13))+
  theme_bw() +
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=10, face="bold"),
        legend.direction = "horizontal",
        legend.position = c(0.167,0.1),
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"))

t1 + facet_grid(. ~ CondCode, scales = "free", switch = "y",
                labeller = labeller(CondCode = c("Total_s" ="Single background","Total_d"="Dual backgrounds",
                            "Total"="Combined"))) +
                  theme(panel.spacing.x = unit(0,"line"),
                        strip.background = element_rect(fill="white", color="white"),
                        strip.text = element_text(face = "bold", size = 11))
```

Initial inspection of the individuals performance was performed to ensure that the task instructions were followed and well understood. Performance for the reference condition (single incongruent background at a high SNR), which is expected to least impact performance, was compared with a cut-off criterion of `r CutOff_TD2` %, calculated as 2 standard deviations from the TD group mean (`r mean_TD` % $\pm$ `r SD_TD` %). Individuals with performance bellow the cut-off criterion were excluded from the analysis. One TD group aged 7 years old who scored 45 % was thus excluded. Of the remaining data `r nTD_ENVASA` belonged to the TD group and `r nAPD_ENVASA` to the APD group.

Due to the small number of observations in each condition and for clarity, %-correct was calculated for three measures: i. a *single background*, ii. a *dual backgrounds*, iii. and a *combined* measure where scores in both conditions were summed together[^rmd-basics-cites-and-refs-2]. Visual inspection of the listeners scores as a function of age (see Figure \@ref(fig:ENVASA-plots1)) showed a developmental trend in performance. This was suppurated by Kendall rank correlation test for non-parametric data with small sample-size, where performance significantly improved with increased age across the groups in all three measures (p \< .05), excluding the APD group for single background (p = 0.096; see the complete test results in Figure \@ref(fig:ENVASA-plots1)). This is in agreement with @Krishnan2013 study where they found a strong developmental effect across normal-hearing typically developing children in a similar age range to those measured in the present study.

[^rmd-basics-cites-and-refs-2]: See Appendix ?? for a more detailed summary of the listeners scores split into the different test condition.

Thus, for further analysis, age was controlled for using the same multiple-case approach method described in ????. Age-independent score was predicted using a linear regression model which was performed separately for each measure. The model was estimated from the TD data only with %-correct as the dependent variable and age as a predictor. Standard residuals were calculated for each listener, resulting in age-independent residuals that are comparable to z-scores for data with normal distribution, with a mean and SD of approximately 0 and 1, respectively. Furthermore, to reduce possible bias, outliers in the TD group were identified and removed from the model, while they were included back again for the calculation of the standardised residuals. The outliers criteria was set to TD scores more than 1.65 SD below the TD group mean. Boxplots of the age-independent z-scores for the three measures are shown in Figure \@ref(fig:ENVASA-plots2). The red dashed line (z = -1.64) indicate the cut-off value for normal score, where only about 5 % of the normal population would be expected to score below it; the green dashed line (z = +1.64) indicate scores above which only 5 % of the normal population is expected to exceed.

Group difference was analysed using Wilcoxon rank-sum test for independent two samples test which is a t-test equivalent for non-parametric data [N = 999999 permutations and with bonferroni p-value adjustment; 'coin::wilcox_test()', REF]. Effect size (*r*) was analysed using 'rstatix::wilcox_effsize' (REF). Descriptive scores by group collapsed by the three test measures as well as p statistics and effect size are given in Table \@ref(tab:ENVASA-Wilk). Performance of children in the APD group was significantly poorer than of the children in the TD group for both single and combined measure (*p \< 0.05*, moderate effect size), whereas no significant difference in performance between the groups was found for the dual backgrounds measure (*p = 0.118*).

```{r, label='ENVASA-plots2', fig.cap="ENVASA standardised residuals for the \\%-correct in single background, dual background and combined measure. The dashed red line (z\ =\ -1.64) indicate the cut-off value for normal score, where only about 5\ \\% of the normal population would be expected to score below it; the dashed green line (z\ =\ +1.64) indicate scores above which only 5\ \\% of the normal population is expected to exceed.", fig.align='center', out.width='100%', ,echo=FALSE, warning=FALSE, message=FALSE}
# Total z-scores 
ggplot(d_ENVASA_L_Total_z, aes(x=CondCode,y=zScore,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=-CutOff, ymax=CutOff),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA,na.rm=TRUE)+ 
  #geom_text(label=d_ENVASA_L_Total_z$listener)+
  labs(y = "standardised residual (z-score)",x = "")+ 
  guides(fill=guide_legend(title="Group"))+ 
  geom_quasirandom(dodge.width=0.9,colour="blue")+
  scale_y_continuous(limits = c(-8,2),breaks=seq(-8,2,1))+
  scale_x_discrete(labels=c("Total_s" ="Single background","Total_d"="Dual backgrounds",
                            "Total"="Combined"))+
  annotate("text", label = latex2exp::TeX("better performance $\\rightarrow$"), x = 0.5, y = -5, size = 4, angle = 90, colour = "black")+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.position="none")
```

```{r,label='ENVASA-Wilk',echo=FALSE,warning=FALSE, message=FALSE}
# --------------------------------------------------------------------------------------------------
# Compare differences between Groups by Condition
# --------------------------------------------------------------------------------------------------
# Wilcoxon rank sum test / Mann-Whitney U test (for 2 independent UNPAIRED samples 
# --> two types of measurements) when data is non-parametric (data (when) 
# normality and/or homogeneity of variance is violated
# --------------------------------------------------------------------------------------------------

Wilk_ENVASA <- d_ENVASA_L_Total_z %>%
  group_by(CondCode) %>%
  rstatix::wilcox_test(data =., zScore ~ Group, paired=FALSE, detailed=TRUE) %>%
  adjust_pvalue(method = "bonferroni") %>%
  add_significance("p.adj")
Wilk_ENVASA$CI <- sprintf("%.02f - %.02f",round(Wilk_ENVASA$conf.low,2),round(Wilk_ENVASA$conf.high,2))

Wilk_ENVASA_effectSize <- d_ENVASA_L_Total_z %>%
  group_by(CondCode) %>%
  wilcox_effsize(data =., zScore ~ Group, paired=FALSE, detailed=TRUE)
Wilk_ENVASA_effectSize$effsize <- round(Wilk_ENVASA_effectSize$effsize,2)

# ----$$$$$$$$$---------------------------------------------------------------------------------------
## Wilcoxon rank-sum test / Mann-Whitney U test for independent 2 samples in non-parametric data (when normality assumption is violated)
## ** With permutation **
#library(coin)
#library(effsize)
# results_p <- numeric(length(levels(d_ENVASA_L_Total_z$CondCode))) 
# effectSize <- data.frame()
# for (nCond in 1:length(levels(d_ENVASA_L_Total_z$CondCode))) {
#   #print(paste0("Calculating z-scores for: ", levels(ENVASA.Wilk$CondCode)[nCond],""))
#   # get all subjects' scores in a single condition 
#   nCondData <- d_ENVASA_L_Total_z[which(d_ENVASA_L_Total_z$CondCode == levels(d_ENVASA_L_Total_z$CondCode)[nCond]),]
#   results_p[nCond] <- pvalue(coin::wilcox_test(zScore ~ Group, data = nCondData,
#                                          p.adjust.method ="bonferroni", na.rm=TRUE, paired = FALSE,
#                                          distribution=approximate(nresample=999999)))[1]
#   # optional: get effect size (r):
#   effectSize[nCond,1:7] <- rstatix::wilcox_effsize(zScore~ Group, data = nCondData, paired = FALSE)
#   
#   # nEffectSize <- VD.A(d=nCondData$zScore,f=nCondData$Group)
#   # effectSize[nCond,1:5] <- cbind(levels(d_ENVASA_L_Total_z$CondCode)[nCond],matrix(unlist(nEffectSize),ncol=4))
#   }
# effectSize$effsize <- round(effectSize$effsize,3)
# colnames(effectSize)[4] = "effect-size (r)"
# significance <- ifelse(results_p < .05, "sig.","n.s")

# --------------------------------------------------------------------------------------------------
# get table
ENVASA_tab_TD <- d_ENVASA_L_Total_z %>% filter(Group=="TD") %>%
ddply(.,~CondCode*Group,summarise,N=length(zScore),median=round(median(zScore,na.rm=TRUE),2),SD=round(sd(zScore,na.rm=TRUE),2),min=round(min(zScore,na.rm=TRUE),2),max=round(max(zScore,na.rm=TRUE),2)) 
# remove group column
ENVASA_tab_TD <- ENVASA_tab_TD[-c(2)]

ENVASA_tab_APD <- d_ENVASA_L_Total_z %>% filter(Group=="APD") %>%
ddply(.,~CondCode*Group,summarise,N=length(zScore),median=round(median(zScore,na.rm=TRUE),2),SD=round(sd(zScore,na.rm=TRUE),2),min=round(min(zScore,na.rm=TRUE),2),max=round(max(zScore,na.rm=TRUE),2)) 

ENVASA_tab <- cbind(ENVASA_tab_TD,ENVASA_tab_APD[3:7],
                 "CI"=Wilk_ENVASA$CI,"p"=round(Wilk_ENVASA$p,2),
                 "effect size (r)"=round(Wilk_ENVASA_effectSize$effsize,2),
                 "magnitude"=Wilk_ENVASA_effectSize$magnitude)
colnames(ENVASA_tab)[1] = "background"
ENVASA_tab$background <- c("single","dual","combined")

# prepare table using kbl()
# for more options see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
kbl(ENVASA_tab, booktabs = T, caption = "ENVASA standard residuals (z-scores) descriptive statistics and group difference analysis by test measures.",
    align = c("lccccccccc")) %>% 
  kable_styling(latex_options = c("scale_down")) %>%
  add_header_above(c(" ", "TD" = 5, "APD" = 5,"Wilcoxon rank-sum test" = 4)) %>%
  column_spec(12,border_left = T) %>% column_spec(13:14, italic = T)
```

-   Correlation with other measures

For appendix:

-   similar figure to Kirshnan's figure with % correct & scores by age & z-scores

### CELF-RS

```{r, label='CELF', fig.cap="Boxplots for CELF-5 UK Recall Sentences subtest scaled scores by groups. The dashed line represents the norms mean and the grey area indicate the upper and lower limit of an average performance in the normal population ($\\pm$\ 1\ SD).", fig.align='center', fig.width=3, fig.asp=0.5, out.width='50%', ,echo=FALSE,warning=FALSE, message=FALSE}

d_RS<- read.csv(file.path(FileDir,'Files','CELF_RS_13032020.csv'),header=T)

# merge data frames to include extra info
d_RS <- merge(d_Info,d_RS,by=c("listener"))

d_RS$Group <- factor(d_RS$Group,levels=c("APD","TD"))

describeBy(ScaledScore~Group, data=d_RS, mat=TRUE, digits=2)
# --------------------------------------------------------------------------------------------------
# Assumptions:

# linear model
w1 <- lm(ScaledScore ~ Group, data = d_RS)

# 1. Normality (Shapiro-Wilk test) --> ~is met!
# data is normally distributed if p >.05

# QQ plot of residuals
# qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
# par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
# qqnorm(d_RS$ScaledScore, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
# qqline(d_RS$ScaledScore, col = "red", lwd = 2)
# qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
# qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- d_RS %>%
  group_by(Group) %>%
  rstatix::shapiro_test(ScaledScore)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05
# Option 1:
car::leveneTest(ScaledScore ~ Group, data=d_RS,center=median)
# Option 2: 
DescTools::LeveneTest(lm(ScaledScore~ Group, data = d_RS))

# --------------------------------------------------------------------------------------------------
# Parametric test assumptions are met -> t-test is used.
# boot.t.test is the same as the regular t.test function but with bootstrapping.
RS_ttest <- MKinfer::boot.t.test(ScaledScore~ Group, data = d_RS, paired = FALSE,conf.level = 0.95, R = 9999)
# --------------------------------------------------------------------------------------------------
# get table
RS_tab_TD <- d_RS %>% filter(Group=="TD") %>%
ddply(.,~Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),
      SD=round(sd(ScaledScore,na.rm=TRUE),2),min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) 

RS_tab_APD <- d_RS %>% filter(Group=="APD") %>%
ddply(.,~Group,summarise,N=length(ScaledScore),median=round(median(ScaledScore,na.rm=TRUE),2),
      SD=round(sd(ScaledScore,na.rm=TRUE),2),min=round(min(ScaledScore,na.rm=TRUE),2),max=round(max(ScaledScore,na.rm=TRUE),2)) 

# RS_tab <- cbind(RS_tab_TD[2:6],RS_tab_APD[2:6],p=round(results_p,3),effectSize[c(4,7)])
RS_tab <- cbind(RS_tab_TD[2:6],RS_tab_APD[2:6])

# --------------------------------------------------------------------------------------------------
# get plot
ggplot(d_RS, aes(x=Group,y=ScaledScore,fill=Group))+ 
  geom_rect(aes(xmin=-Inf, xmax=Inf, ymin=7, ymax=13),fill="lightgray", alpha=0.05)+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+ 
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  #geom_text(label=d_RS$listener)+
  labs(y = "Scaled score",x = "Group")+ 
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(1,19),breaks=seq(1,19,2))+
  scale_x_discrete(labels=c("APD","TD"))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))
```

Boxplots of children's age-corrected scaled scores split into groups for the CELF-5 UK Recalling Sentences subtest are given in Figure \@ref(fig:CELF). The grey area indicate the upper and lower norms limit among the normal population ($\pm$ 1 SD).

On average, performance was within the norms range in both the APD group (median = `r RS_tab_APD$median`) and the TD group, albeit laying within the upper norms limit (median = `r RS_tab_TD$median`). Thus, although the majority of the APD children expressive language skills were within the norms, the figure reveals a clear difference in performance between the group, where the TD children expressive language skills are noticeably better than for children in the APD group. 

Almost half of the TD children obtained a scaled score above the average and none exhibited abnormal scores. On the other hand, only three APD children performed above the average and performance of two children was considered to be abnormal (scaled score =  6).

An independent-samples t-test with bootstrapping (n=9999) was computed using **boot.t.test()** function (MKinfer package, REF) to compare the listeners scaled scores in the two groups (parametric data assumptions were met). There was a highly significant difference in scaled scores between the APD (M\ =\ 9.5, SD\ =\ 2.7) and TD group (M\ =\ 13.6, SD\ =\ 3.1) [t(`r round(RS_ttest$parameter,2)`) = `r round(RS_ttest$statistic,2)`, p\ =\ <\ 0.001]. 

### Questionnaires

#### CCC-2

data for on listener (TD13) was flagged as inconsistent and thus was removed.
```{r, label='CCC2', fig.cap="Add caption here.", fig.align='center', fig.width=20, fig.asp=.4, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

d_CCC2<- read.csv(file.path(FileDir,'Files','CCC2_13032020.csv'),header=T)

# Arrange table
colnames(d_CCC2)[8] <- "A.speech"
colnames(d_CCC2)[10] <- "C.semantic"
d_CCC2$group.diagnosis[d_CCC2$group.diagnosis == "1"] <- "APD"
d_CCC2$group.diagnosis[d_CCC2$group.diagnosis == "2"] <- "TD"
d_CCC2$group.diagnosis <- factor(d_CCC2$group.diagnosis,levels=c("APD","TD"))

# delete some columns
# Clean data
d_CCC2[is.na(d_CCC2),]
d_CCC2 <- na.omit(d_CCC2) # remove rows with missing data
# use data only if ConsistencyCheck equal to 1
d_CCC2 <- d_CCC2 %>% filter(ConsistencyCheck==1) %>% droplevels() 
# d_CCC2 <- d_CCC2[,-match(c("date.of.CCC","dob","informant","GCC","SPC","pass.consistency.check...1.yes..0.no.","neg.mean","pos.mean"),names(d_CCC2))] %>% droplevels() 


# change format from wide 2 long
library(tidyr)
d_CCC2_L <- gather(d_CCC2,group.diagnosis, gender, A.speech:J.interests, factor_key=TRUE)

# change columns names
colnames(d_CCC2_L)[1] <- "listener"
colnames(d_CCC2_L)[2] <- "DOB"
colnames(d_CCC2_L)[4] <- "Age"
colnames(d_CCC2_L)[9] <- "Measure"
colnames(d_CCC2_L)[10] <- "ScaledScore"

# convert age from months to years
d_CCC2_L$Age <- round(d_CCC2_L$Age/12,2)

# get groups association
# library(stringr)
d_CCC2_L$Group <- ifelse((str_detect(d_CCC2_L$listener,"APD")=="TRUE"),"APD","TD")
d_CCC2_L$ScaledScore <- as.numeric(as.character(d_CCC2_L$ScaledScore))
d_CCC2_L$Group <- factor(d_CCC2_L$Group,levels=c("APD","TD"))
#str(d_CCC2_L)

# merge data frames  -----------------------------------------------------------------------------------------------
d_CCC2_L <- merge(d_Info,d_CCC2_L,by=c("listener"))
# d_CCC2_L <- d_CCC2_L[,-match(c("Group.y"),names(d_CCC2_L))]
# colnames(d_CCC2_L)[2] = "Group"

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects
if (RmvSubj==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include subjects based on the quality of their testing 
if (QualityCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_E_L$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis 
if (DiagCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns
if (APDsubTypCtrl==1){d_CCC2_L <- d_CCC2_L[ ! d_CCC2_L$Subtype %in% rmvAPDType, ] %>% droplevels()}
## ------------------------------------------------------------------------------------------------------------------

# Check for scores that are cilincally significant
LowScore_CCC2 <- d_CCC2_L %>% filter(ScaledScore<4) 
# get frequency per listener
SigLowScore_CCC2 <- data.frame(table(LowScore_CCC2$listener))
colnames(SigLowScore_CCC2)[1] <- "listener"

# Filter listners with significant scores
SigLowScore_CCC2 <- SigLowScore_CCC2 %>% filter(Freq>=2) %>% droplevels() 

Sig_listeners<-levels(SigLowScore_CCC2$listener)
length(Sig_listeners)
# 13 listeners has sig low scores: APD=12; TD=1

# Data without subjects with significantly low scores
d_CCC2_L_Clean <- d_CCC2_L[ ! d_CCC2_L$listener %in% Sig_listeners, ] %>% droplevels()

t1 <- ggplot(d_CCC2_L, aes(x=Measure,y=ScaledScore,fill=Group))+
  geom_boxplot(position=position_dodge(width=0.8))+
  geom_hline(yintercept=4, linetype="dashed", color = "red")+
  #geom_text(label=d_CCC2_L$listener)+
  labs(y = "Scaled Score",x = "Measure")+
  guides(fill=guide_legend(title="Group"))+
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(0,16),breaks=seq(0,16,2))+
  #scale_x_discrete(labels=c("TD","APD"))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))

# plot GCC and mark subjects with a combination of negative SPC in red (indicative of ASD)
SumScores <- subset(d_CCC2_L, Measure=="A.speech") %>% droplevels() 
SumScores$Abnormal <- ifelse(SumScores$SPC<0 & SumScores$GCC<55,1,0)

t2 <- ggplot(SumScores, aes(x=Group,y=GCC,fill=Group))+
  geom_boxplot(position=position_dodge(width=0.8), show.legend = FALSE)+
  # geom_hline(yintercept=4, linetype="dashed", color = "red")+
  # geom_text(label=d_CCC2_L$listener)+
  labs(y = "sum of scaled scores (sub-scales A-H)",x = "")+
  guides(fill=guide_legend(title="Group"))+
  geom_quasirandom(aes(x=Group),data=filter(SumScores,Abnormal=="0"),dodge.width=0.8,colour="blue", shape=1, show.legend = FALSE)+
  geom_quasirandom(aes(x=Group),data=filter(SumScores,Abnormal=="1"),dodge.width=0.8,shape=21, show.legend = FALSE)+
  scale_y_continuous(limits = c(0,110),breaks=seq(0,110,20))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_blank(),
        legend.text  = element_blank(),
        legend.position = "none")

(t1 + t2) + plot_layout(ncol = 2, nrow = 1, heights = c(1, 1), widths = c(1,0.12)) + plot_annotation(tag_levels = 'A') + plot_layout(guides='collect') &
  theme(legend.position='bottom',        
        legend.direction = "horizontal",
        legend.background = element_blank(),
        legend.box.background = element_rect(colour = "black"),
        plot.tag = element_text(face = 'bold'))

```

What is the definition of abnormal score? 2 abnormal subcategories? 
Abnormal score == GCC < 55
GCC<55 + a negative SIDC is indicative of ASD. 8 APD children were flagged as possible ASDs.

3 out of 8 were diagnosed with ASD, additional 2 were undergoing an ASD assessment at the time of testing. 

Again, despite our best effort to recruit APD children without 


#### ECLIPS

```{r, label='ECLIPS', fig.cap="Add caption here.", fig.align='center', fig.width=10, fig.asp=.5, out.width='100%',echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

d_E<- read.csv(file.path(FileDir,'Files','ECLIPS_13032020.csv'),header=T)

d_E$Group <- factor(d_E$Group,levels=c("APD","TD"))

d_E_ScaledScore <- d_E %>% filter(ScoreType=="Scaled Score") %>% droplevels() 

library(tidyr)
d_E_L <- gather(d_E_ScaledScore,Sex, Age, SAP:Total, factor_key=TRUE)

colnames(d_E_L)[4] <- "Measure"
colnames(d_E_L)[5] <- "ScaledScore"

d_E_L$ScaledScore <- as.numeric(as.character(d_E_L$ScaledScore))
# rename measures for the plot
d_E_L$Measure <- revalue(d_E_L$Measure, c("SAP"="SAP","LLL"="L/L/L","M.A"="M&A",
                                          "PSS"="PSS","EAS"="EAS","Listening"="Listening",
                                          "Language"="Language","Social"="Social","Total"="Total"))
# merge data frames  -----------------------------------------------------------------------------------------------
d_E_L <- merge(d_Info,d_E_L,by=c("listener"))
# d_E_L <- d_E_L[,-match(c("Group.y"),names(d_E_L))]
# colnames(d_E_L)[2] = "Group"

## ------------------------------------------------------------------------------------------------------------------
# Some filtering: 
## ------------------------------------------------------------------------------------------------------------------
# Remove certain subjects
if (RmvSubj==1){d_E_L <- d_E_L[ ! d_E_L$listener %in% Subj2Remove, ] %>% droplevels()}

# Quality control: Include subjects based on the quality of their testing 
if (QualityCtrl==1){d_E_L <- d_E_L[ ! d_E_L$ExpEval %in% rmvEval, ] %>% droplevels()}

# Remove APD subjects based on their diagnosis 
if (DiagCtrl==1){d_E_L <- d_E_L[ ! d_E_L$Diagnosis %in% rmvDiag, ] %>% droplevels()}

# Include only APD subjects with SPD patterns 
if (APDsubTypCtrl==1){d_E_L <- d_E_L[ ! d_E_L$Subtype %in% rmvAPDType, ] %>% droplevels()}
## ------------------------------------------------------------------------------------------------------------------
ggplot(d_E_L, aes(x=Measure,y=ScaledScore,fill=Group))+
  geom_boxplot(position=position_dodge(width=0.8),outlier.shape=NA)+
  geom_hline(yintercept=5, linetype="dashed", color = "red")+
  #geom_text(label=d_E_L$listener)+
  labs(y = "ECLiPS Scaled Score",x = "Measure")+
  guides(fill=guide_legend(title="Group"))+
  geom_quasirandom(dodge.width=0.8,colour="blue", shape=1)+
  scale_y_continuous(limits = c(min(d_E_L$ScaledScore),max(d_E_L$ScaledScore)),breaks=seq(min(d_E_L$ScaledScore),max(d_E_L$ScaledScore),2))+
  theme(strip.background = element_blank())+
  theme_bw()+
  theme(axis.text = element_text(size = 11, face="bold",colour = "black"),
        axis.title.x = element_text(size=11, face="bold"),
        axis.title.y = element_text(size=11, face="bold"),
        legend.title = element_text(size=11, face="bold"),
        legend.text  = element_text(size=11, face="bold"),
        legend.box.background = element_rect(colour = "black", fill = "transparent"))
```

```{r,echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# --------------------------------------------------------------------------------------------------
# Assumptions:

# linear model
w1 <- lm(ScaledScore ~ Group, data = d_RS)

# 1. Normality (Shapiro-Wilk test) --> ~is met!
# data is normally distributed if p >.05

# QQ plot of residuals
# qqPlot(residuals(w1))

#jpeg('Q-Q Plot.png', width = 10, height = 6, units = 'in', res = 300)
# par(mfrow=c(1,2))    # set the plotting area into a 1*2 array
# qqnorm(d_RS$ScaledScore, pch = 1, frame = FALSE,main = "SRdT - Normal Q-Q Plot")
# qqline(d_RS$ScaledScore, col = "red", lwd = 2)
# qqnorm(rstandard(w1), pch = 1, frame = FALSE,main = "Residuals - Normal Q-Q Plot")
# qqline(rstandard(w1), col = "red", lwd = 2)
#dev.off()

# Option 1:
shapiro.test(residuals(w1))

# Option 2 by conditions:
NormTest <- d_RS %>%
  group_by(Group) %>%
  rstatix::shapiro_test(ScaledScore)

# 2. Homoggeneity of variance (Levene's test) --> is met!
# homogeneity is met if p>.05
# Option 1:
car::leveneTest(ScaledScore ~ Group, data=d_RS,center=median)
# Option 2: 
DescTools::LeveneTest(lm(ScaledScore~ Group, data = d_RS))

# --------------------------------------------------------------------------------------------------
```



## Discussion

## Conclusion

\clearpage

```{=html}
<!-- clearpage ends the page, and also dumps out all floats.
  Floats are things like tables and figures. -->
```
